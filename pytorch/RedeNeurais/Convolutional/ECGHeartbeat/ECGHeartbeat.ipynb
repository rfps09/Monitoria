{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87554"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(227, 227)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.6900, 0.4713, 0.5236], std=[0.3172, 0.4550, 0.4746]),\n",
    "        # transforms.Normalize(mean=[0.5685, 0.2570, 0.4582], std=[0.3371, 0.3743, 0.4563]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_data_path = 'DataSets/mitbih_fusion/train/'\n",
    "test_data_path = 'DataSets/mitbih_fusion/test/'\n",
    "\n",
    "dir_train = torchvision.datasets.ImageFolder(train_data_path,transform=transform)\n",
    "train_data = torch.utils.data.DataLoader(dir_train,batch_size=128,shuffle=True,num_workers=8)\n",
    "\n",
    "dir_test = torchvision.datasets.ImageFolder(test_data_path,transform=transform)\n",
    "test_data = torch.utils.data.DataLoader(dir_test,batch_size=32,shuffle=True,num_workers=8)\n",
    "\n",
    "len(train_data.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs = torch.stack([i for img,_ in test_data for i in img], dim=3)\n",
    "# media = imgs.view(3,-1).mean(dim=1)\n",
    "# desvio = imgs.view(3,-1).std(dim=1)\n",
    "# print(media,desvio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(NeuralNet,Loss,Optimizer,data_treino):\n",
    "    NeuralNet.train(True)\n",
    "    current_loss = 0.0\n",
    "    current_accuracy = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i,data in enumerate(data_treino):\n",
    "        x,y = data\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        Optimizer.zero_grad()\n",
    "        output = NeuralNet(x)\n",
    "        loss = Loss(output,y)\n",
    "        current_loss += loss.item()\n",
    "        loss.backward()\n",
    "        Optimizer.step()\n",
    "        \n",
    "        output = output.argmax(dim=1)\n",
    "        batch_accuracy = torch.eq(output,y)\n",
    "        batch_accuracy = batch_accuracy.sum()\n",
    "        current_accuracy += batch_accuracy\n",
    "        total_samples += len(x)\n",
    "\n",
    "    return current_loss/(i+1), (current_accuracy/total_samples).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_one_epoch(NeuralNet,Loss,val_data):\n",
    "    NeuralNet.train(False)\n",
    "    current_loss = 0.0\n",
    "    current_accuracy = 0.0\n",
    "    total_samples = len(val_data.dataset)\n",
    "    \n",
    "    for i,data in enumerate(val_data):\n",
    "        x,y = data\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        output = NeuralNet(x)\n",
    "        loss = Loss(output,y)\n",
    "        current_loss += loss.item()\n",
    "\n",
    "        output = output.argmax(dim=1)\n",
    "        batch_accuracy = torch.eq(output,y)\n",
    "        batch_accuracy = batch_accuracy.sum()\n",
    "        current_accuracy += batch_accuracy\n",
    "    return current_loss/(i+1), (current_accuracy/total_samples).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "    (7): Linear(in_features=1000, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torchvision.models as models\n",
    "\n",
    "cnn = models.alexnet(weights=models.AlexNet_Weights.DEFAULT)\n",
    "for i,param in enumerate(cnn.parameters()):\n",
    "    if i >= 5: break\n",
    "    param.requires_grad=False\n",
    "num_ftrs = cnn.classifier[6].out_features\n",
    "cnn.classifier.add_module(\"7\",nn.Linear(num_ftrs, 5))\n",
    "cnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(cnn.parameters(),lr=1e-3,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Train Loss: 0.38167902218708155\n",
      "Val Loss: 0.2031847948004512\n",
      "Train Accuracy: 0.9129794239997864\n",
      "Val Accuracy: 0.943358302116394\n",
      "\n",
      "Starting epoch 2\n",
      "Train Loss: 0.18736450218044928\n",
      "Val Loss: 0.1543128915974041\n",
      "Train Accuracy: 0.9492655992507935\n",
      "Val Accuracy: 0.9566051363945007\n",
      "\n",
      "Starting epoch 3\n",
      "Train Loss: 0.15272851796127365\n",
      "Val Loss: 0.13536392795397853\n",
      "Train Accuracy: 0.959396481513977\n",
      "Val Accuracy: 0.9638223648071289\n",
      "\n",
      "Starting epoch 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      9\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mStarting epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m     train_loss_per_epoch, train_accuracy_per_epoch \u001b[39m=\u001b[39m train_one_epoch(cnn,loss_function,optimizer,train_data)\n\u001b[0;32m     13\u001b[0m     train_loss_all_epoch\u001b[39m.\u001b[39mappend(train_loss_per_epoch)\n\u001b[0;32m     14\u001b[0m     train_accuracy_all_epoch\u001b[39m.\u001b[39mappend(train_accuracy_per_epoch)\n",
      "Cell \u001b[1;32mIn [4], line 9\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(NeuralNet, Loss, Optimizer, data_treino)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i,data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_treino):\n\u001b[0;32m      8\u001b[0m     x,y \u001b[39m=\u001b[39m data\n\u001b[1;32m----> 9\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mto(device)\n\u001b[0;32m     10\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m     Optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "train_loss_all_epoch = []\n",
    "train_accuracy_all_epoch = []\n",
    "val_loss_all_epoch = []\n",
    "val_accuracy_all_epoch = []\n",
    "loss_best_model = 1e9\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    train_loss_per_epoch, train_accuracy_per_epoch = train_one_epoch(cnn,loss_function,optimizer,train_data)\n",
    "\n",
    "    train_loss_all_epoch.append(train_loss_per_epoch)\n",
    "    train_accuracy_all_epoch.append(train_accuracy_per_epoch)\n",
    "\n",
    "    val_loss_per_epoch,val_accuracy_per_epoch = validation_one_epoch(cnn,loss_function,test_data)\n",
    "    \n",
    "    val_loss_all_epoch.append(val_loss_per_epoch)\n",
    "    val_accuracy_all_epoch.append(val_accuracy_per_epoch)\n",
    "\n",
    "    if val_loss_per_epoch < loss_best_model:\n",
    "        loss_best_model = val_loss_per_epoch\n",
    "        model_path = 'SavedModels/test_model'\n",
    "        torch.save(cnn.state_dict(),model_path)\n",
    "\n",
    "    print(f'Train Loss: {train_loss_per_epoch}')\n",
    "    print(f'Val Loss: {val_loss_per_epoch}')\n",
    "    print(f'Train Accuracy: {train_accuracy_per_epoch}')\n",
    "    print(f'Val Accuracy: {val_accuracy_per_epoch}')\n",
    "    print()\n",
    "\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_all_epoch)\n",
    "plt.plot(val_loss_all_epoch)\n",
    "plt.legend(['Treino', 'Validação'])\n",
    "plt.xlabel('Épocas')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_accuracy_all_epoch)\n",
    "plt.plot(val_accuracy_all_epoch)\n",
    "plt.legend(['Treino', 'Validação'])\n",
    "plt.xlabel('Épocas')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cnn.train(False)\n",
    "\n",
    "all_pred = torch.tensor([]).to(device)\n",
    "all_true = torch.tensor([]).to(device)\n",
    "\n",
    "for data in test_data:\n",
    "    x_test,y_test = data\n",
    "    x_test = x_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    y_pred = cnn(x_test)\n",
    "    y_pred = torch.Tensor.argmax(y_pred, dim=1)\n",
    "    all_pred = torch.cat((all_pred,y_pred))\n",
    "    all_true = torch.cat((all_true,y_test))\n",
    "\n",
    "all_true = all_true.to('cpu')\n",
    "all_pred = all_pred.to('cpu')\n",
    "print(classification_report(all_true,all_pred,zero_division=1,digits=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "saved_model = models.alexnet()\n",
    "num_ftrs = saved_model.classifier[6].out_features\n",
    "saved_model.fc = nn.Linear(num_ftrs, 5)\n",
    "\n",
    "saved_model.load_state_dict(torch.load('SavedModels/test_model'))\n",
    "\n",
    "saved_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "saved_model.train(False)\n",
    "\n",
    "all_pred = torch.tensor([]).to(device)\n",
    "all_true = torch.tensor([]).to(device)\n",
    "\n",
    "for data in test_data:\n",
    "    x_test,y_test = data\n",
    "    x_test = x_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    y_pred = saved_model(x_test)\n",
    "    y_pred = torch.Tensor.argmax(y_pred, dim=1)\n",
    "    all_pred = torch.cat((all_pred,y_pred))\n",
    "    all_true = torch.cat((all_true,y_test))\n",
    "\n",
    "all_true = all_true.to('cpu')\n",
    "all_pred = all_pred.to('cpu')\n",
    "print(classification_report(all_true,all_pred,zero_division=1,digits=5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c7eb35bf8493b15a7794fd0a89c627863cb8195addfe4e8a6a5f6b5be170870a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
