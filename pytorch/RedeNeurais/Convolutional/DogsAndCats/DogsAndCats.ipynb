{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1114"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "transform = transforms.Compose(\n",
    "  [\n",
    "    transforms.Resize(size=(299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5875, 0.5591, 0.4995], [0.2855, 0.2831, 0.3047]),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "  ]\n",
    ")\n",
    "\n",
    "augmentation = transforms.Compose(\n",
    "  [\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomRotation((0,360)),\n",
    "    transforms.Resize(size=(299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5875, 0.5591, 0.4995], [0.2855, 0.2831, 0.3047]),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "  ]\n",
    ")\n",
    "\n",
    "train_data_path = 'DataSet/train/'\n",
    "test_data_path = 'DataSet/test/'\n",
    "\n",
    "dir_train = torchvision.datasets.ImageFolder(train_data_path,transform=transform)\n",
    "dir_aug = torchvision.datasets.ImageFolder(train_data_path,transform=augmentation)\n",
    "dir_train = torch.utils.data.ConcatDataset((dir_train,dir_aug))\n",
    "train_data = torch.utils.data.DataLoader(dir_train,batch_size=256,shuffle=True,num_workers=10)\n",
    "\n",
    "dir_test = torchvision.datasets.ImageFolder(test_data_path,transform=transform)\n",
    "test_data = torch.utils.data.DataLoader(dir_test,batch_size=32,shuffle=True,num_workers=10)\n",
    "len(train_data.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(NeuralNet,Loss,Optimizer,data_treino):\n",
    "    NeuralNet.train(True)\n",
    "    current_loss = 0.0\n",
    "    current_accuracy = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i,data in enumerate(data_treino):\n",
    "        x,y = data\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        Optimizer.zero_grad()\n",
    "        output = NeuralNet(x)\n",
    "        loss = Loss(output,y)\n",
    "        loss.backward()\n",
    "        Optimizer.step()\n",
    "        current_loss += loss.item()\n",
    "        \n",
    "        output = output.argmax(dim=1)\n",
    "        batch_accuracy = torch.eq(output,y)\n",
    "        batch_accuracy = batch_accuracy.sum()\n",
    "        current_accuracy += batch_accuracy\n",
    "        total_samples += len(x)\n",
    "\n",
    "    return current_loss/(i+1), (current_accuracy/total_samples).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_one_epoch(NeuralNet,Loss,val_data):\n",
    "    NeuralNet.train(False)\n",
    "    current_loss = 0.0\n",
    "    current_accuracy = 0.0\n",
    "    total_samples = 0\n",
    "    for i,data in enumerate(val_data):\n",
    "        x,y = data\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        output = NeuralNet(x)\n",
    "        loss = Loss(output,y)\n",
    "        current_loss += loss.item()\n",
    "\n",
    "        output = output.argmax(dim=1)\n",
    "        batch_accuracy = torch.eq(output,y)\n",
    "        batch_accuracy = batch_accuracy.sum()\n",
    "        current_accuracy += batch_accuracy\n",
    "        total_samples += len(x)\n",
    "    return current_loss/(i+1), (current_accuracy/total_samples).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "cnn = torchvision.models.resnet50(num_classes=2).to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(cnn.parameters(),lr=1e-3,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n"
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "train_loss_all_epoch = []\n",
    "train_accuracy_all_epoch = []\n",
    "val_loss_all_epoch = []\n",
    "val_accuracy_all_epoch = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    train_loss_per_epoch, train_accuracy_per_epoch = train_one_epoch(cnn,loss_function,optimizer,train_data)\n",
    "\n",
    "    train_loss_all_epoch.append(train_loss_per_epoch)\n",
    "    train_accuracy_all_epoch.append(train_accuracy_per_epoch)\n",
    "\n",
    "    val_loss_per_epoch,val_accuracy_per_epoch = validation_one_epoch(cnn,loss_function,test_data)\n",
    "    \n",
    "    val_loss_all_epoch.append(val_loss_per_epoch)\n",
    "    val_accuracy_all_epoch.append(val_accuracy_per_epoch)\n",
    "\n",
    "    print(f'Train Loss: {train_loss_per_epoch}')\n",
    "    print(f'Val Loss: {val_loss_per_epoch}')\n",
    "    print(f'Train Accuracy: {train_accuracy_per_epoch}')\n",
    "    print(f'Val Accuracy: {val_accuracy_per_epoch}')\n",
    "    print()\n",
    "\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_all_epoch)\n",
    "plt.plot(val_loss_all_epoch)\n",
    "plt.legend(['Treino', 'Validação'])\n",
    "plt.xlabel('Épocas')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_accuracy_all_epoch)\n",
    "plt.plot(val_accuracy_all_epoch)\n",
    "plt.legend(['Treino', 'Validação'])\n",
    "plt.xlabel('Épocas')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cnn.train(False)\n",
    "\n",
    "all_pred = torch.tensor([]).to(device)\n",
    "all_true = torch.tensor([]).to(device)\n",
    "\n",
    "for data in test_data:\n",
    "    x_test,y_test = data\n",
    "    x_test = x_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    y_pred = cnn(x_test)\n",
    "    y_pred = torch.Tensor.argmax(y_pred, dim=1)\n",
    "    all_pred = torch.cat((all_pred,y_pred))\n",
    "    all_true = torch.cat((all_true,y_test))\n",
    "\n",
    "all_true = all_true.to('cpu')\n",
    "all_pred = all_pred.to('cpu')\n",
    "print(classification_report(all_true,all_pred,zero_division=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(299, 299)),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        #transforms.Normalize([0.5875, 0.5591, 0.4995], [0.2855, 0.2831, 0.3047]) \n",
    "    ]\n",
    ")\n",
    "\n",
    "dir_val = torchvision.datasets.ImageFolder('Teste',transform=transform)\n",
    "val_data = torch.utils.data.DataLoader(dir_val,batch_size=32,shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cnn.train(False)\n",
    "\n",
    "for data in val_data:\n",
    "    x_test,y_test = data\n",
    "    x_test = x_test.to(device)\n",
    "    y_test = y_test.to(device)\n",
    "    y_pred = cnn(x_test)\n",
    "    y_pred = y_pred.softmax(dim=1)\n",
    "    print(y_pred)\n",
    "    y_pred = torch.Tensor.argmax(y_pred, dim=1)\n",
    "    print(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b89750708a65724d1ad44a6840d11699d802f355f062b571e40236a66d24876"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
