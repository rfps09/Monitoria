{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self,input,output):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input, 16)\n",
    "        self.layer2 = nn.Linear(16,20)\n",
    "        self.layer3 = nn.Linear(20,output)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = F.softmax(self.layer3(x), dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class DataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self,data,labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = np.genfromtxt('iris.data',delimiter=',')\n",
    "data = np.delete(data,-1,axis=1)\n",
    "classes = np.genfromtxt('iris.data',delimiter=',', dtype=str,usecols=[-1])\n",
    "classes = np.unique(classes,return_inverse=1)[1]\n",
    "\n",
    "data_treino, data_teste, classe_treino, classe_teste = train_test_split(data,classes,test_size=0.2,stratify=classes,random_state=123)\n",
    "\n",
    "data_treino, data_validacao, classe_treino, classe_validacao = train_test_split(data_treino,classe_treino,test_size=0.1, stratify=classe_treino, random_state=1)\n",
    "\n",
    "dataset = DataSet(data_treino,classe_treino)\n",
    "data_train = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "dataset = DataSet(data_validacao,classe_validacao)\n",
    "data_val = DataLoader(dataset, batch_size=len(data_validacao), shuffle=True, num_workers=0)\n",
    "\n",
    "dataset = DataSet(data_teste,classe_teste)\n",
    "data_test = DataLoader(dataset, batch_size=len(data_teste), shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(4,3)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(NeuralNet,Loss,Optimizer,data_treino):\n",
    "    NeuralNet.train(True)\n",
    "    current_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for data in data_treino:\n",
    "        x,y = data\n",
    "        x = x.to(torch.float)\n",
    "        Optimizer.zero_grad()\n",
    "        output = NeuralNet(x)\n",
    "        loss = Loss(output,y)\n",
    "        loss.backward()\n",
    "        Optimizer.step()\n",
    "        current_loss += loss.item()\n",
    "        total_samples += len(x)\n",
    "\n",
    "    return current_loss/total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_one_epoch(NeuralNet,Loss,val_data):\n",
    "    NeuralNet.train(False)\n",
    "    current_loss = 0.0\n",
    "    total_samples = 0\n",
    "    for data in val_data:\n",
    "        x,y = data\n",
    "        x = x.to(torch.float)\n",
    "        output = NeuralNet(x)\n",
    "        loss = Loss(output,y)\n",
    "        current_loss += loss.item()\n",
    "        total_samples += len(x)\n",
    "    return current_loss/total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Train Loss: 0.04071248460699011\n",
      "Val Loss: 0.040732082393434316\n",
      "Starting epoch 2\n",
      "Train Loss: 0.040802952316072255\n",
      "Val Loss: 0.04055100017123752\n",
      "Starting epoch 3\n",
      "Train Loss: 0.04079006005216528\n",
      "Val Loss: 0.040725151697794594\n",
      "Starting epoch 4\n",
      "Train Loss: 0.04044861925972833\n",
      "Val Loss: 0.04049990464139868\n",
      "Starting epoch 5\n",
      "Train Loss: 0.04034193798347756\n",
      "Val Loss: 0.04066880433647721\n",
      "Starting epoch 6\n",
      "Train Loss: 0.04075101569846824\n",
      "Val Loss: 0.040469600094689265\n",
      "Starting epoch 7\n",
      "Train Loss: 0.0405384533935123\n",
      "Val Loss: 0.04058253213211342\n",
      "Starting epoch 8\n",
      "Train Loss: 0.04050056250007064\n",
      "Val Loss: 0.04064047336578369\n",
      "Starting epoch 9\n",
      "Train Loss: 0.04049771030743917\n",
      "Val Loss: 0.040552514570730704\n",
      "Starting epoch 10\n",
      "Train Loss: 0.04062898181102894\n",
      "Val Loss: 0.04053475349037736\n",
      "Starting epoch 11\n",
      "Train Loss: 0.040446188714769155\n",
      "Val Loss: 0.04037903525211193\n",
      "Starting epoch 12\n",
      "Train Loss: 0.0403502760110078\n",
      "Val Loss: 0.04038275943862067\n",
      "Starting epoch 13\n",
      "Train Loss: 0.040295159375226056\n",
      "Val Loss: 0.04042118787765503\n",
      "Starting epoch 14\n",
      "Train Loss: 0.04040322149241412\n",
      "Val Loss: 0.04027999992723818\n",
      "Starting epoch 15\n",
      "Train Loss: 0.04040492574373881\n",
      "Val Loss: 0.040271617748119215\n",
      "Starting epoch 16\n",
      "Train Loss: 0.040306691770200374\n",
      "Val Loss: 0.04042791768356606\n",
      "Starting epoch 17\n",
      "Train Loss: 0.04038305194289596\n",
      "Val Loss: 0.04046017704186616\n",
      "Starting epoch 18\n",
      "Train Loss: 0.04022795182687265\n",
      "Val Loss: 0.04011487740057486\n",
      "Starting epoch 19\n",
      "Train Loss: 0.040232434316917705\n",
      "Val Loss: 0.04016034912180017\n",
      "Starting epoch 20\n",
      "Train Loss: 0.040085036445547034\n",
      "Val Loss: 0.040174132144009625\n",
      "Starting epoch 21\n",
      "Train Loss: 0.040223154756757945\n",
      "Val Loss: 0.040356173559471416\n",
      "Starting epoch 22\n",
      "Train Loss: 0.040202067957984075\n",
      "Val Loss: 0.0402240808363314\n",
      "Starting epoch 23\n",
      "Train Loss: 0.040226756422607986\n",
      "Val Loss: 0.04007102383507623\n",
      "Starting epoch 24\n",
      "Train Loss: 0.0402918623553382\n",
      "Val Loss: 0.03996664947933621\n",
      "Starting epoch 25\n",
      "Train Loss: 0.04024131651277895\n",
      "Val Loss: 0.0403056056411178\n",
      "Starting epoch 26\n",
      "Train Loss: 0.04023830427063836\n",
      "Val Loss: 0.04028618335723877\n",
      "Starting epoch 27\n",
      "Train Loss: 0.04030353603539644\n",
      "Val Loss: 0.04018582127712391\n",
      "Starting epoch 28\n",
      "Train Loss: 0.03992992639541626\n",
      "Val Loss: 0.040243578177911264\n",
      "Starting epoch 29\n",
      "Train Loss: 0.040140488633403075\n",
      "Val Loss: 0.039980173110961914\n",
      "Starting epoch 30\n",
      "Train Loss: 0.039945611247309935\n",
      "Val Loss: 0.04018701557759886\n",
      "Starting epoch 31\n",
      "Train Loss: 0.04008406511059514\n",
      "Val Loss: 0.04009451137648688\n",
      "Starting epoch 32\n",
      "Train Loss: 0.039965423168959444\n",
      "Val Loss: 0.039884453570401227\n",
      "Starting epoch 33\n",
      "Train Loss: 0.040009276734458074\n",
      "Val Loss: 0.03990174222875525\n",
      "Starting epoch 34\n",
      "Train Loss: 0.04012288870634856\n",
      "Val Loss: 0.04013531737857395\n",
      "Starting epoch 35\n",
      "Train Loss: 0.04007361001438565\n",
      "Val Loss: 0.039738609834953594\n",
      "Starting epoch 36\n",
      "Train Loss: 0.04004316528638204\n",
      "Val Loss: 0.040162749864436964\n",
      "Starting epoch 37\n",
      "Train Loss: 0.03993209865358141\n",
      "Val Loss: 0.03962298455061736\n",
      "Starting epoch 38\n",
      "Train Loss: 0.04005332456694709\n",
      "Val Loss: 0.03987290351479142\n",
      "Starting epoch 39\n",
      "Train Loss: 0.03987496318640532\n",
      "Val Loss: 0.04005303758162039\n",
      "Starting epoch 40\n",
      "Train Loss: 0.03990661766793993\n",
      "Val Loss: 0.03980071345965067\n",
      "Starting epoch 41\n",
      "Train Loss: 0.03993512082982947\n",
      "Val Loss: 0.03993959228197733\n",
      "Starting epoch 42\n",
      "Train Loss: 0.03992994295226203\n",
      "Val Loss: 0.040032824984303224\n",
      "Starting epoch 43\n",
      "Train Loss: 0.0398327664092735\n",
      "Val Loss: 0.039929747581481934\n",
      "Starting epoch 44\n",
      "Train Loss: 0.03959367231086448\n",
      "Val Loss: 0.03972921658445288\n",
      "Starting epoch 45\n",
      "Train Loss: 0.0398934351073371\n",
      "Val Loss: 0.039762408645064744\n",
      "Starting epoch 46\n",
      "Train Loss: 0.03979513932157446\n",
      "Val Loss: 0.03978921197078846\n",
      "Starting epoch 47\n",
      "Train Loss: 0.039722319002504704\n",
      "Val Loss: 0.03981905182202657\n",
      "Starting epoch 48\n",
      "Train Loss: 0.039923246260042546\n",
      "Val Loss: 0.0396842239079652\n",
      "Starting epoch 49\n",
      "Train Loss: 0.03968319186457881\n",
      "Val Loss: 0.039543730241281015\n",
      "Starting epoch 50\n",
      "Train Loss: 0.03948626253339979\n",
      "Val Loss: 0.03961682981914944\n",
      "Starting epoch 51\n",
      "Train Loss: 0.039618337595904315\n",
      "Val Loss: 0.03962930485054299\n",
      "Starting epoch 52\n",
      "Train Loss: 0.03940351141823663\n",
      "Val Loss: 0.03966145382987128\n",
      "Starting epoch 53\n",
      "Train Loss: 0.03955888196274086\n",
      "Val Loss: 0.03958247546796446\n",
      "Starting epoch 54\n",
      "Train Loss: 0.03933252780525773\n",
      "Val Loss: 0.03963482159155386\n",
      "Starting epoch 55\n",
      "Train Loss: 0.03970398505528768\n",
      "Val Loss: 0.03941837394679034\n",
      "Starting epoch 56\n",
      "Train Loss: 0.039388445792374785\n",
      "Val Loss: 0.039471577714990685\n",
      "Starting epoch 57\n",
      "Train Loss: 0.03957472796793337\n",
      "Val Loss: 0.03945266317438196\n",
      "Starting epoch 58\n",
      "Train Loss: 0.03963465933446531\n",
      "Val Loss: 0.0396380866015399\n",
      "Starting epoch 59\n",
      "Train Loss: 0.03930415930571379\n",
      "Val Loss: 0.03965099652608236\n",
      "Starting epoch 60\n",
      "Train Loss: 0.03928335066194887\n",
      "Val Loss: 0.0395622816350725\n",
      "Starting epoch 61\n",
      "Train Loss: 0.03958221276601156\n",
      "Val Loss: 0.039478556977377996\n",
      "Starting epoch 62\n",
      "Train Loss: 0.03946485784318712\n",
      "Val Loss: 0.03926862279574076\n",
      "Starting epoch 63\n",
      "Train Loss: 0.03944692788300691\n",
      "Val Loss: 0.039428889751434326\n",
      "Starting epoch 64\n",
      "Train Loss: 0.03931588817525793\n",
      "Val Loss: 0.03929767785248933\n",
      "Starting epoch 65\n",
      "Train Loss: 0.03941278435565807\n",
      "Val Loss: 0.03920593085112395\n",
      "Starting epoch 66\n",
      "Train Loss: 0.03942635655403137\n",
      "Val Loss: 0.03924253031059548\n",
      "Starting epoch 67\n",
      "Train Loss: 0.03928086713508323\n",
      "Val Loss: 0.039224737220340304\n",
      "Starting epoch 68\n",
      "Train Loss: 0.03956457531010663\n",
      "Val Loss: 0.03938743803236219\n",
      "Starting epoch 69\n",
      "Train Loss: 0.03950754580674348\n",
      "Val Loss: 0.03954253594080607\n",
      "Starting epoch 70\n",
      "Train Loss: 0.039341137365058614\n",
      "Val Loss: 0.03952960283667953\n",
      "Starting epoch 71\n",
      "Train Loss: 0.03920151127709283\n",
      "Val Loss: 0.039354676449740375\n",
      "Starting epoch 72\n",
      "Train Loss: 0.039470027994226525\n",
      "Val Loss: 0.039183478664468835\n",
      "Starting epoch 73\n",
      "Train Loss: 0.039241801809381555\n",
      "Val Loss: 0.03932643267843458\n",
      "Starting epoch 74\n",
      "Train Loss: 0.039179598843609845\n",
      "Val Loss: 0.03928966985808478\n",
      "Starting epoch 75\n",
      "Train Loss: 0.03907775768527278\n",
      "Val Loss: 0.03950732504879987\n",
      "Starting epoch 76\n",
      "Train Loss: 0.039441173827206646\n",
      "Val Loss: 0.03920082582367791\n",
      "Starting epoch 77\n",
      "Train Loss: 0.039204554425345525\n",
      "Val Loss: 0.03922814241162053\n",
      "Starting epoch 78\n",
      "Train Loss: 0.039367632733450994\n",
      "Val Loss: 0.03933513164520264\n",
      "Starting epoch 79\n",
      "Train Loss: 0.03935538177137022\n",
      "Val Loss: 0.03928804728719923\n",
      "Starting epoch 80\n",
      "Train Loss: 0.03905019164085388\n",
      "Val Loss: 0.039239852516739455\n",
      "Starting epoch 81\n",
      "Train Loss: 0.03917358760480528\n",
      "Val Loss: 0.03896705309549967\n",
      "Starting epoch 82\n",
      "Train Loss: 0.03883681253150657\n",
      "Val Loss: 0.039137938508281005\n",
      "Starting epoch 83\n",
      "Train Loss: 0.03924896871602094\n",
      "Val Loss: 0.03916957753675955\n",
      "Starting epoch 84\n",
      "Train Loss: 0.03925184519202621\n",
      "Val Loss: 0.03904827877327248\n",
      "Starting epoch 85\n",
      "Train Loss: 0.03929110809608742\n",
      "Val Loss: 0.03888303482974017\n",
      "Starting epoch 86\n",
      "Train Loss: 0.039002841269528424\n",
      "Val Loss: 0.038998523244151366\n",
      "Starting epoch 87\n",
      "Train Loss: 0.039050148593054876\n",
      "Val Loss: 0.039211135219644616\n",
      "Starting epoch 88\n",
      "Train Loss: 0.039224855325840136\n",
      "Val Loss: 0.0390090909269121\n",
      "Starting epoch 89\n",
      "Train Loss: 0.03880384122883832\n",
      "Val Loss: 0.03872891156761735\n",
      "Starting epoch 90\n",
      "Train Loss: 0.03911473905598676\n",
      "Val Loss: 0.038913322819603816\n",
      "Starting epoch 91\n",
      "Train Loss: 0.03918664874853911\n",
      "Val Loss: 0.039155434679102014\n",
      "Starting epoch 92\n",
      "Train Loss: 0.038938835815147115\n",
      "Val Loss: 0.03903133339352078\n",
      "Starting epoch 93\n",
      "Train Loss: 0.038903659140622174\n",
      "Val Loss: 0.03901814200260021\n",
      "Starting epoch 94\n",
      "Train Loss: 0.038729310035705566\n",
      "Val Loss: 0.03869874057946382\n",
      "Starting epoch 95\n",
      "Train Loss: 0.0390773857081378\n",
      "Val Loss: 0.03868071127820898\n",
      "Starting epoch 96\n",
      "Train Loss: 0.03901196740291737\n",
      "Val Loss: 0.038867193239706534\n",
      "Starting epoch 97\n",
      "Train Loss: 0.03896729041028906\n",
      "Val Loss: 0.03884383925685176\n",
      "Starting epoch 98\n",
      "Train Loss: 0.038553201489978366\n",
      "Val Loss: 0.038700104863555344\n",
      "Starting epoch 99\n",
      "Train Loss: 0.038797466843216506\n",
      "Val Loss: 0.0387496550877889\n",
      "Starting epoch 100\n",
      "Train Loss: 0.03896051424520987\n",
      "Val Loss: 0.03893111922122814\n",
      "Starting epoch 101\n",
      "Train Loss: 0.03884071001300105\n",
      "Val Loss: 0.038766802461059006\n",
      "Starting epoch 102\n",
      "Train Loss: 0.03878730866644117\n",
      "Val Loss: 0.03860942743442677\n",
      "Starting epoch 103\n",
      "Train Loss: 0.03870254534262198\n",
      "Val Loss: 0.0386332129990613\n",
      "Starting epoch 104\n",
      "Train Loss: 0.0386912414321193\n",
      "Val Loss: 0.03870754330246537\n",
      "Starting epoch 105\n",
      "Train Loss: 0.03895919190512763\n",
      "Val Loss: 0.03871933177665428\n",
      "Starting epoch 106\n",
      "Train Loss: 0.03869787520832486\n",
      "Val Loss: 0.03856374378557558\n",
      "Starting epoch 107\n",
      "Train Loss: 0.0385421735269052\n",
      "Val Loss: 0.038354703673609984\n",
      "Starting epoch 108\n",
      "Train Loss: 0.03848547516045747\n",
      "Val Loss: 0.038542479276657104\n",
      "Starting epoch 109\n",
      "Train Loss: 0.03853763253600509\n",
      "Val Loss: 0.03828057922698833\n",
      "Starting epoch 110\n",
      "Train Loss: 0.03869633100650929\n",
      "Val Loss: 0.038745902202747484\n",
      "Starting epoch 111\n",
      "Train Loss: 0.038408889814659404\n",
      "Val Loss: 0.0385402606593238\n",
      "Starting epoch 112\n",
      "Train Loss: 0.03848073769498755\n",
      "Val Loss: 0.03816197426230819\n",
      "Starting epoch 113\n",
      "Train Loss: 0.03822466399934557\n",
      "Val Loss: 0.038616157240337796\n",
      "Starting epoch 114\n",
      "Train Loss: 0.03859995802243551\n",
      "Val Loss: 0.038358963198131986\n",
      "Starting epoch 115\n",
      "Train Loss: 0.038576505802295824\n",
      "Val Loss: 0.03829947665885643\n",
      "Starting epoch 116\n",
      "Train Loss: 0.03862194882498847\n",
      "Val Loss: 0.03836268628085101\n",
      "Starting epoch 117\n",
      "Train Loss: 0.03812130568204103\n",
      "Val Loss: 0.03814982374509176\n",
      "Starting epoch 118\n",
      "Train Loss: 0.03846639174002188\n",
      "Val Loss: 0.03830097339771412\n",
      "Starting epoch 119\n",
      "Train Loss: 0.03832270591347306\n",
      "Val Loss: 0.038171716310359816\n",
      "Starting epoch 120\n",
      "Train Loss: 0.03793795075681475\n",
      "Val Loss: 0.038351595401763916\n",
      "Starting epoch 121\n",
      "Train Loss: 0.0383121305041843\n",
      "Val Loss: 0.03823765560432717\n",
      "Starting epoch 122\n",
      "Train Loss: 0.03834961299543028\n",
      "Val Loss: 0.0384329910631533\n",
      "Starting epoch 123\n",
      "Train Loss: 0.03793561844914048\n",
      "Val Loss: 0.03843718767166138\n",
      "Starting epoch 124\n",
      "Train Loss: 0.03803734095008285\n",
      "Val Loss: 0.038128808692649556\n",
      "Starting epoch 125\n",
      "Train Loss: 0.038170326639104774\n",
      "Val Loss: 0.03796466853883532\n",
      "Starting epoch 126\n",
      "Train Loss: 0.037960177218472516\n",
      "Val Loss: 0.037984370081513015\n",
      "Starting epoch 127\n",
      "Train Loss: 0.03802259652702897\n",
      "Val Loss: 0.03802500389240406\n",
      "Starting epoch 128\n",
      "Train Loss: 0.037995988572085346\n",
      "Val Loss: 0.03797198997603522\n",
      "Starting epoch 129\n",
      "Train Loss: 0.03792827052098734\n",
      "Val Loss: 0.03786160107012148\n",
      "Starting epoch 130\n",
      "Train Loss: 0.037957219062028105\n",
      "Val Loss: 0.03791811179231714\n",
      "Starting epoch 131\n",
      "Train Loss: 0.037728260512705204\n",
      "Val Loss: 0.03787178353027061\n",
      "Starting epoch 132\n",
      "Train Loss: 0.037686139897063924\n",
      "Val Loss: 0.03785654129805388\n",
      "Starting epoch 133\n",
      "Train Loss: 0.0377526581287384\n",
      "Val Loss: 0.03786682806633137\n",
      "Starting epoch 134\n",
      "Train Loss: 0.0377138356367747\n",
      "Val Loss: 0.0377789956552011\n",
      "Starting epoch 135\n",
      "Train Loss: 0.03762405945195092\n",
      "Val Loss: 0.037848640923146847\n",
      "Starting epoch 136\n",
      "Train Loss: 0.037862555848227605\n",
      "Val Loss: 0.03766357622764729\n",
      "Starting epoch 137\n",
      "Train Loss: 0.03795903424421946\n",
      "Val Loss: 0.037589944071239896\n",
      "Starting epoch 138\n",
      "Train Loss: 0.03777935769822863\n",
      "Val Loss: 0.03777615891562568\n",
      "Starting epoch 139\n",
      "Train Loss: 0.03798840167345824\n",
      "Val Loss: 0.03810620142353906\n",
      "Starting epoch 140\n",
      "Train Loss: 0.03754566002775122\n",
      "Val Loss: 0.0372966389965128\n",
      "Starting epoch 141\n",
      "Train Loss: 0.037436728124265316\n",
      "Val Loss: 0.03748226662476858\n",
      "Starting epoch 142\n",
      "Train Loss: 0.0374709599547916\n",
      "Val Loss: 0.037450593378808766\n",
      "Starting epoch 143\n",
      "Train Loss: 0.03729165924919976\n",
      "Val Loss: 0.03737900212959007\n",
      "Starting epoch 144\n",
      "Train Loss: 0.03759291381747634\n",
      "Val Loss: 0.037405904244493554\n",
      "Starting epoch 145\n",
      "Train Loss: 0.03756130403942532\n",
      "Val Loss: 0.03733257563025863\n",
      "Starting epoch 146\n",
      "Train Loss: 0.03750997229858681\n",
      "Val Loss: 0.03751835061444177\n",
      "Starting epoch 147\n",
      "Train Loss: 0.037289231463714885\n",
      "Val Loss: 0.03746747749823111\n",
      "Starting epoch 148\n",
      "Train Loss: 0.03722056912051307\n",
      "Val Loss: 0.03730686836772495\n",
      "Starting epoch 149\n",
      "Train Loss: 0.037112374548558834\n",
      "Val Loss: 0.036974994672669306\n",
      "Starting epoch 150\n",
      "Train Loss: 0.03739675106825652\n",
      "Val Loss: 0.037187544284043486\n",
      "Starting epoch 151\n",
      "Train Loss: 0.03718885613812341\n",
      "Val Loss: 0.037132694765373515\n",
      "Starting epoch 152\n",
      "Train Loss: 0.03703344309771502\n",
      "Val Loss: 0.03692726680526027\n",
      "Starting epoch 153\n",
      "Train Loss: 0.03681125188315356\n",
      "Val Loss: 0.03687547257652989\n",
      "Starting epoch 154\n",
      "Train Loss: 0.037059654792149864\n",
      "Val Loss: 0.03719923452094749\n",
      "Starting epoch 155\n",
      "Train Loss: 0.03711593316660987\n",
      "Val Loss: 0.03707655546841798\n",
      "Starting epoch 156\n",
      "Train Loss: 0.037051180446589435\n",
      "Val Loss: 0.03699271380901337\n",
      "Starting epoch 157\n",
      "Train Loss: 0.03697554270426432\n",
      "Val Loss: 0.03738667512381518\n",
      "Starting epoch 158\n",
      "Train Loss: 0.03712477838551557\n",
      "Val Loss: 0.036733786265055336\n",
      "Starting epoch 159\n",
      "Train Loss: 0.036693304777145386\n",
      "Val Loss: 0.03677764203813341\n",
      "Starting epoch 160\n",
      "Train Loss: 0.037086564081686514\n",
      "Val Loss: 0.037288293794349385\n",
      "Starting epoch 161\n",
      "Train Loss: 0.03713387030142325\n",
      "Val Loss: 0.03647426929738787\n",
      "Starting epoch 162\n",
      "Train Loss: 0.036436377852051345\n",
      "Val Loss: 0.03690977063443926\n",
      "Starting epoch 163\n",
      "Train Loss: 0.03720462487803565\n",
      "Val Loss: 0.036621519812831176\n",
      "Starting epoch 164\n",
      "Train Loss: 0.0368997300112689\n",
      "Val Loss: 0.03660066922505697\n",
      "Starting epoch 165\n",
      "Train Loss: 0.03659515745109982\n",
      "Val Loss: 0.03664716139987663\n",
      "Starting epoch 166\n",
      "Train Loss: 0.03637311469625543\n",
      "Val Loss: 0.03708075649208493\n",
      "Starting epoch 167\n",
      "Train Loss: 0.03645628635530119\n",
      "Val Loss: 0.036480039910033894\n",
      "Starting epoch 168\n",
      "Train Loss: 0.03690920714978819\n",
      "Val Loss: 0.03642583334887469\n",
      "Starting epoch 169\n",
      "Train Loss: 0.036293795263325726\n",
      "Val Loss: 0.03611418273713854\n",
      "Starting epoch 170\n",
      "Train Loss: 0.03662851287258996\n",
      "Val Loss: 0.03628395552988405\n",
      "Starting epoch 171\n",
      "Train Loss: 0.03666425744692484\n",
      "Val Loss: 0.036301740893611205\n",
      "Starting epoch 172\n",
      "Train Loss: 0.036587107512685985\n",
      "Val Loss: 0.0364754663573371\n",
      "Starting epoch 173\n",
      "Train Loss: 0.036354335921782034\n",
      "Val Loss: 0.03631672704661334\n",
      "Starting epoch 174\n",
      "Train Loss: 0.03638202614254422\n",
      "Val Loss: 0.0362207630166301\n",
      "Starting epoch 175\n",
      "Train Loss: 0.0365260276529524\n",
      "Val Loss: 0.03600031082276945\n",
      "Starting epoch 176\n",
      "Train Loss: 0.03616258502006531\n",
      "Val Loss: 0.036238915390438504\n",
      "Starting epoch 177\n",
      "Train Loss: 0.03613621437991107\n",
      "Val Loss: 0.03641050336537538\n",
      "Starting epoch 178\n",
      "Train Loss: 0.036447104480531484\n",
      "Val Loss: 0.03654575071952961\n",
      "Starting epoch 179\n",
      "Train Loss: 0.036191581575958816\n",
      "Val Loss: 0.036229858795801796\n",
      "Starting epoch 180\n",
      "Train Loss: 0.03613880828574852\n",
      "Val Loss: 0.03595557588118094\n",
      "Starting epoch 181\n",
      "Train Loss: 0.036161754418302466\n",
      "Val Loss: 0.03586716673992298\n",
      "Starting epoch 182\n",
      "Train Loss: 0.0363442572178664\n",
      "Val Loss: 0.03605660630597009\n",
      "Starting epoch 183\n",
      "Train Loss: 0.03571748292004621\n",
      "Val Loss: 0.03630980131802736\n",
      "Starting epoch 184\n",
      "Train Loss: 0.03570573363039228\n",
      "Val Loss: 0.03562310834725698\n",
      "Starting epoch 185\n",
      "Train Loss: 0.035410705539915294\n",
      "Val Loss: 0.036316819213054796\n",
      "Starting epoch 186\n",
      "Train Loss: 0.035884396345527085\n",
      "Val Loss: 0.03571334701997263\n",
      "Starting epoch 187\n",
      "Train Loss: 0.035691343523837904\n",
      "Val Loss: 0.036096202554526155\n",
      "Starting epoch 188\n",
      "Train Loss: 0.035974609631079214\n",
      "Val Loss: 0.035925854135442664\n",
      "Starting epoch 189\n",
      "Train Loss: 0.03591903547445933\n",
      "Val Loss: 0.036025138916792696\n",
      "Starting epoch 190\n",
      "Train Loss: 0.0359786539166062\n",
      "Val Loss: 0.03558312853177389\n",
      "Starting epoch 191\n",
      "Train Loss: 0.03561287124951681\n",
      "Val Loss: 0.035806307638133014\n",
      "Starting epoch 192\n",
      "Train Loss: 0.03579818319391321\n",
      "Val Loss: 0.035906873919345716\n",
      "Starting epoch 193\n",
      "Train Loss: 0.035705107229727286\n",
      "Val Loss: 0.035018261384080956\n",
      "Starting epoch 194\n",
      "Train Loss: 0.03545236808282358\n",
      "Val Loss: 0.036027625755027486\n",
      "Starting epoch 195\n",
      "Train Loss: 0.03578334163736414\n",
      "Val Loss: 0.03577984979859105\n",
      "Starting epoch 196\n",
      "Train Loss: 0.03530745649779284\n",
      "Val Loss: 0.036014346612824336\n",
      "Starting epoch 197\n",
      "Train Loss: 0.0351383575686702\n",
      "Val Loss: 0.03541290980798227\n",
      "Starting epoch 198\n",
      "Train Loss: 0.03548103626127596\n",
      "Val Loss: 0.03508235403784999\n",
      "Starting epoch 199\n",
      "Train Loss: 0.03555328040211289\n",
      "Val Loss: 0.03514888109984221\n",
      "Starting epoch 200\n",
      "Train Loss: 0.03549049849863405\n",
      "Val Loss: 0.035846432050069175\n",
      "Starting epoch 201\n",
      "Train Loss: 0.035575673536018086\n",
      "Val Loss: 0.035654090620853285\n",
      "Starting epoch 202\n",
      "Train Loss: 0.035071753793292575\n",
      "Val Loss: 0.03544959149978779\n",
      "Starting epoch 203\n",
      "Train Loss: 0.0349503176079856\n",
      "Val Loss: 0.034772891689229896\n",
      "Starting epoch 204\n",
      "Train Loss: 0.03490704408398381\n",
      "Val Loss: 0.03522017763720618\n",
      "Starting epoch 205\n",
      "Train Loss: 0.03505856571374116\n",
      "Val Loss: 0.03520902439400002\n",
      "Starting epoch 206\n",
      "Train Loss: 0.035092876465232285\n",
      "Val Loss: 0.03504818015628391\n",
      "Starting epoch 207\n",
      "Train Loss: 0.035047953879391705\n",
      "Val Loss: 0.03545855813556247\n",
      "Starting epoch 208\n",
      "Train Loss: 0.03479465455920608\n",
      "Val Loss: 0.0355785373184416\n",
      "Starting epoch 209\n",
      "Train Loss: 0.03502739745157736\n",
      "Val Loss: 0.03511136218353554\n",
      "Starting epoch 210\n",
      "Train Loss: 0.0351369822466815\n",
      "Val Loss: 0.035254772614549706\n",
      "Starting epoch 211\n",
      "Train Loss: 0.03493276514388897\n",
      "Val Loss: 0.0349002910984887\n",
      "Starting epoch 212\n",
      "Train Loss: 0.03472770033059297\n",
      "Val Loss: 0.03529665094834787\n",
      "Starting epoch 213\n",
      "Train Loss: 0.03495733771059248\n",
      "Val Loss: 0.034992930513841135\n",
      "Starting epoch 214\n",
      "Train Loss: 0.03516611512060518\n",
      "Val Loss: 0.03476092881626553\n",
      "Starting epoch 215\n",
      "Train Loss: 0.03446504694444162\n",
      "Val Loss: 0.034759582192809495\n",
      "Starting epoch 216\n",
      "Train Loss: 0.03446678927651158\n",
      "Val Loss: 0.035176795389917165\n",
      "Starting epoch 217\n",
      "Train Loss: 0.03443754381603665\n",
      "Val Loss: 0.03447278064710123\n",
      "Starting epoch 218\n",
      "Train Loss: 0.03430092500315772\n",
      "Val Loss: 0.03478574752807617\n",
      "Starting epoch 219\n",
      "Train Loss: 0.03470851370581874\n",
      "Val Loss: 0.03435982267061869\n",
      "Starting epoch 220\n",
      "Train Loss: 0.034881320816499216\n",
      "Val Loss: 0.03425162975434904\n",
      "Starting epoch 221\n",
      "Train Loss: 0.0349379982109423\n",
      "Val Loss: 0.03465391474741476\n",
      "Starting epoch 222\n",
      "Train Loss: 0.0348853623425519\n",
      "Val Loss: 0.03479199939303928\n",
      "Starting epoch 223\n",
      "Train Loss: 0.034676324438165734\n",
      "Val Loss: 0.03438945224991551\n",
      "Starting epoch 224\n",
      "Train Loss: 0.03451516010143139\n",
      "Val Loss: 0.034806415990546895\n",
      "Starting epoch 225\n",
      "Train Loss: 0.03431282275252872\n",
      "Val Loss: 0.0343269407749176\n",
      "Starting epoch 226\n",
      "Train Loss: 0.034344818305086205\n",
      "Val Loss: 0.03450857875523744\n",
      "Starting epoch 227\n",
      "Train Loss: 0.03444590226367668\n",
      "Val Loss: 0.03430941369798449\n",
      "Starting epoch 228\n",
      "Train Loss: 0.03436595367060767\n",
      "Val Loss: 0.034241692887412176\n",
      "Starting epoch 229\n",
      "Train Loss: 0.03421640064981249\n",
      "Val Loss: 0.033868177621452895\n",
      "Starting epoch 230\n",
      "Train Loss: 0.034335187187901246\n",
      "Val Loss: 0.03421670860714383\n",
      "Starting epoch 231\n",
      "Train Loss: 0.03419691765749896\n",
      "Val Loss: 0.03426014659581361\n",
      "Starting epoch 232\n",
      "Train Loss: 0.034111215008629694\n",
      "Val Loss: 0.03356071699548651\n",
      "Starting epoch 233\n",
      "Train Loss: 0.03464902882222776\n",
      "Val Loss: 0.03434300753805372\n",
      "Starting epoch 234\n",
      "Train Loss: 0.03415581915113661\n",
      "Val Loss: 0.034552209355213026\n",
      "Starting epoch 235\n",
      "Train Loss: 0.0338344673315684\n",
      "Val Loss: 0.03407911238846956\n",
      "Starting epoch 236\n",
      "Train Loss: 0.03404295002972638\n",
      "Val Loss: 0.03422847555743323\n",
      "Starting epoch 237\n",
      "Train Loss: 0.03466946659264741\n",
      "Val Loss: 0.03368194401264191\n",
      "Starting epoch 238\n",
      "Train Loss: 0.033874860516300905\n",
      "Val Loss: 0.03406542263649128\n",
      "Starting epoch 239\n",
      "Train Loss: 0.03378491931491428\n",
      "Val Loss: 0.03397769287780479\n",
      "Starting epoch 240\n",
      "Train Loss: 0.0337756077448527\n",
      "Val Loss: 0.03415348408398805\n",
      "Starting epoch 241\n",
      "Train Loss: 0.03463938390767133\n",
      "Val Loss: 0.03406135461948536\n",
      "Starting epoch 242\n",
      "Train Loss: 0.03403088947137197\n",
      "Val Loss: 0.033609401848581105\n",
      "Starting epoch 243\n",
      "Train Loss: 0.03430764597875101\n",
      "Val Loss: 0.03366821617991836\n",
      "Starting epoch 244\n",
      "Train Loss: 0.03363867048864012\n",
      "Val Loss: 0.03319261305862003\n",
      "Starting epoch 245\n",
      "Train Loss: 0.03321276605129242\n",
      "Val Loss: 0.03395114231992651\n",
      "Starting epoch 246\n",
      "Train Loss: 0.033241141173574656\n",
      "Val Loss: 0.03341097467475467\n",
      "Starting epoch 247\n",
      "Train Loss: 0.033773269366334985\n",
      "Val Loss: 0.03341799919252043\n",
      "Starting epoch 248\n",
      "Train Loss: 0.03300834750687635\n",
      "Val Loss: 0.033572090996636286\n",
      "Starting epoch 249\n",
      "Train Loss: 0.03339826839941519\n",
      "Val Loss: 0.03360546242307733\n",
      "Starting epoch 250\n",
      "Train Loss: 0.03382807307773166\n",
      "Val Loss: 0.0344553843692497\n",
      "Starting epoch 251\n",
      "Train Loss: 0.03377527826362186\n",
      "Val Loss: 0.033444704280959234\n",
      "Starting epoch 252\n",
      "Train Loss: 0.03353435628943973\n",
      "Val Loss: 0.033356306729493315\n",
      "Starting epoch 253\n",
      "Train Loss: 0.03347310147903584\n",
      "Val Loss: 0.03302068511644999\n",
      "Starting epoch 254\n",
      "Train Loss: 0.03300999767250485\n",
      "Val Loss: 0.03348136058560124\n",
      "Starting epoch 255\n",
      "Train Loss: 0.03372077257544906\n",
      "Val Loss: 0.033245422773891024\n",
      "Starting epoch 256\n",
      "Train Loss: 0.033156325971638714\n",
      "Val Loss: 0.0337539596690072\n",
      "Starting epoch 257\n",
      "Train Loss: 0.0329378346602122\n",
      "Val Loss: 0.033097485149348224\n",
      "Starting epoch 258\n",
      "Train Loss: 0.03296075926886664\n",
      "Val Loss: 0.03291939474918224\n",
      "Starting epoch 259\n",
      "Train Loss: 0.03334618663346326\n",
      "Val Loss: 0.03322943162035059\n",
      "Starting epoch 260\n",
      "Train Loss: 0.032843601372506886\n",
      "Val Loss: 0.03371388272002891\n",
      "Starting epoch 261\n",
      "Train Loss: 0.03325314323107401\n",
      "Val Loss: 0.03307462731997172\n",
      "Starting epoch 262\n",
      "Train Loss: 0.03315346991574323\n",
      "Val Loss: 0.03325496503600368\n",
      "Starting epoch 263\n",
      "Train Loss: 0.03355656564235687\n",
      "Val Loss: 0.033649125032954745\n",
      "Starting epoch 264\n",
      "Train Loss: 0.03274960098443208\n",
      "Val Loss: 0.03309992728409944\n",
      "Starting epoch 265\n",
      "Train Loss: 0.03304489839960028\n",
      "Val Loss: 0.03302502190625226\n",
      "Starting epoch 266\n",
      "Train Loss: 0.03342760933770074\n",
      "Val Loss: 0.03317862804289217\n",
      "Starting epoch 267\n",
      "Train Loss: 0.033507538614449675\n",
      "Val Loss: 0.03310585573867515\n",
      "Starting epoch 268\n",
      "Train Loss: 0.033198943844547975\n",
      "Val Loss: 0.03370329958421213\n",
      "Starting epoch 269\n",
      "Train Loss: 0.03291917509502835\n",
      "Val Loss: 0.03283654925999818\n",
      "Starting epoch 270\n",
      "Train Loss: 0.033375702522419115\n",
      "Val Loss: 0.03261213501294454\n",
      "Starting epoch 271\n",
      "Train Loss: 0.03348757326602936\n",
      "Val Loss: 0.032178065843052335\n",
      "Starting epoch 272\n",
      "Train Loss: 0.03350471125708686\n",
      "Val Loss: 0.03295609741299241\n",
      "Starting epoch 273\n",
      "Train Loss: 0.033232917388280235\n",
      "Val Loss: 0.033264705428370726\n",
      "Starting epoch 274\n",
      "Train Loss: 0.032791437926115816\n",
      "Val Loss: 0.03318909307320913\n",
      "Starting epoch 275\n",
      "Train Loss: 0.03299119461465765\n",
      "Val Loss: 0.032234190238846674\n",
      "Starting epoch 276\n",
      "Train Loss: 0.03304211519382618\n",
      "Val Loss: 0.03252029474134798\n",
      "Starting epoch 277\n",
      "Train Loss: 0.03260275445602558\n",
      "Val Loss: 0.03278450557479152\n",
      "Starting epoch 278\n",
      "Train Loss: 0.03300030971014941\n",
      "Val Loss: 0.03295696168034165\n",
      "Starting epoch 279\n",
      "Train Loss: 0.032447492634808575\n",
      "Val Loss: 0.03305961246843691\n",
      "Starting epoch 280\n",
      "Train Loss: 0.03275280031892988\n",
      "Val Loss: 0.03253226147757636\n",
      "Starting epoch 281\n",
      "Train Loss: 0.032716088824801974\n",
      "Val Loss: 0.032974239300798486\n",
      "Starting epoch 282\n",
      "Train Loss: 0.03208190478660442\n",
      "Val Loss: 0.032458805927523864\n",
      "Starting epoch 283\n",
      "Train Loss: 0.03242592955077136\n",
      "Val Loss: 0.03322804250099041\n",
      "Starting epoch 284\n",
      "Train Loss: 0.032356131407949656\n",
      "Val Loss: 0.03275076548258463\n",
      "Starting epoch 285\n",
      "Train Loss: 0.032054637317304256\n",
      "Val Loss: 0.032684426064844486\n",
      "Starting epoch 286\n",
      "Train Loss: 0.03250453648743806\n",
      "Val Loss: 0.03217175051018044\n",
      "Starting epoch 287\n",
      "Train Loss: 0.0329879069769824\n",
      "Val Loss: 0.03294720583491855\n",
      "Starting epoch 288\n",
      "Train Loss: 0.03350974453820123\n",
      "Val Loss: 0.03224955885498612\n",
      "Starting epoch 289\n",
      "Train Loss: 0.03287036275422132\n",
      "Val Loss: 0.03276114441730358\n",
      "Starting epoch 290\n",
      "Train Loss: 0.03200077127527307\n",
      "Val Loss: 0.0321991918263612\n",
      "Starting epoch 291\n",
      "Train Loss: 0.032026463084750705\n",
      "Val Loss: 0.03287694685988956\n",
      "Starting epoch 292\n",
      "Train Loss: 0.03279991171978138\n",
      "Val Loss: 0.031847931168697496\n",
      "Starting epoch 293\n",
      "Train Loss: 0.032898402876324125\n",
      "Val Loss: 0.03246649051154101\n",
      "Starting epoch 294\n",
      "Train Loss: 0.0322231219874488\n",
      "Val Loss: 0.0329253563174495\n",
      "Starting epoch 295\n",
      "Train Loss: 0.03201350624914522\n",
      "Val Loss: 0.032261784429903385\n",
      "Starting epoch 296\n",
      "Train Loss: 0.03246883937606105\n",
      "Val Loss: 0.03169575168026818\n",
      "Starting epoch 297\n",
      "Train Loss: 0.03246549047805645\n",
      "Val Loss: 0.0324496665486583\n",
      "Starting epoch 298\n",
      "Train Loss: 0.03169138398435381\n",
      "Val Loss: 0.032203147256815876\n",
      "Starting epoch 299\n",
      "Train Loss: 0.03207142264754684\n",
      "Val Loss: 0.032000937395625643\n",
      "Starting epoch 300\n",
      "Train Loss: 0.03262598150306278\n",
      "Val Loss: 0.03211543791823917\n",
      "Starting epoch 301\n",
      "Train Loss: 0.032546577630219634\n",
      "Val Loss: 0.03216543131404453\n",
      "Starting epoch 302\n",
      "Train Loss: 0.032118976668075276\n",
      "Val Loss: 0.032170226176579796\n",
      "Starting epoch 303\n",
      "Train Loss: 0.032502578364478216\n",
      "Val Loss: 0.03252641911859865\n",
      "Starting epoch 304\n",
      "Train Loss: 0.031777850455707975\n",
      "Val Loss: 0.03234259894600621\n",
      "Starting epoch 305\n",
      "Train Loss: 0.0322240905629264\n",
      "Val Loss: 0.03185362506795813\n",
      "Starting epoch 306\n",
      "Train Loss: 0.032247681308675696\n",
      "Val Loss: 0.03162407985440007\n",
      "Starting epoch 307\n",
      "Train Loss: 0.031910938797173674\n",
      "Val Loss: 0.03257604881569191\n",
      "Starting epoch 308\n",
      "Train Loss: 0.03198754953013526\n",
      "Val Loss: 0.0319245672888226\n",
      "Starting epoch 309\n",
      "Train Loss: 0.032140596597282974\n",
      "Val Loss: 0.03222055678014402\n",
      "Starting epoch 310\n",
      "Train Loss: 0.03238683442274729\n",
      "Val Loss: 0.03173617135595392\n",
      "Starting epoch 311\n",
      "Train Loss: 0.03198699708338137\n",
      "Val Loss: 0.03185837412322009\n",
      "Starting epoch 312\n",
      "Train Loss: 0.032001319306868094\n",
      "Val Loss: 0.03237988441078751\n",
      "Starting epoch 313\n",
      "Train Loss: 0.03247207016856582\n",
      "Val Loss: 0.03203375471962823\n",
      "Starting epoch 314\n",
      "Train Loss: 0.031279094241283556\n",
      "Val Loss: 0.031228033480820833\n",
      "Starting epoch 315\n",
      "Train Loss: 0.03167352025155668\n",
      "Val Loss: 0.03146087074721301\n",
      "Starting epoch 316\n",
      "Train Loss: 0.031761441517759254\n",
      "Val Loss: 0.03207208823274683\n",
      "Starting epoch 317\n",
      "Train Loss: 0.03169934506769533\n",
      "Val Loss: 0.03217081891165839\n",
      "Starting epoch 318\n",
      "Train Loss: 0.03171349951514491\n",
      "Val Loss: 0.03185704736797898\n",
      "Starting epoch 319\n",
      "Train Loss: 0.031955335979108455\n",
      "Val Loss: 0.03175008848861412\n",
      "Starting epoch 320\n",
      "Train Loss: 0.03159309095806546\n",
      "Val Loss: 0.0315526337535293\n",
      "Starting epoch 321\n",
      "Train Loss: 0.03146896373342584\n",
      "Val Loss: 0.031125953352009808\n",
      "Starting epoch 322\n",
      "Train Loss: 0.03147114868517275\n",
      "Val Loss: 0.031834520123623034\n",
      "Starting epoch 323\n",
      "Train Loss: 0.031068503304764076\n",
      "Val Loss: 0.03192787534660763\n",
      "Starting epoch 324\n",
      "Train Loss: 0.03165399697091845\n",
      "Val Loss: 0.031968044462027376\n",
      "Starting epoch 325\n",
      "Train Loss: 0.03112213479148017\n",
      "Val Loss: 0.031713869836595326\n",
      "Starting epoch 326\n",
      "Train Loss: 0.03224651515483856\n",
      "Val Loss: 0.0315804867832749\n",
      "Starting epoch 327\n",
      "Train Loss: 0.030903102623091802\n",
      "Val Loss: 0.031235317941065186\n",
      "Starting epoch 328\n",
      "Train Loss: 0.031025540497567918\n",
      "Val Loss: 0.03227551722968066\n",
      "Starting epoch 329\n",
      "Train Loss: 0.03132784697744581\n",
      "Val Loss: 0.03157997848810973\n",
      "Starting epoch 330\n",
      "Train Loss: 0.03175295006345819\n",
      "Val Loss: 0.03165140527266043\n",
      "Starting epoch 331\n",
      "Train Loss: 0.03137042456203037\n",
      "Val Loss: 0.031085612045394048\n",
      "Starting epoch 332\n",
      "Train Loss: 0.031142879415441443\n",
      "Val Loss: 0.031373088558514915\n",
      "Starting epoch 333\n",
      "Train Loss: 0.03165849932917842\n",
      "Val Loss: 0.0320130095437721\n",
      "Starting epoch 334\n",
      "Train Loss: 0.03148256131896266\n",
      "Val Loss: 0.0312033223885077\n",
      "Starting epoch 335\n",
      "Train Loss: 0.03130552779745172\n",
      "Val Loss: 0.031036811294379057\n",
      "Starting epoch 336\n",
      "Train Loss: 0.0312917215956582\n",
      "Val Loss: 0.03135287154603888\n",
      "Starting epoch 337\n",
      "Train Loss: 0.03140946670814797\n",
      "Val Loss: 0.031147329343689814\n",
      "Starting epoch 338\n",
      "Train Loss: 0.03143526337764881\n",
      "Val Loss: 0.03147333970776311\n",
      "Starting epoch 339\n",
      "Train Loss: 0.031101404516785232\n",
      "Val Loss: 0.03124862688559073\n",
      "Starting epoch 340\n",
      "Train Loss: 0.0312188896867964\n",
      "Val Loss: 0.03068664338853624\n",
      "Starting epoch 341\n",
      "Train Loss: 0.031196102499961853\n",
      "Val Loss: 0.031107535516774212\n",
      "Starting epoch 342\n",
      "Train Loss: 0.031093883293646353\n",
      "Val Loss: 0.03143707966362989\n",
      "Starting epoch 343\n",
      "Train Loss: 0.03136362245789281\n",
      "Val Loss: 0.03125289910369449\n",
      "Starting epoch 344\n",
      "Train Loss: 0.031451845058688414\n",
      "Val Loss: 0.03164088946801645\n",
      "Starting epoch 345\n",
      "Train Loss: 0.0314684995898494\n",
      "Val Loss: 0.03160053381213435\n",
      "Starting epoch 346\n",
      "Train Loss: 0.03163609791685034\n",
      "Val Loss: 0.031608271378057974\n",
      "Starting epoch 347\n",
      "Train Loss: 0.031318464764842284\n",
      "Val Loss: 0.030911749711743108\n",
      "Starting epoch 348\n",
      "Train Loss: 0.031342845824029714\n",
      "Val Loss: 0.03198693527115716\n",
      "Starting epoch 349\n",
      "Train Loss: 0.031414567320435134\n",
      "Val Loss: 0.03133256291901624\n",
      "Starting epoch 350\n",
      "Train Loss: 0.031092966596285503\n",
      "Val Loss: 0.030683285660213895\n",
      "Starting epoch 351\n",
      "Train Loss: 0.030368248621622723\n",
      "Val Loss: 0.030898908222163166\n",
      "Starting epoch 352\n",
      "Train Loss: 0.03100606578367728\n",
      "Val Loss: 0.03120235988387355\n",
      "Starting epoch 353\n",
      "Train Loss: 0.0314234776629342\n",
      "Val Loss: 0.03094083567460378\n",
      "Starting epoch 354\n",
      "Train Loss: 0.03136238014256513\n",
      "Val Loss: 0.03115170531802707\n",
      "Starting epoch 355\n",
      "Train Loss: 0.030971684389644198\n",
      "Val Loss: 0.030505820556923195\n",
      "Starting epoch 356\n",
      "Train Loss: 0.030759691088287917\n",
      "Val Loss: 0.030706949256084585\n",
      "Starting epoch 357\n",
      "Train Loss: 0.031405116672869084\n",
      "Val Loss: 0.03077703383233812\n",
      "Starting epoch 358\n",
      "Train Loss: 0.030723284240122193\n",
      "Val Loss: 0.031074526133360685\n",
      "Starting epoch 359\n",
      "Train Loss: 0.03144039268846865\n",
      "Val Loss: 0.03106864348605827\n",
      "Starting epoch 360\n",
      "Train Loss: 0.03118469704080511\n",
      "Val Loss: 0.030981231618810584\n",
      "Starting epoch 361\n",
      "Train Loss: 0.03083571129375034\n",
      "Val Loss: 0.030767096413506403\n",
      "Starting epoch 362\n",
      "Train Loss: 0.03112935523192088\n",
      "Val Loss: 0.030823224672564754\n",
      "Starting epoch 363\n",
      "Train Loss: 0.031056225299835205\n",
      "Val Loss: 0.03090234045629148\n",
      "Starting epoch 364\n",
      "Train Loss: 0.031131662704326487\n",
      "Val Loss: 0.03054395318031311\n",
      "Starting epoch 365\n",
      "Train Loss: 0.030723535904177913\n",
      "Val Loss: 0.030471321609285142\n",
      "Starting epoch 366\n",
      "Train Loss: 0.031453095100544115\n",
      "Val Loss: 0.03032059360433508\n",
      "Starting epoch 367\n",
      "Train Loss: 0.031352476941214666\n",
      "Val Loss: 0.03046987730043906\n",
      "Starting epoch 368\n",
      "Train Loss: 0.03089380098713769\n",
      "Val Loss: 0.030869626888522395\n",
      "Starting epoch 369\n",
      "Train Loss: 0.03070902548454426\n",
      "Val Loss: 0.030587026366481074\n",
      "Starting epoch 370\n",
      "Train Loss: 0.0312609749811667\n",
      "Val Loss: 0.030429537649507874\n",
      "Starting epoch 371\n",
      "Train Loss: 0.030958323567001907\n",
      "Val Loss: 0.030990597274568345\n",
      "Starting epoch 372\n",
      "Train Loss: 0.031000763177871704\n",
      "Val Loss: 0.030604757644512034\n",
      "Starting epoch 373\n",
      "Train Loss: 0.030992791608527855\n",
      "Val Loss: 0.0302060533452917\n",
      "Starting epoch 374\n",
      "Train Loss: 0.030934308414106017\n",
      "Val Loss: 0.031109807116013986\n",
      "Starting epoch 375\n",
      "Train Loss: 0.031212068266338773\n",
      "Val Loss: 0.030469173082598933\n",
      "Starting epoch 376\n",
      "Train Loss: 0.030898194622110436\n",
      "Val Loss: 0.030560838403525175\n",
      "Starting epoch 377\n",
      "Train Loss: 0.03063461791585993\n",
      "Val Loss: 0.031095553879384643\n",
      "Starting epoch 378\n",
      "Train Loss: 0.030984687584417837\n",
      "Val Loss: 0.03105474015076955\n",
      "Starting epoch 379\n",
      "Train Loss: 0.030769714050822787\n",
      "Val Loss: 0.03062738147046831\n",
      "Starting epoch 380\n",
      "Train Loss: 0.03016163905461629\n",
      "Val Loss: 0.030500804936444317\n",
      "Starting epoch 381\n",
      "Train Loss: 0.03012064927154117\n",
      "Val Loss: 0.030192469557126362\n",
      "Starting epoch 382\n",
      "Train Loss: 0.030665201721368014\n",
      "Val Loss: 0.03085192762039326\n",
      "Starting epoch 383\n",
      "Train Loss: 0.03044896931559951\n",
      "Val Loss: 0.030817806720733643\n",
      "Starting epoch 384\n",
      "Train Loss: 0.030220059884919062\n",
      "Val Loss: 0.030443954247015494\n",
      "Starting epoch 385\n",
      "Train Loss: 0.0304564634958903\n",
      "Val Loss: 0.029964701996909246\n",
      "Starting epoch 386\n",
      "Train Loss: 0.03016101486153073\n",
      "Val Loss: 0.030537453514558298\n",
      "Starting epoch 387\n",
      "Train Loss: 0.030594955439920777\n",
      "Val Loss: 0.030735367426165828\n",
      "Starting epoch 388\n",
      "Train Loss: 0.03075145681699117\n",
      "Val Loss: 0.030792077934300457\n",
      "Starting epoch 389\n",
      "Train Loss: 0.030429621537526447\n",
      "Val Loss: 0.030655229533160175\n",
      "Starting epoch 390\n",
      "Train Loss: 0.031103083932841266\n",
      "Val Loss: 0.03034688201215532\n",
      "Starting epoch 391\n",
      "Train Loss: 0.031062892741627164\n",
      "Val Loss: 0.030200808688446327\n",
      "Starting epoch 392\n",
      "Train Loss: 0.030157569933820655\n",
      "Val Loss: 0.030576578444904752\n",
      "Starting epoch 393\n",
      "Train Loss: 0.03009577537024463\n",
      "Val Loss: 0.03073450039934229\n",
      "Starting epoch 394\n",
      "Train Loss: 0.030003168516688876\n",
      "Val Loss: 0.030297725288956252\n",
      "Starting epoch 395\n",
      "Train Loss: 0.030388552833486487\n",
      "Val Loss: 0.030244603201195045\n",
      "Starting epoch 396\n",
      "Train Loss: 0.03032068853025083\n",
      "Val Loss: 0.030256508125199214\n",
      "Starting epoch 397\n",
      "Train Loss: 0.03023819735756627\n",
      "Val Loss: 0.03028125564257304\n",
      "Starting epoch 398\n",
      "Train Loss: 0.03041634570669245\n",
      "Val Loss: 0.029933560225698683\n",
      "Starting epoch 399\n",
      "Train Loss: 0.030499399812133225\n",
      "Val Loss: 0.030613665227536804\n",
      "Starting epoch 400\n",
      "Train Loss: 0.030397600597805448\n",
      "Val Loss: 0.029824057111033687\n",
      "Starting epoch 401\n",
      "Train Loss: 0.03016195363468594\n",
      "Val Loss: 0.030345564087231953\n",
      "Starting epoch 402\n",
      "Train Loss: 0.03065265052848392\n",
      "Val Loss: 0.029895669884151883\n",
      "Starting epoch 403\n",
      "Train Loss: 0.029918272186208655\n",
      "Val Loss: 0.030030685994360182\n",
      "Starting epoch 404\n",
      "Train Loss: 0.02945831031711013\n",
      "Val Loss: 0.029934612689194857\n",
      "Starting epoch 405\n",
      "Train Loss: 0.030228907863299053\n",
      "Val Loss: 0.030276061208159837\n",
      "Starting epoch 406\n",
      "Train Loss: 0.030036435635001572\n",
      "Val Loss: 0.030487923158539668\n",
      "Starting epoch 407\n",
      "Train Loss: 0.03040716548760732\n",
      "Val Loss: 0.030192911073013588\n",
      "Starting epoch 408\n",
      "Train Loss: 0.030462968128698843\n",
      "Val Loss: 0.0297014315923055\n",
      "Starting epoch 409\n",
      "Train Loss: 0.029862386208993418\n",
      "Val Loss: 0.03031308893804197\n",
      "Starting epoch 410\n",
      "Train Loss: 0.02978251156983552\n",
      "Val Loss: 0.030221242595601966\n",
      "Starting epoch 411\n",
      "Train Loss: 0.03009557944756967\n",
      "Val Loss: 0.03001671091273979\n",
      "Starting epoch 412\n",
      "Train Loss: 0.030049834538389136\n",
      "Val Loss: 0.030186843540933397\n",
      "Starting epoch 413\n",
      "Train Loss: 0.03040352463722229\n",
      "Val Loss: 0.029495988731031066\n",
      "Starting epoch 414\n",
      "Train Loss: 0.030015364841178612\n",
      "Val Loss: 0.029863084355990093\n",
      "Starting epoch 415\n",
      "Train Loss: 0.029921544922722712\n",
      "Val Loss: 0.029751126412992126\n",
      "Starting epoch 416\n",
      "Train Loss: 0.030180293100851553\n",
      "Val Loss: 0.030013691495966027\n",
      "Starting epoch 417\n",
      "Train Loss: 0.029902596716527587\n",
      "Val Loss: 0.03011139178717578\n",
      "Starting epoch 418\n",
      "Train Loss: 0.030554747139966046\n",
      "Val Loss: 0.030266954391090957\n",
      "Starting epoch 419\n",
      "Train Loss: 0.029973459464532358\n",
      "Val Loss: 0.029826298356056213\n",
      "Starting epoch 420\n",
      "Train Loss: 0.02986086905002594\n",
      "Val Loss: 0.02937002424840574\n",
      "Starting epoch 421\n",
      "Train Loss: 0.029793100776495756\n",
      "Val Loss: 0.029906812641355727\n",
      "Starting epoch 422\n",
      "Train Loss: 0.029900757802857295\n",
      "Val Loss: 0.029839491954556218\n",
      "Starting epoch 423\n",
      "Train Loss: 0.029817459207993967\n",
      "Val Loss: 0.029423066863307246\n",
      "Starting epoch 424\n",
      "Train Loss: 0.030155791728584853\n",
      "Val Loss: 0.029058167779887165\n",
      "Starting epoch 425\n",
      "Train Loss: 0.02962948547469245\n",
      "Val Loss: 0.029884217513932124\n",
      "Starting epoch 426\n",
      "Train Loss: 0.030109291275342304\n",
      "Val Loss: 0.02979387950014185\n",
      "Starting epoch 427\n",
      "Train Loss: 0.029597215630390025\n",
      "Val Loss: 0.029901593923568726\n",
      "Starting epoch 428\n",
      "Train Loss: 0.02979464332262675\n",
      "Val Loss: 0.029625760184393987\n",
      "Starting epoch 429\n",
      "Train Loss: 0.029535070061683655\n",
      "Val Loss: 0.029932488997777302\n",
      "Starting epoch 430\n",
      "Train Loss: 0.030043988868042274\n",
      "Val Loss: 0.030015895764033\n",
      "Starting epoch 431\n",
      "Train Loss: 0.029783479593418264\n",
      "Val Loss: 0.029619236787160236\n",
      "Starting epoch 432\n",
      "Train Loss: 0.02962108177167398\n",
      "Val Loss: 0.02982227283495444\n",
      "Starting epoch 433\n",
      "Train Loss: 0.029481227199236553\n",
      "Val Loss: 0.030301858981450398\n",
      "Starting epoch 434\n",
      "Train Loss: 0.030090163703317994\n",
      "Val Loss: 0.029567279749446444\n",
      "Starting epoch 435\n",
      "Train Loss: 0.029685707555876836\n",
      "Val Loss: 0.029636234045028687\n",
      "Starting epoch 436\n",
      "Train Loss: 0.029530329284844576\n",
      "Val Loss: 0.029883697628974915\n",
      "Starting epoch 437\n",
      "Train Loss: 0.029789420741575735\n",
      "Val Loss: 0.029835415659127413\n",
      "Starting epoch 438\n",
      "Train Loss: 0.02944629942929303\n",
      "Val Loss: 0.029531082069432293\n",
      "Starting epoch 439\n",
      "Train Loss: 0.03002620405620999\n",
      "Val Loss: 0.02921541200743781\n",
      "Starting epoch 440\n",
      "Train Loss: 0.02983099001425284\n",
      "Val Loss: 0.029869914606765465\n",
      "Starting epoch 441\n",
      "Train Loss: 0.030197998991719\n",
      "Val Loss: 0.029113122158580355\n",
      "Starting epoch 442\n",
      "Train Loss: 0.029859679164709867\n",
      "Val Loss: 0.030063628598495765\n",
      "Starting epoch 443\n",
      "Train Loss: 0.029422378650418034\n",
      "Val Loss: 0.029820844531059265\n",
      "Starting epoch 444\n",
      "Train Loss: 0.0291821895926087\n",
      "Val Loss: 0.02960742292580781\n",
      "Starting epoch 445\n",
      "Train Loss: 0.02944883207480113\n",
      "Val Loss: 0.029118650489383273\n",
      "Starting epoch 446\n",
      "Train Loss: 0.029514484935336642\n",
      "Val Loss: 0.029906557114035996\n",
      "Starting epoch 447\n",
      "Train Loss: 0.029426441148475365\n",
      "Val Loss: 0.02920514124411124\n",
      "Starting epoch 448\n",
      "Train Loss: 0.02937347579885412\n",
      "Val Loss: 0.029135817178973445\n",
      "Starting epoch 449\n",
      "Train Loss: 0.02903231260953126\n",
      "Val Loss: 0.029298782348632812\n",
      "Starting epoch 450\n",
      "Train Loss: 0.029481933624656113\n",
      "Val Loss: 0.029327949440037762\n",
      "Starting epoch 451\n",
      "Train Loss: 0.02947886840060905\n",
      "Val Loss: 0.029134872334974783\n",
      "Starting epoch 452\n",
      "Train Loss: 0.029506512262203074\n",
      "Val Loss: 0.029231609569655523\n",
      "Starting epoch 453\n",
      "Train Loss: 0.029553284799611126\n",
      "Val Loss: 0.02919355752291503\n",
      "Starting epoch 454\n",
      "Train Loss: 0.029297697875234816\n",
      "Val Loss: 0.029459619411715755\n",
      "Starting epoch 455\n",
      "Train Loss: 0.02954839611494983\n",
      "Val Loss: 0.029941260814666748\n",
      "Starting epoch 456\n",
      "Train Loss: 0.029625973767704435\n",
      "Val Loss: 0.029211132062806025\n",
      "Starting epoch 457\n",
      "Train Loss: 0.02935928271876441\n",
      "Val Loss: 0.029159255049846792\n",
      "Starting epoch 458\n",
      "Train Loss: 0.029649402808260034\n",
      "Val Loss: 0.02890252846258658\n",
      "Starting epoch 459\n",
      "Train Loss: 0.029443355622114958\n",
      "Val Loss: 0.02917654701956996\n",
      "Starting epoch 460\n",
      "Train Loss: 0.02963475110354247\n",
      "Val Loss: 0.029764990011850994\n",
      "Starting epoch 461\n",
      "Train Loss: 0.029218185830999305\n",
      "Val Loss: 0.029422099391619366\n",
      "Starting epoch 462\n",
      "Train Loss: 0.02919466296831767\n",
      "Val Loss: 0.028895985197137902\n",
      "Starting epoch 463\n",
      "Train Loss: 0.02923979527420468\n",
      "Val Loss: 0.02929913721702717\n",
      "Starting epoch 464\n",
      "Train Loss: 0.029481782405464736\n",
      "Val Loss: 0.029169240483531245\n",
      "Starting epoch 465\n",
      "Train Loss: 0.029437540305985346\n",
      "Val Loss: 0.02921892868147956\n",
      "Starting epoch 466\n",
      "Train Loss: 0.02935254794579965\n",
      "Val Loss: 0.029406560791863337\n",
      "Starting epoch 467\n",
      "Train Loss: 0.02891732973081094\n",
      "Val Loss: 0.02889154133973298\n",
      "Starting epoch 468\n",
      "Train Loss: 0.028758442512264958\n",
      "Val Loss: 0.02917733015837493\n",
      "Starting epoch 469\n",
      "Train Loss: 0.02897419090624209\n",
      "Val Loss: 0.02901063914652224\n",
      "Starting epoch 470\n",
      "Train Loss: 0.028768529494603474\n",
      "Val Loss: 0.028910724101243197\n",
      "Starting epoch 471\n",
      "Train Loss: 0.028946151887928998\n",
      "Val Loss: 0.028685584112449928\n",
      "Starting epoch 472\n",
      "Train Loss: 0.02937931595025239\n",
      "Val Loss: 0.0292084206033636\n",
      "Starting epoch 473\n",
      "Train Loss: 0.028670732621793395\n",
      "Val Loss: 0.029028987994900456\n",
      "Starting epoch 474\n",
      "Train Loss: 0.028927098269815796\n",
      "Val Loss: 0.028911742899152968\n",
      "Starting epoch 475\n",
      "Train Loss: 0.029094713705557364\n",
      "Val Loss: 0.02878428609282882\n",
      "Starting epoch 476\n",
      "Train Loss: 0.028577463494406805\n",
      "Val Loss: 0.028933856774259498\n",
      "Starting epoch 477\n",
      "Train Loss: 0.029061184989081487\n",
      "Val Loss: 0.028817819776358427\n",
      "Starting epoch 478\n",
      "Train Loss: 0.02875018561327899\n",
      "Val Loss: 0.028918269607755873\n",
      "Starting epoch 479\n",
      "Train Loss: 0.028821882826310617\n",
      "Val Loss: 0.028392556640836928\n",
      "Starting epoch 480\n",
      "Train Loss: 0.029654577926353173\n",
      "Val Loss: 0.029153669873873394\n",
      "Starting epoch 481\n",
      "Train Loss: 0.02893769961816293\n",
      "Val Loss: 0.029279145929548476\n",
      "Starting epoch 482\n",
      "Train Loss: 0.028751362253118445\n",
      "Val Loss: 0.029100091920958623\n",
      "Starting epoch 483\n",
      "Train Loss: 0.028708672633877507\n",
      "Val Loss: 0.02884433501296573\n",
      "Starting epoch 484\n",
      "Train Loss: 0.02863581313027276\n",
      "Val Loss: 0.028631984083740798\n",
      "Starting epoch 485\n",
      "Train Loss: 0.028459876775741577\n",
      "Val Loss: 0.0287539506400073\n",
      "Starting epoch 486\n",
      "Train Loss: 0.02891665421150349\n",
      "Val Loss: 0.028752878860191063\n",
      "Starting epoch 487\n",
      "Train Loss: 0.02847520179218716\n",
      "Val Loss: 0.02853216893143124\n",
      "Starting epoch 488\n",
      "Train Loss: 0.029018001423941717\n",
      "Val Loss: 0.029161074647197017\n",
      "Starting epoch 489\n",
      "Train Loss: 0.02868960577028769\n",
      "Val Loss: 0.028986705674065485\n",
      "Starting epoch 490\n",
      "Train Loss: 0.028373216037397033\n",
      "Val Loss: 0.028759132380838746\n",
      "Starting epoch 491\n",
      "Train Loss: 0.028774413797590468\n",
      "Val Loss: 0.028608353049666795\n",
      "Starting epoch 492\n",
      "Train Loss: 0.028679770452004892\n",
      "Val Loss: 0.028406308205039414\n",
      "Starting epoch 493\n",
      "Train Loss: 0.028785183473869606\n",
      "Val Loss: 0.028781918463883577\n",
      "Starting epoch 494\n",
      "Train Loss: 0.028727316194110446\n",
      "Val Loss: 0.028694194776040537\n",
      "Starting epoch 495\n",
      "Train Loss: 0.028728245585053054\n",
      "Val Loss: 0.02844559042542069\n",
      "Starting epoch 496\n",
      "Train Loss: 0.02874328030480279\n",
      "Val Loss: 0.02889250550005171\n",
      "Starting epoch 497\n",
      "Train Loss: 0.02865769852090765\n",
      "Val Loss: 0.0282114964944345\n",
      "Starting epoch 498\n",
      "Train Loss: 0.028643936470702843\n",
      "Val Loss: 0.028795656782609445\n",
      "Starting epoch 499\n",
      "Train Loss: 0.028622790067284194\n",
      "Val Loss: 0.028617899726938317\n",
      "Starting epoch 500\n",
      "Train Loss: 0.02827276896547388\n",
      "Val Loss: 0.02893364374284391\n",
      "Starting epoch 501\n",
      "Train Loss: 0.028923959643752488\n",
      "Val Loss: 0.028231516480445862\n",
      "Starting epoch 502\n",
      "Train Loss: 0.02824711247726723\n",
      "Val Loss: 0.027890362673335604\n",
      "Starting epoch 503\n",
      "Train Loss: 0.028473918084745056\n",
      "Val Loss: 0.028171631473082083\n",
      "Starting epoch 504\n",
      "Train Loss: 0.028276307715309992\n",
      "Val Loss: 0.028131806188159518\n",
      "Starting epoch 505\n",
      "Train Loss: 0.02845348748895857\n",
      "Val Loss: 0.028462863630718656\n",
      "Starting epoch 506\n",
      "Train Loss: 0.028820706186471163\n",
      "Val Loss: 0.028432420006504765\n",
      "Starting epoch 507\n",
      "Train Loss: 0.02861798416685175\n",
      "Val Loss: 0.0285579115152359\n",
      "Starting epoch 508\n",
      "Train Loss: 0.02832703678696244\n",
      "Val Loss: 0.028492786818080477\n",
      "Starting epoch 509\n",
      "Train Loss: 0.028328763665976347\n",
      "Val Loss: 0.028461232229515358\n",
      "Starting epoch 510\n",
      "Train Loss: 0.028704120605080215\n",
      "Val Loss: 0.028554569791864465\n",
      "Starting epoch 511\n",
      "Train Loss: 0.028086943758858576\n",
      "Val Loss: 0.02833620762383496\n",
      "Starting epoch 512\n",
      "Train Loss: 0.028016398902292603\n",
      "Val Loss: 0.02809600532054901\n",
      "Starting epoch 513\n",
      "Train Loss: 0.02829403899334095\n",
      "Val Loss: 0.028307542204856873\n",
      "Starting epoch 514\n",
      "Train Loss: 0.02792170423048514\n",
      "Val Loss: 0.028250653434682776\n",
      "Starting epoch 515\n",
      "Train Loss: 0.02825189906137961\n",
      "Val Loss: 0.028382844395107694\n",
      "Starting epoch 516\n",
      "Train Loss: 0.02814152505662706\n",
      "Val Loss: 0.027830728226237826\n",
      "Starting epoch 517\n",
      "Train Loss: 0.028431313457312406\n",
      "Val Loss: 0.02831390058552777\n",
      "Starting epoch 518\n",
      "Train Loss: 0.028189807026474563\n",
      "Val Loss: 0.028075040490538987\n",
      "Starting epoch 519\n",
      "Train Loss: 0.02849843159869865\n",
      "Val Loss: 0.028121340605947707\n",
      "Starting epoch 520\n",
      "Train Loss: 0.02807525959279802\n",
      "Val Loss: 0.02794936023376606\n",
      "Starting epoch 521\n",
      "Train Loss: 0.02821783114362646\n",
      "Val Loss: 0.02810557683308919\n",
      "Starting epoch 522\n",
      "Train Loss: 0.02843616516501815\n",
      "Val Loss: 0.02792358453626986\n",
      "Starting epoch 523\n",
      "Train Loss: 0.028064920394508926\n",
      "Val Loss: 0.027710953796351398\n",
      "Starting epoch 524\n",
      "Train Loss: 0.028065301753856516\n",
      "Val Loss: 0.02799818030110112\n",
      "Starting epoch 525\n",
      "Train Loss: 0.028142356210284762\n",
      "Val Loss: 0.028078328680109094\n",
      "Starting epoch 526\n",
      "Train Loss: 0.02755836425004182\n",
      "Val Loss: 0.028027930745372066\n",
      "Starting epoch 527\n",
      "Train Loss: 0.02787290734273416\n",
      "Val Loss: 0.027487699080396583\n",
      "Starting epoch 528\n",
      "Train Loss: 0.028227094698835303\n",
      "Val Loss: 0.028096839785575867\n",
      "Starting epoch 529\n",
      "Train Loss: 0.02812499028665048\n",
      "Val Loss: 0.027970818457780062\n",
      "Starting epoch 530\n",
      "Train Loss: 0.028259639386777526\n",
      "Val Loss: 0.028150224023395114\n",
      "Starting epoch 531\n",
      "Train Loss: 0.02811168134212494\n",
      "Val Loss: 0.027731414746355126\n",
      "Starting epoch 532\n",
      "Train Loss: 0.027877504626909893\n",
      "Val Loss: 0.027743161828429612\n",
      "Starting epoch 533\n",
      "Train Loss: 0.027611858866832876\n",
      "Val Loss: 0.028048301736513775\n",
      "Starting epoch 534\n",
      "Train Loss: 0.02831421571749228\n",
      "Val Loss: 0.02777547030537217\n",
      "Starting epoch 535\n",
      "Train Loss: 0.02800170139030174\n",
      "Val Loss: 0.027557884101514465\n",
      "Starting epoch 536\n",
      "Train Loss: 0.027322078744570415\n",
      "Val Loss: 0.027533860118300828\n",
      "Starting epoch 537\n",
      "Train Loss: 0.02771265032114806\n",
      "Val Loss: 0.027993699466740643\n",
      "Starting epoch 538\n",
      "Train Loss: 0.02773013103891302\n",
      "Val Loss: 0.027913786746837473\n",
      "Starting epoch 539\n",
      "Train Loss: 0.02782030955508903\n",
      "Val Loss: 0.027925102247132197\n",
      "Starting epoch 540\n",
      "Train Loss: 0.027499263485272724\n",
      "Val Loss: 0.028000298473570082\n",
      "Starting epoch 541\n",
      "Train Loss: 0.02771863396520968\n",
      "Val Loss: 0.02775139444404178\n",
      "Starting epoch 542\n",
      "Train Loss: 0.02808186522236577\n",
      "Val Loss: 0.02736443391552678\n",
      "Starting epoch 543\n",
      "Train Loss: 0.027585500920260395\n",
      "Val Loss: 0.027449266226203355\n",
      "Starting epoch 544\n",
      "Train Loss: 0.027541171621393273\n",
      "Val Loss: 0.02782032335246051\n",
      "Starting epoch 545\n",
      "Train Loss: 0.02747563631446273\n",
      "Val Loss: 0.027557694249682956\n",
      "Starting epoch 546\n",
      "Train Loss: 0.027564565892572754\n",
      "Val Loss: 0.02794466471230542\n",
      "Starting epoch 547\n",
      "Train Loss: 0.027743370996581182\n",
      "Val Loss: 0.028036234555421053\n",
      "Starting epoch 548\n",
      "Train Loss: 0.02737755963095912\n",
      "Val Loss: 0.027819009842696012\n",
      "Starting epoch 549\n",
      "Train Loss: 0.02760715009989562\n",
      "Val Loss: 0.02766664491759406\n",
      "Starting epoch 550\n",
      "Train Loss: 0.027693410714467365\n",
      "Val Loss: 0.02746157513724433\n",
      "Starting epoch 551\n",
      "Train Loss: 0.027864014108975727\n",
      "Val Loss: 0.02756786291246061\n",
      "Starting epoch 552\n",
      "Train Loss: 0.02744989924960666\n",
      "Val Loss: 0.02740789066862177\n",
      "Starting epoch 553\n",
      "Train Loss: 0.02719488850346318\n",
      "Val Loss: 0.027922248398816144\n",
      "Starting epoch 554\n",
      "Train Loss: 0.027514904737472534\n",
      "Val Loss: 0.02762866461718524\n",
      "Starting epoch 555\n",
      "Train Loss: 0.027584988761831214\n",
      "Val Loss: 0.027540657807279517\n",
      "Starting epoch 556\n",
      "Train Loss: 0.02765367207703767\n",
      "Val Loss: 0.02742167920977981\n",
      "Starting epoch 557\n",
      "Train Loss: 0.027275840993280762\n",
      "Val Loss: 0.027768629016699613\n",
      "Starting epoch 558\n",
      "Train Loss: 0.027570572164323594\n",
      "Val Loss: 0.02759015946476548\n",
      "Starting epoch 559\n",
      "Train Loss: 0.027397903027357878\n",
      "Val Loss: 0.027543279859754775\n",
      "Starting epoch 560\n",
      "Train Loss: 0.027577397448045236\n",
      "Val Loss: 0.027509507757646066\n",
      "Starting epoch 561\n",
      "Train Loss: 0.02733740817617487\n",
      "Val Loss: 0.02728315911911152\n",
      "Starting epoch 562\n",
      "Train Loss: 0.02731064513877586\n",
      "Val Loss: 0.027375400618270592\n",
      "Starting epoch 563\n",
      "Train Loss: 0.02735550867186652\n",
      "Val Loss: 0.027025562193658616\n",
      "Starting epoch 564\n",
      "Train Loss: 0.027508335532965483\n",
      "Val Loss: 0.027198488513628643\n",
      "Starting epoch 565\n",
      "Train Loss: 0.02722355944138986\n",
      "Val Loss: 0.02724638470896968\n",
      "Starting epoch 566\n",
      "Train Loss: 0.027469931377304926\n",
      "Val Loss: 0.027409608165423077\n",
      "Starting epoch 567\n",
      "Train Loss: 0.02740350420828219\n",
      "Val Loss: 0.027252676862257498\n",
      "Starting epoch 568\n",
      "Train Loss: 0.02746755215856764\n",
      "Val Loss: 0.027008514713357995\n",
      "Starting epoch 569\n",
      "Train Loss: 0.02733300902225353\n",
      "Val Loss: 0.027213876446088154\n",
      "Starting epoch 570\n",
      "Train Loss: 0.027579147506643226\n",
      "Val Loss: 0.027392428782251146\n",
      "Starting epoch 571\n",
      "Train Loss: 0.027690044707722135\n",
      "Val Loss: 0.027177318930625916\n",
      "Starting epoch 572\n",
      "Train Loss: 0.027390007619504577\n",
      "Val Loss: 0.02733852465947469\n",
      "Starting epoch 573\n",
      "Train Loss: 0.027368334156495554\n",
      "Val Loss: 0.027415367188277067\n",
      "Starting epoch 574\n",
      "Train Loss: 0.027511238499923988\n",
      "Val Loss: 0.027490989477546128\n",
      "Starting epoch 575\n",
      "Train Loss: 0.027012019245712844\n",
      "Val Loss: 0.026855290487960534\n",
      "Starting epoch 576\n",
      "Train Loss: 0.027661532715514855\n",
      "Val Loss: 0.027317721534658362\n",
      "Starting epoch 577\n",
      "Train Loss: 0.027059944139586553\n",
      "Val Loss: 0.02691237849217874\n",
      "Starting epoch 578\n",
      "Train Loss: 0.027452809943093195\n",
      "Val Loss: 0.02742625386626632\n",
      "Starting epoch 579\n",
      "Train Loss: 0.02709063059753842\n",
      "Val Loss: 0.027359210782580905\n",
      "Starting epoch 580\n",
      "Train Loss: 0.027221089160000836\n",
      "Val Loss: 0.027049819076502765\n",
      "Starting epoch 581\n",
      "Train Loss: 0.027303823718318233\n",
      "Val Loss: 0.0269734600075969\n",
      "Starting epoch 582\n",
      "Train Loss: 0.0269073866031788\n",
      "Val Loss: 0.026878247658411663\n",
      "Starting epoch 583\n",
      "Train Loss: 0.027263960904545255\n",
      "Val Loss: 0.02736819949414995\n",
      "Starting epoch 584\n",
      "Train Loss: 0.02696654807638239\n",
      "Val Loss: 0.027055760224660236\n",
      "Starting epoch 585\n",
      "Train Loss: 0.026819507280985515\n",
      "Val Loss: 0.027317002415657043\n",
      "Starting epoch 586\n",
      "Train Loss: 0.02730269840470067\n",
      "Val Loss: 0.027076541825577064\n",
      "Starting epoch 587\n",
      "Train Loss: 0.026942466144208557\n",
      "Val Loss: 0.027333364994437608\n",
      "Starting epoch 588\n",
      "Train Loss: 0.02713433184005596\n",
      "Val Loss: 0.02675788104534149\n",
      "Starting epoch 589\n",
      "Train Loss: 0.02716930596916764\n",
      "Val Loss: 0.026995187004407246\n",
      "Starting epoch 590\n",
      "Train Loss: 0.02718490086219929\n",
      "Val Loss: 0.02676225315641474\n",
      "Starting epoch 591\n",
      "Train Loss: 0.027564418536645395\n",
      "Val Loss: 0.027080513260982656\n",
      "Starting epoch 592\n",
      "Train Loss: 0.027405619069381996\n",
      "Val Loss: 0.02725837959183587\n",
      "Starting epoch 593\n",
      "Train Loss: 0.026471442094555608\n",
      "Val Loss: 0.02700956165790558\n",
      "Starting epoch 594\n",
      "Train Loss: 0.027092917649834243\n",
      "Val Loss: 0.026746949111973797\n",
      "Starting epoch 595\n",
      "Train Loss: 0.027367380482179147\n",
      "Val Loss: 0.02698488367928399\n",
      "Starting epoch 596\n",
      "Train Loss: 0.026930426005963928\n",
      "Val Loss: 0.02701784008079105\n",
      "Starting epoch 597\n",
      "Train Loss: 0.026909813284873962\n",
      "Val Loss: 0.026796722853625263\n",
      "Starting epoch 598\n",
      "Train Loss: 0.026924280656708613\n",
      "Val Loss: 0.026926940238034283\n",
      "Starting epoch 599\n",
      "Train Loss: 0.026839085751109652\n",
      "Val Loss: 0.026926558326791833\n",
      "Starting epoch 600\n",
      "Train Loss: 0.02676740178355464\n",
      "Val Loss: 0.026751674987651682\n",
      "Starting epoch 601\n",
      "Train Loss: 0.026873027284940083\n",
      "Val Loss: 0.026567966297820763\n",
      "Starting epoch 602\n",
      "Train Loss: 0.02638767770043126\n",
      "Val Loss: 0.026724102872389334\n",
      "Starting epoch 603\n",
      "Train Loss: 0.027261497797789396\n",
      "Val Loss: 0.027181767203189707\n",
      "Starting epoch 604\n",
      "Train Loss: 0.02696465066185704\n",
      "Val Loss: 0.027217608911019785\n",
      "Starting epoch 605\n",
      "Train Loss: 0.02676532389941039\n",
      "Val Loss: 0.0272213375126874\n",
      "Starting epoch 606\n",
      "Train Loss: 0.026708365038589196\n",
      "Val Loss: 0.02720202836725447\n",
      "Starting epoch 607\n",
      "Train Loss: 0.026991414803045767\n",
      "Val Loss: 0.027054091294606526\n",
      "Starting epoch 608\n",
      "Train Loss: 0.026620024884188617\n",
      "Val Loss: 0.02657429377237956\n",
      "Starting epoch 609\n",
      "Train Loss: 0.026732476221190557\n",
      "Val Loss: 0.027130635800185026\n",
      "Starting epoch 610\n",
      "Train Loss: 0.02687093946668837\n",
      "Val Loss: 0.026929448048273723\n",
      "Starting epoch 611\n",
      "Train Loss: 0.026785840038900024\n",
      "Val Loss: 0.026791856796653184\n",
      "Starting epoch 612\n",
      "Train Loss: 0.026948157835889747\n",
      "Val Loss: 0.0268117211483143\n",
      "Starting epoch 613\n",
      "Train Loss: 0.02649797609558812\n",
      "Val Loss: 0.02659252451525794\n",
      "Starting epoch 614\n",
      "Train Loss: 0.026840381600238657\n",
      "Val Loss: 0.026655196039764968\n",
      "Starting epoch 615\n",
      "Train Loss: 0.026699021458625793\n",
      "Val Loss: 0.026711691860799438\n",
      "Starting epoch 616\n",
      "Train Loss: 0.0265662454896503\n",
      "Val Loss: 0.026501534161744295\n",
      "Starting epoch 617\n",
      "Train Loss: 0.026866348253356084\n",
      "Val Loss: 0.026526854545981797\n",
      "Starting epoch 618\n",
      "Train Loss: 0.026488006114959717\n",
      "Val Loss: 0.026398819905740244\n",
      "Starting epoch 619\n",
      "Train Loss: 0.02698815531200833\n",
      "Val Loss: 0.026947136830400537\n",
      "Starting epoch 620\n",
      "Train Loss: 0.026719399072505808\n",
      "Val Loss: 0.026411728726492986\n",
      "Starting epoch 621\n",
      "Train Loss: 0.026708422987549392\n",
      "Val Loss: 0.02657336272575237\n",
      "Starting epoch 622\n",
      "Train Loss: 0.026828041783085576\n",
      "Val Loss: 0.02661287232681557\n",
      "Starting epoch 623\n",
      "Train Loss: 0.02643107098561746\n",
      "Val Loss: 0.026565646131833393\n",
      "Starting epoch 624\n",
      "Train Loss: 0.026731940883177298\n",
      "Val Loss: 0.026705162944617094\n",
      "Starting epoch 625\n",
      "Train Loss: 0.02680847269517404\n",
      "Val Loss: 0.0268693588398121\n",
      "Starting epoch 626\n",
      "Train Loss: 0.0264944886719739\n",
      "Val Loss: 0.026546533460970276\n",
      "Starting epoch 627\n",
      "Train Loss: 0.026392568040777137\n",
      "Val Loss: 0.0263850219823696\n",
      "Starting epoch 628\n",
      "Train Loss: 0.02642084437387961\n",
      "Val Loss: 0.026181659212818852\n",
      "Starting epoch 629\n",
      "Train Loss: 0.026344283863350196\n",
      "Val Loss: 0.026441839558106882\n",
      "Starting epoch 630\n",
      "Train Loss: 0.026329959984178895\n",
      "Val Loss: 0.02687637452726011\n",
      "Starting epoch 631\n",
      "Train Loss: 0.026407497348608793\n",
      "Val Loss: 0.026535167186348525\n",
      "Starting epoch 632\n",
      "Train Loss: 0.02656618312553123\n",
      "Val Loss: 0.02699270678891076\n",
      "Starting epoch 633\n",
      "Train Loss: 0.026404021514786616\n",
      "Val Loss: 0.026477165244243765\n",
      "Starting epoch 634\n",
      "Train Loss: 0.026549810612643207\n",
      "Val Loss: 0.02696557894900993\n",
      "Starting epoch 635\n",
      "Train Loss: 0.026417266439508508\n",
      "Val Loss: 0.02650330243287263\n",
      "Starting epoch 636\n",
      "Train Loss: 0.026911486630086547\n",
      "Val Loss: 0.02647628993899734\n",
      "Starting epoch 637\n",
      "Train Loss: 0.026460023941817106\n",
      "Val Loss: 0.026214894873124582\n",
      "Starting epoch 638\n",
      "Train Loss: 0.026144034332699247\n",
      "Val Loss: 0.026393925702130352\n",
      "Starting epoch 639\n",
      "Train Loss: 0.02680756813950009\n",
      "Val Loss: 0.026509876052538555\n",
      "Starting epoch 640\n",
      "Train Loss: 0.026283809432276973\n",
      "Val Loss: 0.026394615570704143\n",
      "Starting epoch 641\n",
      "Train Loss: 0.026349925884494075\n",
      "Val Loss: 0.02650452708756482\n",
      "Starting epoch 642\n",
      "Train Loss: 0.02650672086962947\n",
      "Val Loss: 0.026134997054382606\n",
      "Starting epoch 643\n",
      "Train Loss: 0.02655281678394035\n",
      "Val Loss: 0.026804292643511737\n",
      "Starting epoch 644\n",
      "Train Loss: 0.02649399803744422\n",
      "Val Loss: 0.026168456784001103\n",
      "Starting epoch 645\n",
      "Train Loss: 0.02645393157446826\n",
      "Val Loss: 0.026216778490278456\n",
      "Starting epoch 646\n",
      "Train Loss: 0.026393941707081266\n",
      "Val Loss: 0.026678474964918913\n",
      "Starting epoch 647\n",
      "Train Loss: 0.026082422998216417\n",
      "Val Loss: 0.02635341661947745\n",
      "Starting epoch 648\n",
      "Train Loss: 0.026333676444159612\n",
      "Val Loss: 0.026276742418607075\n",
      "Starting epoch 649\n",
      "Train Loss: 0.02674968264721058\n",
      "Val Loss: 0.026267551161624766\n",
      "Starting epoch 650\n",
      "Train Loss: 0.026059575654842234\n",
      "Val Loss: 0.026316007530247723\n",
      "Starting epoch 651\n",
      "Train Loss: 0.026225566312118812\n",
      "Val Loss: 0.026244175654870493\n",
      "Starting epoch 652\n",
      "Train Loss: 0.026253536895469384\n",
      "Val Loss: 0.02636140419377221\n",
      "Starting epoch 653\n",
      "Train Loss: 0.026181322005059984\n",
      "Val Loss: 0.026174419456058078\n",
      "Starting epoch 654\n",
      "Train Loss: 0.026035086424262437\n",
      "Val Loss: 0.025986458968233178\n",
      "Starting epoch 655\n",
      "Train Loss: 0.026017372806866963\n",
      "Val Loss: 0.026358701012752676\n",
      "Starting epoch 656\n",
      "Train Loss: 0.026530382257920725\n",
      "Val Loss: 0.026115488674905565\n",
      "Starting epoch 657\n",
      "Train Loss: 0.0263959605384756\n",
      "Val Loss: 0.026038839861198707\n",
      "Starting epoch 658\n",
      "Train Loss: 0.02618569963508182\n",
      "Val Loss: 0.026002488754413747\n",
      "Starting epoch 659\n",
      "Train Loss: 0.02620353411745142\n",
      "Val Loss: 0.02644563493905244\n",
      "Starting epoch 660\n",
      "Train Loss: 0.025977476879402443\n",
      "Val Loss: 0.02615310748418172\n",
      "Starting epoch 661\n",
      "Train Loss: 0.026176074036845454\n",
      "Val Loss: 0.025784187294818735\n",
      "Starting epoch 662\n",
      "Train Loss: 0.02575994696882036\n",
      "Val Loss: 0.02610145785190441\n",
      "Starting epoch 663\n",
      "Train Loss: 0.02661594914065467\n",
      "Val Loss: 0.026165413083853544\n",
      "Starting epoch 664\n",
      "Train Loss: 0.025825396180152893\n",
      "Val Loss: 0.025855076533776743\n",
      "Starting epoch 665\n",
      "Train Loss: 0.026042261057429843\n",
      "Val Loss: 0.02580345008108351\n",
      "Starting epoch 666\n",
      "Train Loss: 0.026021879028390954\n",
      "Val Loss: 0.0262451845186728\n",
      "Starting epoch 667\n",
      "Train Loss: 0.025873616337776184\n",
      "Val Loss: 0.026033204462793138\n",
      "Starting epoch 668\n",
      "Train Loss: 0.0259396450387107\n",
      "Val Loss: 0.0262411970783163\n",
      "Starting epoch 669\n",
      "Train Loss: 0.025908681529539603\n",
      "Val Loss: 0.025980590670197097\n",
      "Starting epoch 670\n",
      "Train Loss: 0.025870691295023316\n",
      "Val Loss: 0.025751905308829412\n",
      "Starting epoch 671\n",
      "Train Loss: 0.025988243796207285\n",
      "Val Loss: 0.025943785905838013\n",
      "Starting epoch 672\n",
      "Train Loss: 0.02609082504555031\n",
      "Val Loss: 0.026142207560715853\n",
      "Starting epoch 673\n",
      "Train Loss: 0.025920580934595178\n",
      "Val Loss: 0.025928987948982803\n",
      "Starting epoch 674\n",
      "Train Loss: 0.026350940819139832\n",
      "Val Loss: 0.026153756512535944\n",
      "Starting epoch 675\n",
      "Train Loss: 0.025837115115589566\n",
      "Val Loss: 0.026008151747562266\n",
      "Starting epoch 676\n",
      "Train Loss: 0.025720322573626483\n",
      "Val Loss: 0.02597465669667279\n",
      "Starting epoch 677\n",
      "Train Loss: 0.025723745425542194\n",
      "Val Loss: 0.02592303576292815\n",
      "Starting epoch 678\n",
      "Train Loss: 0.025799376545129\n",
      "Val Loss: 0.02594289901079955\n",
      "Starting epoch 679\n",
      "Train Loss: 0.025608142217000324\n",
      "Val Loss: 0.025901484820577834\n",
      "Starting epoch 680\n",
      "Train Loss: 0.025870418107068097\n",
      "Val Loss: 0.025947736369238958\n",
      "Starting epoch 681\n",
      "Train Loss: 0.02606312268310123\n",
      "Val Loss: 0.025966586890044035\n",
      "Starting epoch 682\n",
      "Train Loss: 0.025992548024212872\n",
      "Val Loss: 0.0257510918158072\n",
      "Starting epoch 683\n",
      "Train Loss: 0.026215069823794894\n",
      "Val Loss: 0.025620402561293706\n",
      "Starting epoch 684\n",
      "Train Loss: 0.025773819397996972\n",
      "Val Loss: 0.025816865541316843\n",
      "Starting epoch 685\n",
      "Train Loss: 0.025419355542571458\n",
      "Val Loss: 0.025879234627441124\n",
      "Starting epoch 686\n",
      "Train Loss: 0.02578942643271552\n",
      "Val Loss: 0.025704698430167303\n",
      "Starting epoch 687\n",
      "Train Loss: 0.02589183549086253\n",
      "Val Loss: 0.02563328489109322\n",
      "Starting epoch 688\n",
      "Train Loss: 0.025563636311778316\n",
      "Val Loss: 0.026137521421467816\n",
      "Starting epoch 689\n",
      "Train Loss: 0.025903420867743315\n",
      "Val Loss: 0.025541235451345092\n",
      "Starting epoch 690\n",
      "Train Loss: 0.025901947308469703\n",
      "Val Loss: 0.02605854140387641\n",
      "Starting epoch 691\n",
      "Train Loss: 0.025876246668674326\n",
      "Val Loss: 0.025708289058120164\n",
      "Starting epoch 692\n",
      "Train Loss: 0.025864122642411128\n",
      "Val Loss: 0.025726869702339172\n",
      "Starting epoch 693\n",
      "Train Loss: 0.02570104212672622\n",
      "Val Loss: 0.025530851549572416\n",
      "Starting epoch 694\n",
      "Train Loss: 0.025627233915858798\n",
      "Val Loss: 0.02573124788425587\n",
      "Starting epoch 695\n",
      "Train Loss: 0.025651919621008414\n",
      "Val Loss: 0.025479624116862262\n",
      "Starting epoch 696\n",
      "Train Loss: 0.025970301142445317\n",
      "Val Loss: 0.025911912873939232\n",
      "Starting epoch 697\n",
      "Train Loss: 0.025341478210908396\n",
      "Val Loss: 0.02540609516479351\n",
      "Starting epoch 698\n",
      "Train Loss: 0.025677930977609422\n",
      "Val Loss: 0.026109625895818073\n",
      "Starting epoch 699\n",
      "Train Loss: 0.025817988095460116\n",
      "Val Loss: 0.025511443614959717\n",
      "Starting epoch 700\n",
      "Train Loss: 0.025866382099964\n",
      "Val Loss: 0.025525991011548926\n",
      "Starting epoch 701\n",
      "Train Loss: 0.02564731240272522\n",
      "Val Loss: 0.02560876696198075\n",
      "Starting epoch 702\n",
      "Train Loss: 0.025342727148974384\n",
      "Val Loss: 0.025825184252527025\n",
      "Starting epoch 703\n",
      "Train Loss: 0.025802387683479873\n",
      "Val Loss: 0.025623692406548396\n",
      "Starting epoch 704\n",
      "Train Loss: 0.025701724268771983\n",
      "Val Loss: 0.025750969847043354\n",
      "Starting epoch 705\n",
      "Train Loss: 0.025432613160875108\n",
      "Val Loss: 0.02547918646423905\n",
      "Starting epoch 706\n",
      "Train Loss: 0.025705208381017048\n",
      "Val Loss: 0.025638448971289175\n",
      "Starting epoch 707\n",
      "Train Loss: 0.02556564962422406\n",
      "Val Loss: 0.025516101055675082\n",
      "Starting epoch 708\n",
      "Train Loss: 0.02524529563056098\n",
      "Val Loss: 0.025572457247310214\n",
      "Starting epoch 709\n",
      "Train Loss: 0.02530715145446636\n",
      "Val Loss: 0.02545858257346683\n",
      "Starting epoch 710\n",
      "Train Loss: 0.025361317727300856\n",
      "Val Loss: 0.025481035312016804\n",
      "Starting epoch 711\n",
      "Train Loss: 0.025618643120483117\n",
      "Val Loss: 0.025316083320864925\n",
      "Starting epoch 712\n",
      "Train Loss: 0.025582689929891517\n",
      "Val Loss: 0.02549672568285907\n",
      "Starting epoch 713\n",
      "Train Loss: 0.025564270438971342\n",
      "Val Loss: 0.025466357668240864\n",
      "Starting epoch 714\n",
      "Train Loss: 0.025141968771263404\n",
      "Val Loss: 0.025339585763436777\n",
      "Starting epoch 715\n",
      "Train Loss: 0.02567649163581707\n",
      "Val Loss: 0.025617532156131887\n",
      "Starting epoch 716\n",
      "Train Loss: 0.025562316179275513\n",
      "Val Loss: 0.02549084358745151\n",
      "Starting epoch 717\n",
      "Train Loss: 0.02560197368816093\n",
      "Val Loss: 0.025517113230846548\n",
      "Starting epoch 718\n",
      "Train Loss: 0.025461635103932134\n",
      "Val Loss: 0.025581968051415903\n",
      "Starting epoch 719\n",
      "Train Loss: 0.025323621100849576\n",
      "Val Loss: 0.025517535982308565\n",
      "Starting epoch 720\n",
      "Train Loss: 0.02552116745048099\n",
      "Val Loss: 0.025257416345455027\n",
      "Starting epoch 721\n",
      "Train Loss: 0.025430513200936495\n",
      "Val Loss: 0.025811474632333825\n",
      "Starting epoch 722\n",
      "Train Loss: 0.025702829162279766\n",
      "Val Loss: 0.02520455199259299\n",
      "Starting epoch 723\n",
      "Train Loss: 0.025367072334995976\n",
      "Val Loss: 0.025712387429343328\n",
      "Starting epoch 724\n",
      "Train Loss: 0.025184241709885775\n",
      "Val Loss: 0.025299230659449543\n",
      "Starting epoch 725\n",
      "Train Loss: 0.025568865515567637\n",
      "Val Loss: 0.02540127436319987\n",
      "Starting epoch 726\n",
      "Train Loss: 0.025690468925016897\n",
      "Val Loss: 0.025412866362818965\n",
      "Starting epoch 727\n",
      "Train Loss: 0.025295512543784246\n",
      "Val Loss: 0.02534373104572296\n",
      "Starting epoch 728\n",
      "Train Loss: 0.025417263861055726\n",
      "Val Loss: 0.025527654974548904\n",
      "Starting epoch 729\n",
      "Train Loss: 0.024802805648909673\n",
      "Val Loss: 0.025173544883728027\n",
      "Starting epoch 730\n",
      "Train Loss: 0.025388609479974816\n",
      "Val Loss: 0.02552969698552732\n",
      "Starting epoch 731\n",
      "Train Loss: 0.025208498040835064\n",
      "Val Loss: 0.02549523115158081\n",
      "Starting epoch 732\n",
      "Train Loss: 0.02538046075238122\n",
      "Val Loss: 0.025489184039610403\n",
      "Starting epoch 733\n",
      "Train Loss: 0.02531264887915717\n",
      "Val Loss: 0.025295806703744112\n",
      "Starting epoch 734\n",
      "Train Loss: 0.025172536571820576\n",
      "Val Loss: 0.024973798129293654\n",
      "Starting epoch 735\n",
      "Train Loss: 0.02551451435795537\n",
      "Val Loss: 0.025319805299794232\n",
      "Starting epoch 736\n",
      "Train Loss: 0.02541984341762684\n",
      "Val Loss: 0.025435776622207078\n",
      "Starting epoch 737\n",
      "Train Loss: 0.025446675993778086\n",
      "Val Loss: 0.025419372099417227\n",
      "Starting epoch 738\n",
      "Train Loss: 0.025414428777164884\n",
      "Val Loss: 0.02555934919251336\n",
      "Starting epoch 739\n",
      "Train Loss: 0.025144698443236174\n",
      "Val Loss: 0.025196424788898893\n",
      "Starting epoch 740\n",
      "Train Loss: 0.025337518365294846\n",
      "Val Loss: 0.025188184998653555\n",
      "Starting epoch 741\n",
      "Train Loss: 0.025306398669878643\n",
      "Val Loss: 0.025197453520916128\n",
      "Starting epoch 742\n",
      "Train Loss: 0.025530044127393653\n",
      "Val Loss: 0.025334600497175147\n",
      "Starting epoch 743\n",
      "Train Loss: 0.025330988345322786\n",
      "Val Loss: 0.025227942400508456\n",
      "Starting epoch 744\n",
      "Train Loss: 0.025378371278444927\n",
      "Val Loss: 0.025326772420494643\n",
      "Starting epoch 745\n",
      "Train Loss: 0.025102459722095065\n",
      "Val Loss: 0.024820440897235164\n",
      "Starting epoch 746\n",
      "Train Loss: 0.025127780106332567\n",
      "Val Loss: 0.025040794301916053\n",
      "Starting epoch 747\n",
      "Train Loss: 0.024973318532661156\n",
      "Val Loss: 0.024908652460133587\n",
      "Starting epoch 748\n",
      "Train Loss: 0.02505234546131558\n",
      "Val Loss: 0.02521166095027217\n",
      "Starting epoch 749\n",
      "Train Loss: 0.025141408046086628\n",
      "Val Loss: 0.024937450885772705\n",
      "Starting epoch 750\n",
      "Train Loss: 0.025222273888411344\n",
      "Val Loss: 0.025094472699695163\n",
      "Starting epoch 751\n",
      "Train Loss: 0.024886221245483117\n",
      "Val Loss: 0.02514950986261721\n",
      "Starting epoch 752\n",
      "Train Loss: 0.025081821061946726\n",
      "Val Loss: 0.02512247970810643\n",
      "Starting epoch 753\n",
      "Train Loss: 0.024971039758788213\n",
      "Val Loss: 0.025402511711473817\n",
      "Starting epoch 754\n",
      "Train Loss: 0.024986081101276255\n",
      "Val Loss: 0.025154042575094435\n",
      "Starting epoch 755\n",
      "Train Loss: 0.025405567553308275\n",
      "Val Loss: 0.025438867233417654\n",
      "Starting epoch 756\n",
      "Train Loss: 0.025281754908738314\n",
      "Val Loss: 0.02517745174743511\n",
      "Starting epoch 757\n",
      "Train Loss: 0.0250910222530365\n",
      "Val Loss: 0.025349683783672475\n",
      "Starting epoch 758\n",
      "Train Loss: 0.024817354701183462\n",
      "Val Loss: 0.024904043586165818\n",
      "Starting epoch 759\n",
      "Train Loss: 0.024998579864148742\n",
      "Val Loss: 0.025083083245489333\n",
      "Starting epoch 760\n",
      "Train Loss: 0.025159979308093036\n",
      "Val Loss: 0.025249111431616324\n",
      "Starting epoch 761\n",
      "Train Loss: 0.025064814973760535\n",
      "Val Loss: 0.024935769814032095\n",
      "Starting epoch 762\n",
      "Train Loss: 0.025005413978188125\n",
      "Val Loss: 0.02498516164444111\n",
      "Starting epoch 763\n",
      "Train Loss: 0.024854838848114014\n",
      "Val Loss: 0.024818273606123747\n",
      "Starting epoch 764\n",
      "Train Loss: 0.024949771938500582\n",
      "Val Loss: 0.024793819696814927\n",
      "Starting epoch 765\n",
      "Train Loss: 0.025170114857179147\n",
      "Val Loss: 0.025331734507172195\n",
      "Starting epoch 766\n",
      "Train Loss: 0.02482746817447521\n",
      "Val Loss: 0.025165746609369915\n",
      "Starting epoch 767\n",
      "Train Loss: 0.025245463958492986\n",
      "Val Loss: 0.0251475903722975\n",
      "Starting epoch 768\n",
      "Train Loss: 0.024881606300671894\n",
      "Val Loss: 0.0249082926246855\n",
      "Starting epoch 769\n",
      "Train Loss: 0.024842761732913828\n",
      "Val Loss: 0.02486024686583766\n",
      "Starting epoch 770\n",
      "Train Loss: 0.024783654897301284\n",
      "Val Loss: 0.02500932029000035\n",
      "Starting epoch 771\n",
      "Train Loss: 0.024819512058187415\n",
      "Val Loss: 0.02517965822308152\n",
      "Starting epoch 772\n",
      "Train Loss: 0.0250096227283831\n",
      "Val Loss: 0.02493971531037931\n",
      "Starting epoch 773\n",
      "Train Loss: 0.025456712753684434\n",
      "Val Loss: 0.025125819775793288\n",
      "Starting epoch 774\n",
      "Train Loss: 0.025054239012576914\n",
      "Val Loss: 0.024449632675559434\n",
      "Starting epoch 775\n",
      "Train Loss: 0.02486695404405947\n",
      "Val Loss: 0.024518329236242507\n",
      "Starting epoch 776\n",
      "Train Loss: 0.02489492462741004\n",
      "Val Loss: 0.024642552490587586\n",
      "Starting epoch 777\n",
      "Train Loss: 0.024754088234018395\n",
      "Val Loss: 0.025073756222371704\n",
      "Starting epoch 778\n",
      "Train Loss: 0.024981551700168185\n",
      "Val Loss: 0.0245724618434906\n",
      "Starting epoch 779\n",
      "Train Loss: 0.025404505707599497\n",
      "Val Loss: 0.025113084801921138\n",
      "Starting epoch 780\n",
      "Train Loss: 0.024731320915398775\n",
      "Val Loss: 0.02494952193012944\n",
      "Starting epoch 781\n",
      "Train Loss: 0.024853060090983356\n",
      "Val Loss: 0.024963132209248014\n",
      "Starting epoch 782\n",
      "Train Loss: 0.024658889130309777\n",
      "Val Loss: 0.024781602952215407\n",
      "Starting epoch 783\n",
      "Train Loss: 0.024555949701203242\n",
      "Val Loss: 0.024759599456080684\n",
      "Starting epoch 784\n",
      "Train Loss: 0.02485949187367051\n",
      "Val Loss: 0.02467022670639886\n",
      "Starting epoch 785\n",
      "Train Loss: 0.02453666815051326\n",
      "Val Loss: 0.025062200095918443\n",
      "Starting epoch 786\n",
      "Train Loss: 0.024942709339989558\n",
      "Val Loss: 0.024607793048576073\n",
      "Starting epoch 787\n",
      "Train Loss: 0.025059001313315496\n",
      "Val Loss: 0.02508363127708435\n",
      "Starting epoch 788\n",
      "Train Loss: 0.02469455533557468\n",
      "Val Loss: 0.024792327373116103\n",
      "Starting epoch 789\n",
      "Train Loss: 0.024782600778120535\n",
      "Val Loss: 0.02460775441593594\n",
      "Starting epoch 790\n",
      "Train Loss: 0.0247657906126093\n",
      "Val Loss: 0.02484853344934958\n",
      "Starting epoch 791\n",
      "Train Loss: 0.024580846230189007\n",
      "Val Loss: 0.02452034475626769\n",
      "Starting epoch 792\n",
      "Train Loss: 0.024806496721726877\n",
      "Val Loss: 0.024300929572847154\n",
      "Starting epoch 793\n",
      "Train Loss: 0.0249931111379906\n",
      "Val Loss: 0.02456420163313548\n",
      "Starting epoch 794\n",
      "Train Loss: 0.024714818707218877\n",
      "Val Loss: 0.024802239404784307\n",
      "Starting epoch 795\n",
      "Train Loss: 0.02463402074796182\n",
      "Val Loss: 0.024358572783293547\n",
      "Starting epoch 796\n",
      "Train Loss: 0.024740756661803635\n",
      "Val Loss: 0.024436116218566895\n",
      "Starting epoch 797\n",
      "Train Loss: 0.0250430460329409\n",
      "Val Loss: 0.02466350849027987\n",
      "Starting epoch 798\n",
      "Train Loss: 0.024754170466352393\n",
      "Val Loss: 0.02474432631775185\n",
      "Starting epoch 799\n",
      "Train Loss: 0.024621147800374915\n",
      "Val Loss: 0.024388877330002962\n",
      "Starting epoch 800\n",
      "Train Loss: 0.02461302556373455\n",
      "Val Loss: 0.024614422961517616\n",
      "Starting epoch 801\n",
      "Train Loss: 0.024627265554887277\n",
      "Val Loss: 0.024380024936464097\n",
      "Starting epoch 802\n",
      "Train Loss: 0.024835545707631995\n",
      "Val Loss: 0.024621636779220017\n",
      "Starting epoch 803\n",
      "Train Loss: 0.024938151240348816\n",
      "Val Loss: 0.024640008255287452\n",
      "Starting epoch 804\n",
      "Train Loss: 0.024483368352607445\n",
      "Val Loss: 0.024634849142145226\n",
      "Starting epoch 805\n",
      "Train Loss: 0.024664360615942214\n",
      "Val Loss: 0.024585621776404203\n",
      "Starting epoch 806\n",
      "Train Loss: 0.024591893509582238\n",
      "Val Loss: 0.024381190538406372\n",
      "Starting epoch 807\n",
      "Train Loss: 0.024584847467916983\n",
      "Val Loss: 0.024795147555845755\n",
      "Starting epoch 808\n",
      "Train Loss: 0.024391853147082858\n",
      "Val Loss: 0.024464203803627578\n",
      "Starting epoch 809\n",
      "Train Loss: 0.02436551120546129\n",
      "Val Loss: 0.024891630918891343\n",
      "Starting epoch 810\n",
      "Train Loss: 0.024535116774064523\n",
      "Val Loss: 0.0243731532935743\n",
      "Starting epoch 811\n",
      "Train Loss: 0.024741810780984384\n",
      "Val Loss: 0.024704439772499934\n",
      "Starting epoch 812\n",
      "Train Loss: 0.024563766188091703\n",
      "Val Loss: 0.024435629447301228\n",
      "Starting epoch 813\n",
      "Train Loss: 0.024597016749558626\n",
      "Val Loss: 0.024535766354313603\n",
      "Starting epoch 814\n",
      "Train Loss: 0.024404037881780555\n",
      "Val Loss: 0.024776351120736863\n",
      "Starting epoch 815\n",
      "Train Loss: 0.024672832202028344\n",
      "Val Loss: 0.024640718543971027\n",
      "Starting epoch 816\n",
      "Train Loss: 0.024605677635581406\n",
      "Val Loss: 0.02462173170513577\n",
      "Starting epoch 817\n",
      "Train Loss: 0.024630394246843126\n",
      "Val Loss: 0.024211214648352727\n",
      "Starting epoch 818\n",
      "Train Loss: 0.024404322659527813\n",
      "Val Loss: 0.024574751655260723\n",
      "Starting epoch 819\n",
      "Train Loss: 0.024236794423173974\n",
      "Val Loss: 0.024302942333398043\n",
      "Starting epoch 820\n",
      "Train Loss: 0.024773096044858296\n",
      "Val Loss: 0.024424937588197214\n",
      "Starting epoch 821\n",
      "Train Loss: 0.024638484473581666\n",
      "Val Loss: 0.024728945559925504\n",
      "Starting epoch 822\n",
      "Train Loss: 0.02438846837591242\n",
      "Val Loss: 0.024880313762912044\n",
      "Starting epoch 823\n",
      "Train Loss: 0.024433744726357638\n",
      "Val Loss: 0.024510764413409762\n",
      "Starting epoch 824\n",
      "Train Loss: 0.024489147795571223\n",
      "Val Loss: 0.024796075291103788\n",
      "Starting epoch 825\n",
      "Train Loss: 0.024494627559626544\n",
      "Val Loss: 0.024426556295818753\n",
      "Starting epoch 826\n",
      "Train Loss: 0.024473818915861624\n",
      "Val Loss: 0.02443636898641233\n",
      "Starting epoch 827\n",
      "Train Loss: 0.024419148211125976\n",
      "Val Loss: 0.024030757171136362\n",
      "Starting epoch 828\n",
      "Train Loss: 0.02443385786480374\n",
      "Val Loss: 0.024605484472380743\n",
      "Starting epoch 829\n",
      "Train Loss: 0.02453675976505986\n",
      "Val Loss: 0.025017999940448336\n",
      "Starting epoch 830\n",
      "Train Loss: 0.024586715080119944\n",
      "Val Loss: 0.024165531551396405\n",
      "Starting epoch 831\n",
      "Train Loss: 0.024274132317966886\n",
      "Val Loss: 0.024382024451538368\n",
      "Starting epoch 832\n",
      "Train Loss: 0.024308059502530982\n",
      "Val Loss: 0.0244180499403565\n",
      "Starting epoch 833\n",
      "Train Loss: 0.02430796954366896\n",
      "Val Loss: 0.02442851221119916\n",
      "Starting epoch 834\n",
      "Train Loss: 0.024523998852129334\n",
      "Val Loss: 0.024507126874393888\n",
      "Starting epoch 835\n",
      "Train Loss: 0.024459379138769926\n",
      "Val Loss: 0.02427930853984974\n",
      "Starting epoch 836\n",
      "Train Loss: 0.024454611319082754\n",
      "Val Loss: 0.02426735394530826\n",
      "Starting epoch 837\n",
      "Train Loss: 0.02447894933047118\n",
      "Val Loss: 0.024235079133952106\n",
      "Starting epoch 838\n",
      "Train Loss: 0.024558477379657603\n",
      "Val Loss: 0.024525300772101792\n",
      "Starting epoch 839\n",
      "Train Loss: 0.024516693971775198\n",
      "Val Loss: 0.02447671470818696\n",
      "Starting epoch 840\n",
      "Train Loss: 0.024278218547503155\n",
      "Val Loss: 0.024461500070713186\n",
      "Starting epoch 841\n",
      "Train Loss: 0.024578312480891193\n",
      "Val Loss: 0.024450063153549476\n",
      "Starting epoch 842\n",
      "Train Loss: 0.024492995606528387\n",
      "Val Loss: 0.024408665520173532\n",
      "Starting epoch 843\n",
      "Train Loss: 0.02415759144005952\n",
      "Val Loss: 0.024077938662634954\n",
      "Starting epoch 844\n",
      "Train Loss: 0.024318519013899344\n",
      "Val Loss: 0.024442806288048072\n",
      "Starting epoch 845\n",
      "Train Loss: 0.024209900586693374\n",
      "Val Loss: 0.024252918583375437\n",
      "Starting epoch 846\n",
      "Train Loss: 0.024171127765266982\n",
      "Val Loss: 0.02431580313929805\n",
      "Starting epoch 847\n",
      "Train Loss: 0.02418648699919383\n",
      "Val Loss: 0.02432068685690562\n",
      "Starting epoch 848\n",
      "Train Loss: 0.024311173293325637\n",
      "Val Loss: 0.024472570529690495\n",
      "Starting epoch 849\n",
      "Train Loss: 0.024196083347002666\n",
      "Val Loss: 0.024184601726355375\n",
      "Starting epoch 850\n",
      "Train Loss: 0.0245758228831821\n",
      "Val Loss: 0.024275222310313472\n",
      "Starting epoch 851\n",
      "Train Loss: 0.02423989220901772\n",
      "Val Loss: 0.0244659924948657\n",
      "Starting epoch 852\n",
      "Train Loss: 0.024323721174840576\n",
      "Val Loss: 0.024270599638974225\n",
      "Starting epoch 853\n",
      "Train Loss: 0.024075616840963012\n",
      "Val Loss: 0.02423826025591956\n",
      "Starting epoch 854\n",
      "Train Loss: 0.024350950011500606\n",
      "Val Loss: 0.024248565788622254\n",
      "Starting epoch 855\n",
      "Train Loss: 0.02457297952086837\n",
      "Val Loss: 0.02418869678620939\n",
      "Starting epoch 856\n",
      "Train Loss: 0.024048013267693697\n",
      "Val Loss: 0.024086872184718097\n",
      "Starting epoch 857\n",
      "Train Loss: 0.0240826192829344\n",
      "Val Loss: 0.024248046455559908\n",
      "Starting epoch 858\n",
      "Train Loss: 0.02433900645485631\n",
      "Val Loss: 0.024223217809641803\n",
      "Starting epoch 859\n",
      "Train Loss: 0.02439343763722314\n",
      "Val Loss: 0.024100067438902677\n",
      "Starting epoch 860\n",
      "Train Loss: 0.023928279126131977\n",
      "Val Loss: 0.02442672351996104\n",
      "Starting epoch 861\n",
      "Train Loss: 0.02413541133756991\n",
      "Val Loss: 0.024160663838739747\n",
      "Starting epoch 862\n",
      "Train Loss: 0.024133283782888343\n",
      "Val Loss: 0.024225079351001315\n",
      "Starting epoch 863\n",
      "Train Loss: 0.024126907189687092\n",
      "Val Loss: 0.02421740746056592\n",
      "Starting epoch 864\n",
      "Train Loss: 0.024322226643562317\n",
      "Val Loss: 0.024389632874064975\n",
      "Starting epoch 865\n",
      "Train Loss: 0.024334003527959187\n",
      "Val Loss: 0.023995980620384216\n",
      "Starting epoch 866\n",
      "Train Loss: 0.024009088123286212\n",
      "Val Loss: 0.024018136439500033\n",
      "Starting epoch 867\n",
      "Train Loss: 0.024197081172907794\n",
      "Val Loss: 0.024384817039525067\n",
      "Starting epoch 868\n",
      "Train Loss: 0.02399355117921476\n",
      "Val Loss: 0.024294963589421025\n",
      "Starting epoch 869\n",
      "Train Loss: 0.024105625572027983\n",
      "Val Loss: 0.02436407020798436\n",
      "Starting epoch 870\n",
      "Train Loss: 0.024427839451366\n",
      "Val Loss: 0.02421460549036662\n",
      "Starting epoch 871\n",
      "Train Loss: 0.023930383501229464\n",
      "Val Loss: 0.02419622904724545\n",
      "Starting epoch 872\n",
      "Train Loss: 0.024071158634291753\n",
      "Val Loss: 0.024202552106645372\n",
      "Starting epoch 873\n",
      "Train Loss: 0.024040026245293795\n",
      "Val Loss: 0.02396451985394513\n",
      "Starting epoch 874\n",
      "Train Loss: 0.024182153520760714\n",
      "Val Loss: 0.024181906271863868\n",
      "Starting epoch 875\n",
      "Train Loss: 0.024116261689751235\n",
      "Val Loss: 0.02400076996397089\n",
      "Starting epoch 876\n",
      "Train Loss: 0.024111220130213985\n",
      "Val Loss: 0.024215838975376554\n",
      "Starting epoch 877\n",
      "Train Loss: 0.023999008315580862\n",
      "Val Loss: 0.02390407301761486\n",
      "Starting epoch 878\n",
      "Train Loss: 0.024077892303466797\n",
      "Val Loss: 0.023856516789506982\n",
      "Starting epoch 879\n",
      "Train Loss: 0.02407441978101377\n",
      "Val Loss: 0.02395977521384204\n",
      "Starting epoch 880\n",
      "Train Loss: 0.02409900780077334\n",
      "Val Loss: 0.024090690193352877\n",
      "Starting epoch 881\n",
      "Train Loss: 0.023980837177347253\n",
      "Val Loss: 0.024436034538127756\n",
      "Starting epoch 882\n",
      "Train Loss: 0.023897241663049767\n",
      "Val Loss: 0.024202412477246037\n",
      "Starting epoch 883\n",
      "Train Loss: 0.023994231113681087\n",
      "Val Loss: 0.02407377516781842\n",
      "Starting epoch 884\n",
      "Train Loss: 0.024016730763294077\n",
      "Val Loss: 0.023822163542111714\n",
      "Starting epoch 885\n",
      "Train Loss: 0.024132015528502287\n",
      "Val Loss: 0.02400549363206934\n",
      "Starting epoch 886\n",
      "Train Loss: 0.023976837595303852\n",
      "Val Loss: 0.023930102586746216\n",
      "Starting epoch 887\n",
      "Train Loss: 0.0241477456357744\n",
      "Val Loss: 0.024182496247468172\n",
      "Starting epoch 888\n",
      "Train Loss: 0.023900190437281574\n",
      "Val Loss: 0.023877506454785664\n",
      "Starting epoch 889\n",
      "Train Loss: 0.023655802011489868\n",
      "Val Loss: 0.023858256913997507\n",
      "Starting epoch 890\n",
      "Train Loss: 0.0240234997537401\n",
      "Val Loss: 0.024024487093642907\n",
      "Starting epoch 891\n",
      "Train Loss: 0.02383226266613713\n",
      "Val Loss: 0.02405436392183657\n",
      "Starting epoch 892\n",
      "Train Loss: 0.024060811157579774\n",
      "Val Loss: 0.024051894192342407\n",
      "Starting epoch 893\n",
      "Train Loss: 0.024276275877599365\n",
      "Val Loss: 0.023986283275816176\n",
      "Starting epoch 894\n",
      "Train Loss: 0.02369198865360684\n",
      "Val Loss: 0.023906023414046677\n",
      "Starting epoch 895\n",
      "Train Loss: 0.02386046614911821\n",
      "Val Loss: 0.023984979148264283\n",
      "Starting epoch 896\n",
      "Train Loss: 0.02408599136052308\n",
      "Val Loss: 0.0237614087484501\n",
      "Starting epoch 897\n",
      "Train Loss: 0.023851411210166082\n",
      "Val Loss: 0.023550969583016855\n",
      "Starting epoch 898\n",
      "Train Loss: 0.02366555509743867\n",
      "Val Loss: 0.0239455865489112\n",
      "Starting epoch 899\n",
      "Train Loss: 0.023888308140966628\n",
      "Val Loss: 0.023925166991021898\n",
      "Starting epoch 900\n",
      "Train Loss: 0.023701578378677368\n",
      "Val Loss: 0.02405213040334207\n",
      "Starting epoch 901\n",
      "Train Loss: 0.024070516228675842\n",
      "Val Loss: 0.023906020102677523\n",
      "Starting epoch 902\n",
      "Train Loss: 0.023977537949879963\n",
      "Val Loss: 0.02393126322163476\n",
      "Starting epoch 903\n",
      "Train Loss: 0.024086986426953918\n",
      "Val Loss: 0.02382698599938993\n",
      "Starting epoch 904\n",
      "Train Loss: 0.023596482696356596\n",
      "Val Loss: 0.023645021849208407\n",
      "Starting epoch 905\n",
      "Train Loss: 0.023801644643147785\n",
      "Val Loss: 0.023951279896276968\n",
      "Starting epoch 906\n",
      "Train Loss: 0.023735390769110784\n",
      "Val Loss: 0.023899628608315078\n",
      "Starting epoch 907\n",
      "Train Loss: 0.02376146724930516\n",
      "Val Loss: 0.02406097341466833\n",
      "Starting epoch 908\n",
      "Train Loss: 0.023585992830770987\n",
      "Val Loss: 0.023894388918523437\n",
      "Starting epoch 909\n",
      "Train Loss: 0.023827621782267536\n",
      "Val Loss: 0.02405311056861171\n",
      "Starting epoch 910\n",
      "Train Loss: 0.023939168563595525\n",
      "Val Loss: 0.02390179203616248\n",
      "Starting epoch 911\n",
      "Train Loss: 0.023833262699621695\n",
      "Val Loss: 0.024071951155309326\n",
      "Starting epoch 912\n",
      "Train Loss: 0.024101083477338154\n",
      "Val Loss: 0.02358225871015478\n",
      "Starting epoch 913\n",
      "Train Loss: 0.023641383206402813\n",
      "Val Loss: 0.023721608298796194\n",
      "Starting epoch 914\n",
      "Train Loss: 0.023670128650135465\n",
      "Val Loss: 0.02386195902471189\n",
      "Starting epoch 915\n",
      "Train Loss: 0.024303437383086594\n",
      "Val Loss: 0.023783338842568575\n",
      "Starting epoch 916\n",
      "Train Loss: 0.023971197229844553\n",
      "Val Loss: 0.023645765803478384\n",
      "Starting epoch 917\n",
      "Train Loss: 0.023891556594106887\n",
      "Val Loss: 0.024312012173511362\n",
      "Starting epoch 918\n",
      "Train Loss: 0.02380287812815772\n",
      "Val Loss: 0.02374404889565927\n",
      "Starting epoch 919\n",
      "Train Loss: 0.023587389676659194\n",
      "Val Loss: 0.023692462731290748\n",
      "Starting epoch 920\n",
      "Train Loss: 0.02360605365700192\n",
      "Val Loss: 0.023829815564332186\n",
      "Starting epoch 921\n",
      "Train Loss: 0.023640323568273475\n",
      "Val Loss: 0.023736560234317073\n",
      "Starting epoch 922\n",
      "Train Loss: 0.023692713843451604\n",
      "Val Loss: 0.023572340607643127\n",
      "Starting epoch 923\n",
      "Train Loss: 0.023847404453489516\n",
      "Val Loss: 0.024125282963116963\n",
      "Starting epoch 924\n",
      "Train Loss: 0.023681284100921067\n",
      "Val Loss: 0.02389616436428494\n",
      "Starting epoch 925\n",
      "Train Loss: 0.02363984673111527\n",
      "Val Loss: 0.023799057360048646\n",
      "Starting epoch 926\n",
      "Train Loss: 0.023571176661385432\n",
      "Val Loss: 0.023613121222566674\n",
      "Starting epoch 927\n",
      "Train Loss: 0.023833423301025673\n",
      "Val Loss: 0.02383058214629138\n",
      "Starting epoch 928\n",
      "Train Loss: 0.023907000819842022\n",
      "Val Loss: 0.023769921174755803\n",
      "Starting epoch 929\n",
      "Train Loss: 0.023978652225600347\n",
      "Val Loss: 0.02373758786254459\n",
      "Starting epoch 930\n",
      "Train Loss: 0.02381241155995263\n",
      "Val Loss: 0.024058562186029222\n",
      "Starting epoch 931\n",
      "Train Loss: 0.02384222878350152\n",
      "Val Loss: 0.023461934592988756\n",
      "Starting epoch 932\n",
      "Train Loss: 0.023730040148452477\n",
      "Val Loss: 0.023784424419756287\n",
      "Starting epoch 933\n",
      "Train Loss: 0.023611017951258906\n",
      "Val Loss: 0.023638478031864873\n",
      "Starting epoch 934\n",
      "Train Loss: 0.023918866007416335\n",
      "Val Loss: 0.023592815355018334\n",
      "Starting epoch 935\n",
      "Train Loss: 0.023687957613556472\n",
      "Val Loss: 0.02403996443306958\n",
      "Starting epoch 936\n",
      "Train Loss: 0.023842795027626887\n",
      "Val Loss: 0.02371427747938368\n",
      "Starting epoch 937\n",
      "Train Loss: 0.024029303480077674\n",
      "Val Loss: 0.02380809243078585\n",
      "Starting epoch 938\n",
      "Train Loss: 0.023651867001144973\n",
      "Val Loss: 0.023800323958750123\n",
      "Starting epoch 939\n",
      "Train Loss: 0.023562704523404438\n",
      "Val Loss: 0.023596382251492253\n",
      "Starting epoch 940\n",
      "Train Loss: 0.0235845943291982\n",
      "Val Loss: 0.023885340602309617\n",
      "Starting epoch 941\n",
      "Train Loss: 0.023769634741323965\n",
      "Val Loss: 0.023615173719547414\n",
      "Starting epoch 942\n",
      "Train Loss: 0.0235791587167316\n",
      "Val Loss: 0.023568924930360582\n",
      "Starting epoch 943\n",
      "Train Loss: 0.023676756355497573\n",
      "Val Loss: 0.023773477585227402\n",
      "Starting epoch 944\n",
      "Train Loss: 0.023703602177125437\n",
      "Val Loss: 0.023514795082586783\n",
      "Starting epoch 945\n",
      "Train Loss: 0.023438871458724694\n",
      "Val Loss: 0.023835338376186514\n",
      "Starting epoch 946\n",
      "Train Loss: 0.023599908307746605\n",
      "Val Loss: 0.023671729697121516\n",
      "Starting epoch 947\n",
      "Train Loss: 0.023833466900719538\n",
      "Val Loss: 0.02376143799887763\n",
      "Starting epoch 948\n",
      "Train Loss: 0.023446127220436378\n",
      "Val Loss: 0.02354028876181002\n",
      "Starting epoch 949\n",
      "Train Loss: 0.023723824708550063\n",
      "Val Loss: 0.023542980353037517\n",
      "Starting epoch 950\n",
      "Train Loss: 0.023696085369145428\n",
      "Val Loss: 0.02361959163789396\n",
      "Starting epoch 951\n",
      "Train Loss: 0.023784596610952308\n",
      "Val Loss: 0.02345046787350266\n",
      "Starting epoch 952\n",
      "Train Loss: 0.02368836325627786\n",
      "Val Loss: 0.02386320851467274\n",
      "Starting epoch 953\n",
      "Train Loss: 0.023691421305691754\n",
      "Val Loss: 0.02354074904212245\n",
      "Starting epoch 954\n",
      "Train Loss: 0.023709242542584736\n",
      "Val Loss: 0.023646572121867427\n",
      "Starting epoch 955\n",
      "Train Loss: 0.023974054389529757\n",
      "Val Loss: 0.023431726075984812\n",
      "Starting epoch 956\n",
      "Train Loss: 0.02341358639575817\n",
      "Val Loss: 0.02363806907777433\n",
      "Starting epoch 957\n",
      "Train Loss: 0.023688150224862276\n",
      "Val Loss: 0.023660881099877535\n",
      "Starting epoch 958\n",
      "Train Loss: 0.023606905782664264\n",
      "Val Loss: 0.023598010341326397\n",
      "Starting epoch 959\n",
      "Train Loss: 0.02359534744863157\n",
      "Val Loss: 0.02374734150038825\n",
      "Starting epoch 960\n",
      "Train Loss: 0.02346509419105671\n",
      "Val Loss: 0.02355835283244098\n",
      "Starting epoch 961\n",
      "Train Loss: 0.02346463280695456\n",
      "Val Loss: 0.02346923505818402\n",
      "Starting epoch 962\n",
      "Train Loss: 0.023458079607398423\n",
      "Val Loss: 0.02352969734757035\n",
      "Starting epoch 963\n",
      "Train Loss: 0.023289880266896\n",
      "Val Loss: 0.023330721038359183\n",
      "Starting epoch 964\n",
      "Train Loss: 0.0235140108399921\n",
      "Val Loss: 0.023280089100201923\n",
      "Starting epoch 965\n",
      "Train Loss: 0.023621713121732075\n",
      "Val Loss: 0.023539602204605384\n",
      "Starting epoch 966\n",
      "Train Loss: 0.023795521369686833\n",
      "Val Loss: 0.023323376421575195\n",
      "Starting epoch 967\n",
      "Train Loss: 0.0235099991162618\n",
      "Val Loss: 0.023463515771759882\n",
      "Starting epoch 968\n",
      "Train Loss: 0.023496943491476553\n",
      "Val Loss: 0.02328879965676202\n",
      "Starting epoch 969\n",
      "Train Loss: 0.023466169282242103\n",
      "Val Loss: 0.023656190545470628\n",
      "Starting epoch 970\n",
      "Train Loss: 0.023557474215825398\n",
      "Val Loss: 0.02354768967186963\n",
      "Starting epoch 971\n",
      "Train Loss: 0.023606021095205237\n",
      "Val Loss: 0.023292838423340408\n",
      "Starting epoch 972\n",
      "Train Loss: 0.023776326466489722\n",
      "Val Loss: 0.023326133688290913\n",
      "Starting epoch 973\n",
      "Train Loss: 0.02339587222646784\n",
      "Val Loss: 0.023384211791886225\n",
      "Starting epoch 974\n",
      "Train Loss: 0.023831218481063843\n",
      "Val Loss: 0.023487745611755935\n",
      "Starting epoch 975\n",
      "Train Loss: 0.023278505713851365\n",
      "Val Loss: 0.023252106375164457\n",
      "Starting epoch 976\n",
      "Train Loss: 0.023697264768459177\n",
      "Val Loss: 0.023418714050893432\n",
      "Starting epoch 977\n",
      "Train Loss: 0.02356356879075368\n",
      "Val Loss: 0.023458777754395095\n",
      "Starting epoch 978\n",
      "Train Loss: 0.023609572538623103\n",
      "Val Loss: 0.02371926164185559\n",
      "Starting epoch 979\n",
      "Train Loss: 0.023681887322001986\n",
      "Val Loss: 0.02325348335283774\n",
      "Starting epoch 980\n",
      "Train Loss: 0.023266812165578205\n",
      "Val Loss: 0.023406301935513813\n",
      "Starting epoch 981\n",
      "Train Loss: 0.023478912534537138\n",
      "Val Loss: 0.0235073196667212\n",
      "Starting epoch 982\n",
      "Train Loss: 0.02311161270848027\n",
      "Val Loss: 0.0233314522990474\n",
      "Starting epoch 983\n",
      "Train Loss: 0.023289000546490704\n",
      "Val Loss: 0.023315576491532503\n",
      "Starting epoch 984\n",
      "Train Loss: 0.023595075916360925\n",
      "Val Loss: 0.023382098034576134\n",
      "Starting epoch 985\n",
      "Train Loss: 0.023414159814516704\n",
      "Val Loss: 0.023298130543143662\n",
      "Starting epoch 986\n",
      "Train Loss: 0.023391733015025104\n",
      "Val Loss: 0.023257660645025748\n",
      "Starting epoch 987\n",
      "Train Loss: 0.023315501433831674\n",
      "Val Loss: 0.023586358185167664\n",
      "Starting epoch 988\n",
      "Train Loss: 0.02354219776612741\n",
      "Val Loss: 0.023210616023452195\n",
      "Starting epoch 989\n",
      "Train Loss: 0.023457872094931425\n",
      "Val Loss: 0.023605630905539902\n",
      "Starting epoch 990\n",
      "Train Loss: 0.02339312544575444\n",
      "Val Loss: 0.023417106381169072\n",
      "Starting epoch 991\n",
      "Train Loss: 0.023217936908757245\n",
      "Val Loss: 0.023421360938637344\n",
      "Starting epoch 992\n",
      "Train Loss: 0.023320826115431608\n",
      "Val Loss: 0.02360797811437536\n",
      "Starting epoch 993\n",
      "Train Loss: 0.023241421690693608\n",
      "Val Loss: 0.02342016167110867\n",
      "Starting epoch 994\n",
      "Train Loss: 0.023754557525670086\n",
      "Val Loss: 0.023440705957236112\n",
      "Starting epoch 995\n",
      "Train Loss: 0.023199138817963778\n",
      "Val Loss: 0.023224733493946218\n",
      "Starting epoch 996\n",
      "Train Loss: 0.023534323330278748\n",
      "Val Loss: 0.02397005756696065\n",
      "Starting epoch 997\n",
      "Train Loss: 0.023779206253864146\n",
      "Val Loss: 0.02332093428682398\n",
      "Starting epoch 998\n",
      "Train Loss: 0.02345307226534243\n",
      "Val Loss: 0.02364496390024821\n",
      "Starting epoch 999\n",
      "Train Loss: 0.02372032348756437\n",
      "Val Loss: 0.02341441865320559\n",
      "Starting epoch 1000\n",
      "Train Loss: 0.02311310613596881\n",
      "Val Loss: 0.02323246995608012\n",
      "Starting epoch 1001\n",
      "Train Loss: 0.023094928374996892\n",
      "Val Loss: 0.023045852780342102\n",
      "Starting epoch 1002\n",
      "Train Loss: 0.023291958702935114\n",
      "Val Loss: 0.023201112393979675\n",
      "Starting epoch 1003\n",
      "Train Loss: 0.023457656304041546\n",
      "Val Loss: 0.023303374096199318\n",
      "Starting epoch 1004\n",
      "Train Loss: 0.023247103448267335\n",
      "Val Loss: 0.023522345556153193\n",
      "Starting epoch 1005\n",
      "Train Loss: 0.02319200888827995\n",
      "Val Loss: 0.023352761511449462\n",
      "Starting epoch 1006\n",
      "Train Loss: 0.023418636785613164\n",
      "Val Loss: 0.023356108753769485\n",
      "Starting epoch 1007\n",
      "Train Loss: 0.023337273134125605\n",
      "Val Loss: 0.023325812485482957\n",
      "Starting epoch 1008\n",
      "Train Loss: 0.023214271223103558\n",
      "Val Loss: 0.023308458703535574\n",
      "Starting epoch 1009\n",
      "Train Loss: 0.023160501210777847\n",
      "Val Loss: 0.023329399250171804\n",
      "Starting epoch 1010\n",
      "Train Loss: 0.023568462994363572\n",
      "Val Loss: 0.023195268379317388\n",
      "Starting epoch 1011\n",
      "Train Loss: 0.02333651262300986\n",
      "Val Loss: 0.023235946341797157\n",
      "Starting epoch 1012\n",
      "Train Loss: 0.023318998791553355\n",
      "Val Loss: 0.023236920988118206\n",
      "Starting epoch 1013\n",
      "Train Loss: 0.023108564041278982\n",
      "Val Loss: 0.023232508588720252\n",
      "Starting epoch 1014\n",
      "Train Loss: 0.023100278995655203\n",
      "Val Loss: 0.02362869072843481\n",
      "Starting epoch 1015\n",
      "Train Loss: 0.023383652170499165\n",
      "Val Loss: 0.023098016778628033\n",
      "Starting epoch 1016\n",
      "Train Loss: 0.02315539452764723\n",
      "Val Loss: 0.02299730866043656\n",
      "Starting epoch 1017\n",
      "Train Loss: 0.023104895596151\n",
      "Val Loss: 0.02332680258486006\n",
      "Starting epoch 1018\n",
      "Train Loss: 0.02328434145009076\n",
      "Val Loss: 0.02315213006955606\n",
      "Starting epoch 1019\n",
      "Train Loss: 0.022992002191366972\n",
      "Val Loss: 0.023226353857252333\n",
      "Starting epoch 1020\n",
      "Train Loss: 0.022933659730134188\n",
      "Val Loss: 0.023274916189688223\n",
      "Starting epoch 1021\n",
      "Train Loss: 0.023084584761548926\n",
      "Val Loss: 0.02354379329416487\n",
      "Starting epoch 1022\n",
      "Train Loss: 0.023275412343166494\n",
      "Val Loss: 0.023115799934775742\n",
      "Starting epoch 1023\n",
      "Train Loss: 0.023400417632526822\n",
      "Val Loss: 0.02299525230019181\n",
      "Starting epoch 1024\n",
      "Train Loss: 0.022998126568617643\n",
      "Val Loss: 0.023245696668271667\n",
      "Starting epoch 1025\n",
      "Train Loss: 0.02347203592459361\n",
      "Val Loss: 0.023290913965966966\n",
      "Starting epoch 1026\n",
      "Train Loss: 0.023089928759468928\n",
      "Val Loss: 0.02299615188881203\n",
      "Starting epoch 1027\n",
      "Train Loss: 0.02292134530014462\n",
      "Val Loss: 0.02317398179460455\n",
      "Starting epoch 1028\n",
      "Train Loss: 0.023025783675688284\n",
      "Val Loss: 0.023376873245945683\n",
      "Starting epoch 1029\n",
      "Train Loss: 0.023233997601049917\n",
      "Val Loss: 0.02307103298328541\n",
      "Starting epoch 1030\n",
      "Train Loss: 0.022976343830426533\n",
      "Val Loss: 0.023253355865125305\n",
      "Starting epoch 1031\n",
      "Train Loss: 0.023143448211528635\n",
      "Val Loss: 0.02309644553396437\n",
      "Starting epoch 1032\n",
      "Train Loss: 0.023033144297423185\n",
      "Val Loss: 0.022946162908165542\n",
      "Starting epoch 1033\n",
      "Train Loss: 0.023318560587035284\n",
      "Val Loss: 0.02314504594714553\n",
      "Starting epoch 1034\n",
      "Train Loss: 0.023178963197602168\n",
      "Val Loss: 0.02310347446688899\n",
      "Starting epoch 1035\n",
      "Train Loss: 0.02308582431740231\n",
      "Val Loss: 0.023114555411868624\n",
      "Starting epoch 1036\n",
      "Train Loss: 0.023053496524139686\n",
      "Val Loss: 0.023043704805550753\n",
      "Starting epoch 1037\n",
      "Train Loss: 0.023169623480902776\n",
      "Val Loss: 0.02364130704491227\n",
      "Starting epoch 1038\n",
      "Train Loss: 0.023149045529188932\n",
      "Val Loss: 0.023429442335058143\n",
      "Starting epoch 1039\n",
      "Train Loss: 0.02308686629489616\n",
      "Val Loss: 0.023229396453610173\n",
      "Starting epoch 1040\n",
      "Train Loss: 0.023164971007241145\n",
      "Val Loss: 0.022962930577772635\n",
      "Starting epoch 1041\n",
      "Train Loss: 0.0230425833551972\n",
      "Val Loss: 0.02310049533843994\n",
      "Starting epoch 1042\n",
      "Train Loss: 0.023319934805234272\n",
      "Val Loss: 0.02317653817159158\n",
      "Starting epoch 1043\n",
      "Train Loss: 0.02315138832286552\n",
      "Val Loss: 0.02294545151569225\n",
      "Starting epoch 1044\n",
      "Train Loss: 0.023099508550431993\n",
      "Val Loss: 0.022930471433533564\n",
      "Starting epoch 1045\n",
      "Train Loss: 0.02296441462304857\n",
      "Val Loss: 0.02322488526503245\n",
      "Starting epoch 1046\n",
      "Train Loss: 0.02337737657405712\n",
      "Val Loss: 0.023088238305515714\n",
      "Starting epoch 1047\n",
      "Train Loss: 0.023006683146512066\n",
      "Val Loss: 0.023159945452654804\n",
      "Starting epoch 1048\n",
      "Train Loss: 0.023136458463139005\n",
      "Val Loss: 0.02326066681632289\n",
      "Starting epoch 1049\n",
      "Train Loss: 0.02286174065536923\n",
      "Val Loss: 0.023037961235752812\n",
      "Starting epoch 1050\n",
      "Train Loss: 0.02327923200748585\n",
      "Val Loss: 0.023334290142412537\n",
      "Starting epoch 1051\n",
      "Train Loss: 0.023261292665093032\n",
      "Val Loss: 0.022990246061925537\n",
      "Starting epoch 1052\n",
      "Train Loss: 0.02303971791708911\n",
      "Val Loss: 0.02291604103865447\n",
      "Starting epoch 1053\n",
      "Train Loss: 0.02305989905639931\n",
      "Val Loss: 0.022859637935956318\n",
      "Starting epoch 1054\n",
      "Train Loss: 0.022992766013851872\n",
      "Val Loss: 0.022986120095959416\n",
      "Starting epoch 1055\n",
      "Train Loss: 0.023191647949042143\n",
      "Val Loss: 0.023076812426249187\n",
      "Starting epoch 1056\n",
      "Train Loss: 0.022967411412133112\n",
      "Val Loss: 0.02336882220374213\n",
      "Starting epoch 1057\n",
      "Train Loss: 0.023221338788668316\n",
      "Val Loss: 0.02296737277949298\n",
      "Starting epoch 1058\n",
      "Train Loss: 0.023025076146479004\n",
      "Val Loss: 0.023013966502966703\n",
      "Starting epoch 1059\n",
      "Train Loss: 0.02320573009826519\n",
      "Val Loss: 0.022936282334504305\n",
      "Starting epoch 1060\n",
      "Train Loss: 0.023019440748073435\n",
      "Val Loss: 0.022896299759546917\n",
      "Starting epoch 1061\n",
      "Train Loss: 0.023003357428091543\n",
      "Val Loss: 0.023173767107504385\n",
      "Starting epoch 1062\n",
      "Train Loss: 0.02289561209855256\n",
      "Val Loss: 0.022880070739322238\n",
      "Starting epoch 1063\n",
      "Train Loss: 0.023304634072162485\n",
      "Val Loss: 0.022962543147581595\n",
      "Starting epoch 1064\n",
      "Train Loss: 0.023110846126521076\n",
      "Val Loss: 0.02283251506310922\n",
      "Starting epoch 1065\n",
      "Train Loss: 0.02295480337407854\n",
      "Val Loss: 0.022862256677062424\n",
      "Starting epoch 1066\n",
      "Train Loss: 0.022808161598664743\n",
      "Val Loss: 0.023073530859417386\n",
      "Starting epoch 1067\n",
      "Train Loss: 0.023132503032684326\n",
      "Val Loss: 0.022912813557518855\n",
      "Starting epoch 1068\n",
      "Train Loss: 0.023355679931464018\n",
      "Val Loss: 0.022767164089061594\n",
      "Starting epoch 1069\n",
      "Train Loss: 0.022783345646328397\n",
      "Val Loss: 0.02285315372325756\n",
      "Starting epoch 1070\n",
      "Train Loss: 0.02297851608859168\n",
      "Val Loss: 0.023150529022570008\n",
      "Starting epoch 1071\n",
      "Train Loss: 0.02295819366419757\n",
      "Val Loss: 0.023041778140597872\n",
      "Starting epoch 1072\n",
      "Train Loss: 0.023464360170894198\n",
      "Val Loss: 0.02312539517879486\n",
      "Starting epoch 1073\n",
      "Train Loss: 0.023204449702192237\n",
      "Val Loss: 0.023044585077850906\n",
      "Starting epoch 1074\n",
      "Train Loss: 0.023247830845691538\n",
      "Val Loss: 0.022875356453436392\n",
      "Starting epoch 1075\n",
      "Train Loss: 0.02286033829053243\n",
      "Val Loss: 0.02309023450922083\n",
      "Starting epoch 1076\n",
      "Train Loss: 0.02287435421237239\n",
      "Val Loss: 0.022997304245277687\n",
      "Starting epoch 1077\n",
      "Train Loss: 0.0228741439404311\n",
      "Val Loss: 0.02314350340101454\n",
      "Starting epoch 1078\n",
      "Train Loss: 0.023060326223020202\n",
      "Val Loss: 0.023078124280329102\n",
      "Starting epoch 1079\n",
      "Train Loss: 0.022801060919408447\n",
      "Val Loss: 0.022990443640285067\n",
      "Starting epoch 1080\n",
      "Train Loss: 0.02300392974306036\n",
      "Val Loss: 0.02280793366608796\n",
      "Starting epoch 1081\n",
      "Train Loss: 0.022838278501122085\n",
      "Val Loss: 0.0230744696325726\n",
      "Starting epoch 1082\n",
      "Train Loss: 0.023051359587245517\n",
      "Val Loss: 0.023034723268614873\n",
      "Starting epoch 1083\n",
      "Train Loss: 0.022865713746459397\n",
      "Val Loss: 0.022918804376213638\n",
      "Starting epoch 1084\n",
      "Train Loss: 0.02278800970978207\n",
      "Val Loss: 0.022856471163255197\n",
      "Starting epoch 1085\n",
      "Train Loss: 0.02288224630885654\n",
      "Val Loss: 0.02287516384213059\n",
      "Starting epoch 1086\n",
      "Train Loss: 0.023006388986552204\n",
      "Val Loss: 0.022891062829229567\n",
      "Starting epoch 1087\n",
      "Train Loss: 0.02293565317436501\n",
      "Val Loss: 0.022830022705925837\n",
      "Starting epoch 1088\n",
      "Train Loss: 0.022940715705906903\n",
      "Val Loss: 0.0229356344099398\n",
      "Starting epoch 1089\n",
      "Train Loss: 0.02292084252392804\n",
      "Val Loss: 0.0227617836660809\n",
      "Starting epoch 1090\n",
      "Train Loss: 0.02289671809585006\n",
      "Val Loss: 0.023379948955995065\n",
      "Starting epoch 1091\n",
      "Train Loss: 0.023251332066677236\n",
      "Val Loss: 0.023243897491031222\n",
      "Starting epoch 1092\n",
      "Train Loss: 0.023020371242805763\n",
      "Val Loss: 0.022871658757880883\n",
      "Starting epoch 1093\n",
      "Train Loss: 0.02287059360080295\n",
      "Val Loss: 0.02278236327347932\n",
      "Starting epoch 1094\n",
      "Train Loss: 0.022790860246728967\n",
      "Val Loss: 0.02294190227985382\n",
      "Starting epoch 1095\n",
      "Train Loss: 0.02284703872821949\n",
      "Val Loss: 0.022938338142854196\n",
      "Starting epoch 1096\n",
      "Train Loss: 0.0227846779205181\n",
      "Val Loss: 0.02277535420876962\n",
      "Starting epoch 1097\n",
      "Train Loss: 0.022927580608261958\n",
      "Val Loss: 0.02331372598807017\n",
      "Starting epoch 1098\n",
      "Train Loss: 0.023008096549246047\n",
      "Val Loss: 0.023087872951119033\n",
      "Starting epoch 1099\n",
      "Train Loss: 0.023162113847555937\n",
      "Val Loss: 0.022770240902900696\n",
      "Starting epoch 1100\n",
      "Train Loss: 0.02278983924123976\n",
      "Val Loss: 0.022943096028433904\n",
      "Starting epoch 1101\n",
      "Train Loss: 0.022770845779666194\n",
      "Val Loss: 0.022748170627488032\n",
      "Starting epoch 1102\n",
      "Train Loss: 0.02312911053498586\n",
      "Val Loss: 0.022866929018938983\n",
      "Starting epoch 1103\n",
      "Train Loss: 0.023088111921592994\n",
      "Val Loss: 0.02276538422814122\n",
      "Starting epoch 1104\n",
      "Train Loss: 0.02281720715540427\n",
      "Val Loss: 0.022854244267499005\n",
      "Starting epoch 1105\n",
      "Train Loss: 0.022905560003386602\n",
      "Val Loss: 0.0227593884423927\n",
      "Starting epoch 1106\n",
      "Train Loss: 0.02289956256195351\n",
      "Val Loss: 0.023069126738442317\n",
      "Starting epoch 1107\n",
      "Train Loss: 0.023028596131889907\n",
      "Val Loss: 0.02271424620239823\n",
      "Starting epoch 1108\n",
      "Train Loss: 0.022992694819415058\n",
      "Val Loss: 0.022891902261310153\n",
      "Starting epoch 1109\n",
      "Train Loss: 0.02292913364039527\n",
      "Val Loss: 0.023028226914229215\n",
      "Starting epoch 1110\n",
      "Train Loss: 0.02298994583112222\n",
      "Val Loss: 0.022723401034319843\n",
      "Starting epoch 1111\n",
      "Train Loss: 0.022729787009733694\n",
      "Val Loss: 0.022945117619302537\n",
      "Starting epoch 1112\n",
      "Train Loss: 0.02302818497021993\n",
      "Val Loss: 0.022929069068696763\n",
      "Starting epoch 1113\n",
      "Train Loss: 0.022940212377795467\n",
      "Val Loss: 0.02272410304458053\n",
      "Starting epoch 1114\n",
      "Train Loss: 0.023317601945665147\n",
      "Val Loss: 0.022916749671653466\n",
      "Starting epoch 1115\n",
      "Train Loss: 0.02312830090522766\n",
      "Val Loss: 0.023232117847160057\n",
      "Starting epoch 1116\n",
      "Train Loss: 0.022990566160943773\n",
      "Val Loss: 0.022837559934015626\n",
      "Starting epoch 1117\n",
      "Train Loss: 0.022729219109923753\n",
      "Val Loss: 0.022684730313442373\n",
      "Starting epoch 1118\n",
      "Train Loss: 0.022681497313358164\n",
      "Val Loss: 0.022768407508178993\n",
      "Starting epoch 1119\n",
      "Train Loss: 0.022844254418655677\n",
      "Val Loss: 0.022854077043356718\n",
      "Starting epoch 1120\n",
      "Train Loss: 0.02274619981094643\n",
      "Val Loss: 0.022734310339998315\n",
      "Starting epoch 1121\n",
      "Train Loss: 0.022816777229309082\n",
      "Val Loss: 0.02284292600772999\n",
      "Starting epoch 1122\n",
      "Train Loss: 0.022950034450601647\n",
      "Val Loss: 0.022753170243015996\n",
      "Starting epoch 1123\n",
      "Train Loss: 0.022773466176456876\n",
      "Val Loss: 0.02307782570521037\n",
      "Starting epoch 1124\n",
      "Train Loss: 0.022840513123406306\n",
      "Val Loss: 0.02284033154999768\n",
      "Starting epoch 1125\n",
      "Train Loss: 0.02299951458418811\n",
      "Val Loss: 0.022631410095426772\n",
      "Starting epoch 1126\n",
      "Train Loss: 0.022726392304455792\n",
      "Val Loss: 0.022952739287305762\n",
      "Starting epoch 1127\n",
      "Train Loss: 0.02285856505235036\n",
      "Val Loss: 0.022770012970323914\n",
      "Starting epoch 1128\n",
      "Train Loss: 0.02264676767366904\n",
      "Val Loss: 0.022689110151043645\n",
      "Starting epoch 1129\n",
      "Train Loss: 0.022907860301159048\n",
      "Val Loss: 0.022779142966976872\n",
      "Starting epoch 1130\n",
      "Train Loss: 0.022627275851037767\n",
      "Val Loss: 0.022704149837847108\n",
      "Starting epoch 1131\n",
      "Train Loss: 0.02271807028187646\n",
      "Val Loss: 0.02267991116753331\n",
      "Starting epoch 1132\n",
      "Train Loss: 0.02271045689229612\n",
      "Val Loss: 0.022621813747617934\n",
      "Starting epoch 1133\n",
      "Train Loss: 0.02280464161325384\n",
      "Val Loss: 0.022663599363079778\n",
      "Starting epoch 1134\n",
      "Train Loss: 0.022790507585914048\n",
      "Val Loss: 0.022636296572508634\n",
      "Starting epoch 1135\n",
      "Train Loss: 0.023159857701372216\n",
      "Val Loss: 0.022547798576178373\n",
      "Starting epoch 1136\n",
      "Train Loss: 0.022864060269461736\n",
      "Val Loss: 0.022588858449900592\n",
      "Starting epoch 1137\n",
      "Train Loss: 0.0228075600332684\n",
      "Val Loss: 0.02267138770333043\n",
      "Starting epoch 1138\n",
      "Train Loss: 0.02266271964267448\n",
      "Val Loss: 0.02274399278340516\n",
      "Starting epoch 1139\n",
      "Train Loss: 0.022762316796514723\n",
      "Val Loss: 0.022792523657834088\n",
      "Starting epoch 1140\n",
      "Train Loss: 0.022848571340243023\n",
      "Val Loss: 0.02274556733943798\n",
      "Starting epoch 1141\n",
      "Train Loss: 0.02271155185169644\n",
      "Val Loss: 0.022653437874935293\n",
      "Starting epoch 1142\n",
      "Train Loss: 0.022614508315368934\n",
      "Val Loss: 0.022631854922683152\n",
      "Starting epoch 1143\n",
      "Train Loss: 0.022657431386135244\n",
      "Val Loss: 0.022899497990255004\n",
      "Starting epoch 1144\n",
      "Train Loss: 0.02283936463020466\n",
      "Val Loss: 0.02284862321835977\n",
      "Starting epoch 1145\n",
      "Train Loss: 0.022989990534605802\n",
      "Val Loss: 0.0225464618868298\n",
      "Starting epoch 1146\n",
      "Train Loss: 0.022776810659302607\n",
      "Val Loss: 0.022673919245048805\n",
      "Starting epoch 1147\n",
      "Train Loss: 0.022949872745407954\n",
      "Val Loss: 0.02283283019507373\n",
      "Starting epoch 1148\n",
      "Train Loss: 0.022497139595173025\n",
      "Val Loss: 0.022652804851531982\n",
      "Starting epoch 1149\n",
      "Train Loss: 0.02264701713014532\n",
      "Val Loss: 0.022605573689496075\n",
      "Starting epoch 1150\n",
      "Train Loss: 0.022460778554280598\n",
      "Val Loss: 0.02262595847800926\n",
      "Starting epoch 1151\n",
      "Train Loss: 0.02313602246620037\n",
      "Val Loss: 0.022652927372190688\n",
      "Starting epoch 1152\n",
      "Train Loss: 0.022780206468370225\n",
      "Val Loss: 0.02289872533745236\n",
      "Starting epoch 1153\n",
      "Train Loss: 0.02268236599586628\n",
      "Val Loss: 0.022594097035902518\n",
      "Starting epoch 1154\n",
      "Train Loss: 0.022689708956965694\n",
      "Val Loss: 0.022751268413331773\n",
      "Starting epoch 1155\n",
      "Train Loss: 0.02255707537686383\n",
      "Val Loss: 0.02291119595368703\n",
      "Starting epoch 1156\n",
      "Train Loss: 0.022661411099963717\n",
      "Val Loss: 0.022668034942061814\n",
      "Starting epoch 1157\n",
      "Train Loss: 0.022936201205960027\n",
      "Val Loss: 0.022487405273649428\n",
      "Starting epoch 1158\n",
      "Train Loss: 0.022601647509468928\n",
      "Val Loss: 0.02268053149735486\n",
      "Starting epoch 1159\n",
      "Train Loss: 0.022607361828839337\n",
      "Val Loss: 0.022657736583992286\n",
      "Starting epoch 1160\n",
      "Train Loss: 0.02304600896658721\n",
      "Val Loss: 0.022740481628312006\n",
      "Starting epoch 1161\n",
      "Train Loss: 0.02305384918495461\n",
      "Val Loss: 0.02272587462707802\n",
      "Starting epoch 1162\n",
      "Train Loss: 0.022707367384875263\n",
      "Val Loss: 0.022784579131338332\n",
      "Starting epoch 1163\n",
      "Train Loss: 0.022637767372307955\n",
      "Val Loss: 0.022673088091391104\n",
      "Starting epoch 1164\n",
      "Train Loss: 0.022932055923673842\n",
      "Val Loss: 0.02262983774697339\n",
      "Starting epoch 1165\n",
      "Train Loss: 0.022499616499300355\n",
      "Val Loss: 0.022601595631352178\n",
      "Starting epoch 1166\n",
      "Train Loss: 0.022866414652930364\n",
      "Val Loss: 0.022554755210876465\n",
      "Starting epoch 1167\n",
      "Train Loss: 0.022504740843066463\n",
      "Val Loss: 0.022902764655925608\n",
      "Starting epoch 1168\n",
      "Train Loss: 0.02256438853564086\n",
      "Val Loss: 0.022684410214424133\n",
      "Starting epoch 1169\n",
      "Train Loss: 0.022571152007138287\n",
      "Val Loss: 0.022661856479114957\n",
      "Starting epoch 1170\n",
      "Train Loss: 0.022606662578052945\n",
      "Val Loss: 0.02261208991209666\n",
      "Starting epoch 1171\n",
      "Train Loss: 0.022603011793560453\n",
      "Val Loss: 0.02252887686093648\n",
      "Starting epoch 1172\n",
      "Train Loss: 0.022485537661446467\n",
      "Val Loss: 0.02293519786110631\n",
      "Starting epoch 1173\n",
      "Train Loss: 0.02259787806758174\n",
      "Val Loss: 0.022588283375457482\n",
      "Starting epoch 1174\n",
      "Train Loss: 0.022610599795977276\n",
      "Val Loss: 0.022956418218436064\n",
      "Starting epoch 1175\n",
      "Train Loss: 0.02252002391550276\n",
      "Val Loss: 0.022763199276394315\n",
      "Starting epoch 1176\n",
      "Train Loss: 0.022694022015289025\n",
      "Val Loss: 0.022636372182104323\n",
      "Starting epoch 1177\n",
      "Train Loss: 0.022536453273561265\n",
      "Val Loss: 0.022612776469301293\n",
      "Starting epoch 1178\n",
      "Train Loss: 0.022710185911920335\n",
      "Val Loss: 0.022732111038985075\n",
      "Starting epoch 1179\n",
      "Train Loss: 0.022823500964376662\n",
      "Val Loss: 0.022764131978706078\n",
      "Starting epoch 1180\n",
      "Train Loss: 0.022532966401841905\n",
      "Val Loss: 0.02280732051089958\n",
      "Starting epoch 1181\n",
      "Train Loss: 0.022600532129958825\n",
      "Val Loss: 0.022575348063751503\n",
      "Starting epoch 1182\n",
      "Train Loss: 0.02266969393800806\n",
      "Val Loss: 0.02278041453273208\n",
      "Starting epoch 1183\n",
      "Train Loss: 0.022619031645633555\n",
      "Val Loss: 0.022423652587113558\n",
      "Starting epoch 1184\n",
      "Train Loss: 0.02249118189016978\n",
      "Val Loss: 0.02232890714097906\n",
      "Starting epoch 1185\n",
      "Train Loss: 0.022656774079358136\n",
      "Val Loss: 0.022387455458994263\n",
      "Starting epoch 1186\n",
      "Train Loss: 0.022667098376486037\n",
      "Val Loss: 0.022508822657443858\n",
      "Starting epoch 1187\n",
      "Train Loss: 0.022511453540236863\n",
      "Val Loss: 0.022793102595541213\n",
      "Starting epoch 1188\n",
      "Train Loss: 0.02253470211117356\n",
      "Val Loss: 0.022874049014515348\n",
      "Starting epoch 1189\n",
      "Train Loss: 0.02250919849784286\n",
      "Val Loss: 0.022510660467324434\n",
      "Starting epoch 1190\n",
      "Train Loss: 0.02269070291960681\n",
      "Val Loss: 0.022523030086799904\n",
      "Starting epoch 1191\n",
      "Train Loss: 0.02241594316782775\n",
      "Val Loss: 0.02261417497087408\n",
      "Starting epoch 1192\n",
      "Train Loss: 0.02259369084128627\n",
      "Val Loss: 0.02255009611447652\n",
      "Starting epoch 1193\n",
      "Train Loss: 0.022535329615628277\n",
      "Val Loss: 0.022905733850267198\n",
      "Starting epoch 1194\n",
      "Train Loss: 0.02255463379400748\n",
      "Val Loss: 0.022465870888144883\n",
      "Starting epoch 1195\n",
      "Train Loss: 0.02261111471388075\n",
      "Val Loss: 0.02251057768309558\n",
      "Starting epoch 1196\n",
      "Train Loss: 0.02233415014213986\n",
      "Val Loss: 0.022497413335023104\n",
      "Starting epoch 1197\n",
      "Train Loss: 0.022428885102272034\n",
      "Val Loss: 0.023213161362542048\n",
      "Starting epoch 1198\n",
      "Train Loss: 0.0230981155678078\n",
      "Val Loss: 0.022691851964703313\n",
      "Starting epoch 1199\n",
      "Train Loss: 0.022445841519920913\n",
      "Val Loss: 0.022478103085800453\n",
      "Starting epoch 1200\n",
      "Train Loss: 0.022494067196492797\n",
      "Val Loss: 0.022384610992890817\n",
      "Starting epoch 1201\n",
      "Train Loss: 0.022454722611992446\n",
      "Val Loss: 0.02262224312181826\n",
      "Starting epoch 1202\n",
      "Train Loss: 0.022558172543843586\n",
      "Val Loss: 0.022749404112497967\n",
      "Starting epoch 1203\n",
      "Train Loss: 0.022859783636199102\n",
      "Val Loss: 0.022851161382816457\n",
      "Starting epoch 1204\n",
      "Train Loss: 0.022904808322588604\n",
      "Val Loss: 0.022495759858025446\n",
      "Starting epoch 1205\n",
      "Train Loss: 0.022383660078048706\n",
      "Val Loss: 0.02245525629432113\n",
      "Starting epoch 1206\n",
      "Train Loss: 0.0226764855561433\n",
      "Val Loss: 0.022415453637087787\n",
      "Starting epoch 1207\n",
      "Train Loss: 0.02248451996732641\n",
      "Val Loss: 0.022470804276289762\n",
      "Starting epoch 1208\n",
      "Train Loss: 0.022549362646208868\n",
      "Val Loss: 0.02236448062790765\n",
      "Starting epoch 1209\n",
      "Train Loss: 0.022422633789203786\n",
      "Val Loss: 0.022476730523286043\n",
      "Starting epoch 1210\n",
      "Train Loss: 0.022455441179098905\n",
      "Val Loss: 0.022469992990846985\n",
      "Starting epoch 1211\n",
      "Train Loss: 0.022539865639474656\n",
      "Val Loss: 0.022535070225044532\n",
      "Starting epoch 1212\n",
      "Train Loss: 0.022366642951965332\n",
      "Val Loss: 0.022412424838101422\n",
      "Starting epoch 1213\n",
      "Train Loss: 0.022966759072409734\n",
      "Val Loss: 0.0225090941897145\n",
      "Starting epoch 1214\n",
      "Train Loss: 0.022451337840822008\n",
      "Val Loss: 0.02256386975447337\n",
      "Starting epoch 1215\n",
      "Train Loss: 0.0226663566297955\n",
      "Val Loss: 0.022449073416215402\n",
      "Starting epoch 1216\n",
      "Train Loss: 0.022530742817454867\n",
      "Val Loss: 0.022587002979384527\n",
      "Starting epoch 1217\n",
      "Train Loss: 0.022438074703569764\n",
      "Val Loss: 0.02261676832481667\n",
      "Starting epoch 1218\n",
      "Train Loss: 0.022447446430170978\n",
      "Val Loss: 0.022481693161858454\n",
      "Starting epoch 1219\n",
      "Train Loss: 0.022329849777398287\n",
      "Val Loss: 0.022528487223166006\n",
      "Starting epoch 1220\n",
      "Train Loss: 0.0226684863920565\n",
      "Val Loss: 0.02246511865545202\n",
      "Starting epoch 1221\n",
      "Train Loss: 0.02256957358784146\n",
      "Val Loss: 0.022526142221909982\n",
      "Starting epoch 1222\n",
      "Train Loss: 0.0227787720936316\n",
      "Val Loss: 0.022464575039015874\n",
      "Starting epoch 1223\n",
      "Train Loss: 0.02247270389839455\n",
      "Val Loss: 0.0224961605336931\n",
      "Starting epoch 1224\n",
      "Train Loss: 0.0223854316605462\n",
      "Val Loss: 0.022432660063107807\n",
      "Starting epoch 1225\n",
      "Train Loss: 0.022453043195936415\n",
      "Val Loss: 0.022421117182131165\n",
      "Starting epoch 1226\n",
      "Train Loss: 0.022838604670983774\n",
      "Val Loss: 0.022367786478113244\n",
      "Starting epoch 1227\n",
      "Train Loss: 0.022531098789638944\n",
      "Val Loss: 0.02244336516768844\n",
      "Starting epoch 1228\n",
      "Train Loss: 0.022488711608780756\n",
      "Val Loss: 0.022496721258869878\n",
      "Starting epoch 1229\n",
      "Train Loss: 0.022421145880663837\n",
      "Val Loss: 0.022300043039851718\n",
      "Starting epoch 1230\n",
      "Train Loss: 0.022456854581832886\n",
      "Val Loss: 0.022545575543686195\n",
      "Starting epoch 1231\n",
      "Train Loss: 0.02246780859099494\n",
      "Val Loss: 0.022445002639735187\n",
      "Starting epoch 1232\n",
      "Train Loss: 0.022453085139945702\n",
      "Val Loss: 0.022347850932015315\n",
      "Starting epoch 1233\n",
      "Train Loss: 0.02224304720207497\n",
      "Val Loss: 0.022364732843858225\n",
      "Starting epoch 1234\n",
      "Train Loss: 0.02240961845274325\n",
      "Val Loss: 0.022368033175115234\n",
      "Starting epoch 1235\n",
      "Train Loss: 0.02237579999146638\n",
      "Val Loss: 0.02235924314569544\n",
      "Starting epoch 1236\n",
      "Train Loss: 0.022292786726245174\n",
      "Val Loss: 0.022326598012888874\n",
      "Starting epoch 1237\n",
      "Train Loss: 0.02241031880731936\n",
      "Val Loss: 0.022505000233650208\n",
      "Starting epoch 1238\n",
      "Train Loss: 0.02235761836723045\n",
      "Val Loss: 0.022404577996995714\n",
      "Starting epoch 1239\n",
      "Train Loss: 0.02230845170992392\n",
      "Val Loss: 0.022710094849268597\n",
      "Starting epoch 1240\n",
      "Train Loss: 0.022211588643215322\n",
      "Val Loss: 0.022489538347279583\n",
      "Starting epoch 1241\n",
      "Train Loss: 0.022367714179886714\n",
      "Val Loss: 0.02237860913629885\n",
      "Starting epoch 1242\n",
      "Train Loss: 0.022436113821135625\n",
      "Val Loss: 0.02230810622374217\n",
      "Starting epoch 1243\n",
      "Train Loss: 0.022315354810820684\n",
      "Val Loss: 0.02256504749810254\n",
      "Starting epoch 1244\n",
      "Train Loss: 0.022239705478703534\n",
      "Val Loss: 0.022430167705924424\n",
      "Starting epoch 1245\n",
      "Train Loss: 0.02234030266602834\n",
      "Val Loss: 0.022485196038528724\n",
      "Starting epoch 1246\n",
      "Train Loss: 0.022276655943305405\n",
      "Val Loss: 0.022378014193640813\n",
      "Starting epoch 1247\n",
      "Train Loss: 0.022285624234764663\n",
      "Val Loss: 0.02270171763720336\n",
      "Starting epoch 1248\n",
      "Train Loss: 0.02230010485207593\n",
      "Val Loss: 0.02246487306223975\n",
      "Starting epoch 1249\n",
      "Train Loss: 0.022497695353296068\n",
      "Val Loss: 0.022430653925295228\n",
      "Starting epoch 1250\n",
      "Train Loss: 0.022590229356730426\n",
      "Val Loss: 0.022693966273908264\n",
      "Starting epoch 1251\n",
      "Train Loss: 0.022658097523230093\n",
      "Val Loss: 0.02231560426729697\n",
      "Starting epoch 1252\n",
      "Train Loss: 0.02218861601970814\n",
      "Val Loss: 0.02222132020526462\n",
      "Starting epoch 1253\n",
      "Train Loss: 0.022337549814471492\n",
      "Val Loss: 0.022354796528816223\n",
      "Starting epoch 1254\n",
      "Train Loss: 0.022391973822205154\n",
      "Val Loss: 0.022155407402250502\n",
      "Starting epoch 1255\n",
      "Train Loss: 0.022359719982853642\n",
      "Val Loss: 0.02225347967059524\n",
      "Starting epoch 1256\n",
      "Train Loss: 0.0223040321358928\n",
      "Val Loss: 0.022498729052367033\n",
      "Starting epoch 1257\n",
      "Train Loss: 0.02233671755702407\n",
      "Val Loss: 0.022327627296800965\n",
      "Starting epoch 1258\n",
      "Train Loss: 0.022665410682007118\n",
      "Val Loss: 0.022472277835563378\n",
      "Starting epoch 1259\n",
      "Train Loss: 0.022382206938884878\n",
      "Val Loss: 0.02227401954156381\n",
      "Starting epoch 1260\n",
      "Train Loss: 0.022290848471500254\n",
      "Val Loss: 0.0223473796138057\n",
      "Starting epoch 1261\n",
      "Train Loss: 0.022165991641857005\n",
      "Val Loss: 0.022540785096309805\n",
      "Starting epoch 1262\n",
      "Train Loss: 0.022383775424074243\n",
      "Val Loss: 0.022444546774581627\n",
      "Starting epoch 1263\n",
      "Train Loss: 0.022193799416224163\n",
      "Val Loss: 0.02221810872907992\n",
      "Starting epoch 1264\n",
      "Train Loss: 0.022322569732312805\n",
      "Val Loss: 0.022413290761135244\n",
      "Starting epoch 1265\n",
      "Train Loss: 0.022612310670040273\n",
      "Val Loss: 0.02230148790059266\n",
      "Starting epoch 1266\n",
      "Train Loss: 0.022423680733751367\n",
      "Val Loss: 0.022235094949051185\n",
      "Starting epoch 1267\n",
      "Train Loss: 0.022430125210020278\n",
      "Val Loss: 0.022322470391238178\n",
      "Starting epoch 1268\n",
      "Train Loss: 0.022363633469299034\n",
      "Val Loss: 0.022214679254425898\n",
      "Starting epoch 1269\n",
      "Train Loss: 0.02235450733591009\n",
      "Val Loss: 0.0222370481049573\n",
      "Starting epoch 1270\n",
      "Train Loss: 0.022278888358010188\n",
      "Val Loss: 0.022259008553293016\n",
      "Starting epoch 1271\n",
      "Train Loss: 0.022213089245337027\n",
      "Val Loss: 0.02234661468753108\n",
      "Starting epoch 1272\n",
      "Train Loss: 0.02211579735632296\n",
      "Val Loss: 0.022522534485216492\n",
      "Starting epoch 1273\n",
      "Train Loss: 0.0225289022481\n",
      "Val Loss: 0.02277317808734046\n",
      "Starting epoch 1274\n",
      "Train Loss: 0.02223155399163564\n",
      "Val Loss: 0.022257954434112267\n",
      "Starting epoch 1275\n",
      "Train Loss: 0.022499173879623413\n",
      "Val Loss: 0.02232606984950878\n",
      "Starting epoch 1276\n",
      "Train Loss: 0.022236998434419984\n",
      "Val Loss: 0.022609229992937158\n",
      "Starting epoch 1277\n",
      "Train Loss: 0.022346464572129427\n",
      "Val Loss: 0.022747978568077087\n",
      "Starting epoch 1278\n",
      "Train Loss: 0.022210245883023297\n",
      "Val Loss: 0.02254733388070707\n",
      "Starting epoch 1279\n",
      "Train Loss: 0.02218251702962098\n",
      "Val Loss: 0.022265942560301885\n",
      "Starting epoch 1280\n",
      "Train Loss: 0.022691030745153076\n",
      "Val Loss: 0.022313993838098314\n",
      "Starting epoch 1281\n",
      "Train Loss: 0.022298769266517075\n",
      "Val Loss: 0.022347879078653123\n",
      "Starting epoch 1282\n",
      "Train Loss: 0.022119783140994883\n",
      "Val Loss: 0.022382088833385043\n",
      "Starting epoch 1283\n",
      "Train Loss: 0.022417739033699036\n",
      "Val Loss: 0.02220516072379218\n",
      "Starting epoch 1284\n",
      "Train Loss: 0.022423118904784874\n",
      "Val Loss: 0.02217133453598729\n",
      "Starting epoch 1285\n",
      "Train Loss: 0.022245531832730328\n",
      "Val Loss: 0.02227335230067924\n",
      "Starting epoch 1286\n",
      "Train Loss: 0.022226547753369366\n",
      "Val Loss: 0.022173348952222754\n",
      "Starting epoch 1287\n",
      "Train Loss: 0.02241749068101247\n",
      "Val Loss: 0.02223981585767534\n",
      "Starting epoch 1288\n",
      "Train Loss: 0.02262176462897548\n",
      "Val Loss: 0.022567427820629544\n",
      "Starting epoch 1289\n",
      "Train Loss: 0.022583962038711266\n",
      "Val Loss: 0.022240031648565223\n",
      "Starting epoch 1290\n",
      "Train Loss: 0.022291093512817665\n",
      "Val Loss: 0.022261756437796133\n",
      "Starting epoch 1291\n",
      "Train Loss: 0.022358841918132925\n",
      "Val Loss: 0.022255879309442308\n",
      "Starting epoch 1292\n",
      "Train Loss: 0.02229864453827893\n",
      "Val Loss: 0.022314267026053533\n",
      "Starting epoch 1293\n",
      "Train Loss: 0.022277260820070904\n",
      "Val Loss: 0.022288454351601778\n",
      "Starting epoch 1294\n",
      "Train Loss: 0.022215329938464694\n",
      "Val Loss: 0.022242223223050434\n",
      "Starting epoch 1295\n",
      "Train Loss: 0.02222575964751067\n",
      "Val Loss: 0.022104158997535706\n",
      "Starting epoch 1296\n",
      "Train Loss: 0.02249194516075982\n",
      "Val Loss: 0.022407846870245756\n",
      "Starting epoch 1297\n",
      "Train Loss: 0.02225687382397828\n",
      "Val Loss: 0.022561945297099924\n",
      "Starting epoch 1298\n",
      "Train Loss: 0.022371392007227296\n",
      "Val Loss: 0.022284461392296687\n",
      "Starting epoch 1299\n",
      "Train Loss: 0.022138124262845074\n",
      "Val Loss: 0.02252857828581775\n",
      "Starting epoch 1300\n",
      "Train Loss: 0.022199957459061233\n",
      "Val Loss: 0.022212901049190097\n",
      "Starting epoch 1301\n",
      "Train Loss: 0.02223397515438221\n",
      "Val Loss: 0.022248542419186345\n",
      "Starting epoch 1302\n",
      "Train Loss: 0.02207340631220076\n",
      "Val Loss: 0.02272032366858588\n",
      "Starting epoch 1303\n",
      "Train Loss: 0.02246771256128947\n",
      "Val Loss: 0.02220165619143733\n",
      "Starting epoch 1304\n",
      "Train Loss: 0.022384149608788668\n",
      "Val Loss: 0.022162712834499502\n",
      "Starting epoch 1305\n",
      "Train Loss: 0.0221854360015304\n",
      "Val Loss: 0.02237496331886009\n",
      "Starting epoch 1306\n",
      "Train Loss: 0.022212149920286955\n",
      "Val Loss: 0.022093642089102004\n",
      "Starting epoch 1307\n",
      "Train Loss: 0.022079275714026556\n",
      "Val Loss: 0.02264564953468464\n",
      "Starting epoch 1308\n",
      "Train Loss: 0.022234748359079713\n",
      "Val Loss: 0.022305214846575702\n",
      "Starting epoch 1309\n",
      "Train Loss: 0.022034470681790954\n",
      "Val Loss: 0.022090092853263573\n",
      "Starting epoch 1310\n",
      "Train Loss: 0.022337333471686753\n",
      "Val Loss: 0.022158503532409668\n",
      "Starting epoch 1311\n",
      "Train Loss: 0.022119667794969346\n",
      "Val Loss: 0.022217738407629507\n",
      "Starting epoch 1312\n",
      "Train Loss: 0.022119970233352097\n",
      "Val Loss: 0.022166025859338266\n",
      "Starting epoch 1313\n",
      "Train Loss: 0.02234474210827439\n",
      "Val Loss: 0.022119644615385268\n",
      "Starting epoch 1314\n",
      "Train Loss: 0.022176146507263184\n",
      "Val Loss: 0.02225764868436036\n",
      "Starting epoch 1315\n",
      "Train Loss: 0.022140661323512043\n",
      "Val Loss: 0.022264724528348004\n",
      "Starting epoch 1316\n",
      "Train Loss: 0.0222142791306531\n",
      "Val Loss: 0.022047044502364263\n",
      "Starting epoch 1317\n",
      "Train Loss: 0.022147787941826716\n",
      "Val Loss: 0.02217740758701607\n",
      "Starting epoch 1318\n",
      "Train Loss: 0.022229597524360375\n",
      "Val Loss: 0.02226509264221898\n",
      "Starting epoch 1319\n",
      "Train Loss: 0.022180471707273414\n",
      "Val Loss: 0.022213363537081966\n",
      "Starting epoch 1320\n",
      "Train Loss: 0.02216385360117312\n",
      "Val Loss: 0.022084871927897137\n",
      "Starting epoch 1321\n",
      "Train Loss: 0.02228959732585483\n",
      "Val Loss: 0.022544504867659673\n",
      "Starting epoch 1322\n",
      "Train Loss: 0.022052063986107154\n",
      "Val Loss: 0.02223705362390589\n",
      "Starting epoch 1323\n",
      "Train Loss: 0.022252190996099402\n",
      "Val Loss: 0.02212661063229596\n",
      "Starting epoch 1324\n",
      "Train Loss: 0.02215143817442435\n",
      "Val Loss: 0.02210221963900107\n",
      "Starting epoch 1325\n",
      "Train Loss: 0.02224374258959735\n",
      "Val Loss: 0.022164264210948238\n",
      "Starting epoch 1326\n",
      "Train Loss: 0.022236469167250174\n",
      "Val Loss: 0.022122728603857535\n",
      "Starting epoch 1327\n",
      "Train Loss: 0.022013109591272142\n",
      "Val Loss: 0.022227040043583623\n",
      "Starting epoch 1328\n",
      "Train Loss: 0.022543233301904466\n",
      "Val Loss: 0.022303673956129286\n",
      "Starting epoch 1329\n",
      "Train Loss: 0.022108537179452402\n",
      "Val Loss: 0.022275075316429138\n",
      "Starting epoch 1330\n",
      "Train Loss: 0.022184511577641522\n",
      "Val Loss: 0.022487995249253732\n",
      "Starting epoch 1331\n",
      "Train Loss: 0.022208611170450848\n",
      "Val Loss: 0.022069232331381902\n",
      "Starting epoch 1332\n",
      "Train Loss: 0.02211510141690572\n",
      "Val Loss: 0.022580890191925898\n",
      "Starting epoch 1333\n",
      "Train Loss: 0.02221659267390216\n",
      "Val Loss: 0.022501840083687392\n",
      "Starting epoch 1334\n",
      "Train Loss: 0.022161706178276626\n",
      "Val Loss: 0.022124210993448894\n",
      "Starting epoch 1335\n",
      "Train Loss: 0.022085494465298124\n",
      "Val Loss: 0.02210039617838683\n",
      "Starting epoch 1336\n",
      "Train Loss: 0.022094843012315256\n",
      "Val Loss: 0.022159728738996718\n",
      "Starting epoch 1337\n",
      "Train Loss: 0.022258694525118226\n",
      "Val Loss: 0.02220352601121973\n",
      "Starting epoch 1338\n",
      "Train Loss: 0.02204462720288171\n",
      "Val Loss: 0.022191161910692852\n",
      "Starting epoch 1339\n",
      "Train Loss: 0.022161094678772822\n",
      "Val Loss: 0.021996755842809326\n",
      "Starting epoch 1340\n",
      "Train Loss: 0.022146095832188923\n",
      "Val Loss: 0.02212770614359114\n",
      "Starting epoch 1341\n",
      "Train Loss: 0.022147935849648935\n",
      "Val Loss: 0.0221566508213679\n",
      "Starting epoch 1342\n",
      "Train Loss: 0.022165884574254353\n",
      "Val Loss: 0.022310840310873808\n",
      "Starting epoch 1343\n",
      "Train Loss: 0.02223218039230064\n",
      "Val Loss: 0.02209483914905124\n",
      "Starting epoch 1344\n",
      "Train Loss: 0.022036161135744164\n",
      "Val Loss: 0.0221807857354482\n",
      "Starting epoch 1345\n",
      "Train Loss: 0.02221310414649822\n",
      "Val Loss: 0.02246573070685069\n",
      "Starting epoch 1346\n",
      "Train Loss: 0.02215201214507774\n",
      "Val Loss: 0.022040970347545766\n",
      "Starting epoch 1347\n",
      "Train Loss: 0.0220842769852391\n",
      "Val Loss: 0.02203439893545928\n",
      "Starting epoch 1348\n",
      "Train Loss: 0.02205239843439173\n",
      "Val Loss: 0.022040657423160696\n",
      "Starting epoch 1349\n",
      "Train Loss: 0.02225448798250269\n",
      "Val Loss: 0.02215791631627966\n",
      "Starting epoch 1350\n",
      "Train Loss: 0.022106454880149277\n",
      "Val Loss: 0.02208766561967355\n",
      "Starting epoch 1351\n",
      "Train Loss: 0.022170395210937218\n",
      "Val Loss: 0.02218872363920565\n",
      "Starting epoch 1352\n",
      "Train Loss: 0.022135194253038476\n",
      "Val Loss: 0.022072319079328467\n",
      "Starting epoch 1353\n",
      "Train Loss: 0.022113662075113366\n",
      "Val Loss: 0.022109269543930336\n",
      "Starting epoch 1354\n",
      "Train Loss: 0.02216190375663616\n",
      "Val Loss: 0.022037545288050617\n",
      "Starting epoch 1355\n",
      "Train Loss: 0.02208193088019336\n",
      "Val Loss: 0.02223889695273505\n",
      "Starting epoch 1356\n",
      "Train Loss: 0.02207507413846475\n",
      "Val Loss: 0.02201687737747475\n",
      "Starting epoch 1357\n",
      "Train Loss: 0.022115401647709036\n",
      "Val Loss: 0.022096365138336464\n",
      "Starting epoch 1358\n",
      "Train Loss: 0.022031539016299777\n",
      "Val Loss: 0.02230518062909444\n",
      "Starting epoch 1359\n",
      "Train Loss: 0.022092287187223083\n",
      "Val Loss: 0.022206953278294316\n",
      "Starting epoch 1360\n",
      "Train Loss: 0.022229545646243624\n",
      "Val Loss: 0.022183621371233905\n",
      "Starting epoch 1361\n",
      "Train Loss: 0.022091713768464548\n",
      "Val Loss: 0.022106545390906156\n",
      "Starting epoch 1362\n",
      "Train Loss: 0.022408131647993018\n",
      "Val Loss: 0.022026770092822886\n",
      "Starting epoch 1363\n",
      "Train Loss: 0.022158989751780475\n",
      "Val Loss: 0.02193054832794048\n",
      "Starting epoch 1364\n",
      "Train Loss: 0.022004027057577064\n",
      "Val Loss: 0.022199294633335538\n",
      "Starting epoch 1365\n",
      "Train Loss: 0.022398368627936753\n",
      "Val Loss: 0.022077110630494577\n",
      "Starting epoch 1366\n",
      "Train Loss: 0.022080217798550923\n",
      "Val Loss: 0.021938347706088313\n",
      "Starting epoch 1367\n",
      "Train Loss: 0.0220925725168652\n",
      "Val Loss: 0.02198553416464064\n",
      "Starting epoch 1368\n",
      "Train Loss: 0.02207909138114364\n",
      "Val Loss: 0.02250116014922107\n",
      "Starting epoch 1369\n",
      "Train Loss: 0.022025773922602337\n",
      "Val Loss: 0.02236164168075279\n",
      "Starting epoch 1370\n",
      "Train Loss: 0.021927372173026757\n",
      "Val Loss: 0.022004152337710064\n",
      "Starting epoch 1371\n",
      "Train Loss: 0.022004721893204585\n",
      "Val Loss: 0.02202224510687369\n",
      "Starting epoch 1372\n",
      "Train Loss: 0.021988985715089022\n",
      "Val Loss: 0.0219843829119647\n",
      "Starting epoch 1373\n",
      "Train Loss: 0.022230200745441294\n",
      "Val Loss: 0.022121097202654236\n",
      "Starting epoch 1374\n",
      "Train Loss: 0.022056087299629493\n",
      "Val Loss: 0.021995827003761573\n",
      "Starting epoch 1375\n",
      "Train Loss: 0.02203096835701554\n",
      "Val Loss: 0.022012587498735497\n",
      "Starting epoch 1376\n",
      "Train Loss: 0.02210155736517023\n",
      "Val Loss: 0.02206923950601507\n",
      "Starting epoch 1377\n",
      "Train Loss: 0.0221319689794823\n",
      "Val Loss: 0.022219437691900466\n",
      "Starting epoch 1378\n",
      "Train Loss: 0.021922211404199952\n",
      "Val Loss: 0.022425678041246202\n",
      "Starting epoch 1379\n",
      "Train Loss: 0.02212868575696592\n",
      "Val Loss: 0.022101925479041204\n",
      "Starting epoch 1380\n",
      "Train Loss: 0.02204995850721995\n",
      "Val Loss: 0.022577085980662593\n",
      "Starting epoch 1381\n",
      "Train Loss: 0.02209912074936761\n",
      "Val Loss: 0.022155947707317495\n",
      "Starting epoch 1382\n",
      "Train Loss: 0.022315419934414053\n",
      "Val Loss: 0.02198621741047612\n",
      "Starting epoch 1383\n",
      "Train Loss: 0.02240253929738645\n",
      "Val Loss: 0.022063071529070537\n",
      "Starting epoch 1384\n",
      "Train Loss: 0.022070579506732798\n",
      "Val Loss: 0.02204591477358783\n",
      "Starting epoch 1385\n",
      "Train Loss: 0.02225936507737195\n",
      "Val Loss: 0.021906816297107272\n",
      "Starting epoch 1386\n",
      "Train Loss: 0.02198105001891101\n",
      "Val Loss: 0.022046416997909546\n",
      "Starting epoch 1387\n",
      "Train Loss: 0.022405301531155903\n",
      "Val Loss: 0.02193897521054303\n",
      "Starting epoch 1388\n",
      "Train Loss: 0.022123104444256535\n",
      "Val Loss: 0.022018392328862792\n",
      "Starting epoch 1389\n",
      "Train Loss: 0.02200715685332263\n",
      "Val Loss: 0.022349756624963548\n",
      "Starting epoch 1390\n",
      "Train Loss: 0.0220551038229907\n",
      "Val Loss: 0.02205925186475118\n",
      "Starting epoch 1391\n",
      "Train Loss: 0.022300710832631146\n",
      "Val Loss: 0.022132438090112474\n",
      "Starting epoch 1392\n",
      "Train Loss: 0.02217924760447608\n",
      "Val Loss: 0.021958404117160372\n",
      "Starting epoch 1393\n",
      "Train Loss: 0.022118056813875835\n",
      "Val Loss: 0.021863478201406973\n",
      "Starting epoch 1394\n",
      "Train Loss: 0.021993968221876357\n",
      "Val Loss: 0.021987371422626353\n",
      "Starting epoch 1395\n",
      "Train Loss: 0.022032691372765437\n",
      "Val Loss: 0.022043486436208088\n",
      "Starting epoch 1396\n",
      "Train Loss: 0.022166750497288175\n",
      "Val Loss: 0.022090556996840018\n",
      "Starting epoch 1397\n",
      "Train Loss: 0.022045749757024977\n",
      "Val Loss: 0.02220294541782803\n",
      "Starting epoch 1398\n",
      "Train Loss: 0.02206324703163571\n",
      "Val Loss: 0.021983746025297377\n",
      "Starting epoch 1399\n",
      "Train Loss: 0.02191197430645978\n",
      "Val Loss: 0.022165906098153856\n",
      "Starting epoch 1400\n",
      "Train Loss: 0.022056519433304115\n",
      "Val Loss: 0.022379785224243446\n",
      "Starting epoch 1401\n",
      "Train Loss: 0.02198086623792295\n",
      "Val Loss: 0.02219304828732102\n",
      "Starting epoch 1402\n",
      "Train Loss: 0.021872399581803217\n",
      "Val Loss: 0.022427175331998755\n",
      "Starting epoch 1403\n",
      "Train Loss: 0.021939185482484323\n",
      "Val Loss: 0.022145111803655273\n",
      "Starting epoch 1404\n",
      "Train Loss: 0.02201504839791192\n",
      "Val Loss: 0.022181103626887005\n",
      "Starting epoch 1405\n",
      "Train Loss: 0.021931224399142794\n",
      "Val Loss: 0.022003911159656667\n",
      "Starting epoch 1406\n",
      "Train Loss: 0.021966841485765245\n",
      "Val Loss: 0.022008856137593586\n",
      "Starting epoch 1407\n",
      "Train Loss: 0.02194990383254157\n",
      "Val Loss: 0.021983888966065866\n",
      "Starting epoch 1408\n",
      "Train Loss: 0.021955082813898723\n",
      "Val Loss: 0.021995572580231562\n",
      "Starting epoch 1409\n",
      "Train Loss: 0.02199269444854171\n",
      "Val Loss: 0.02202964049798471\n",
      "Starting epoch 1410\n",
      "Train Loss: 0.022008175651232403\n",
      "Val Loss: 0.02209537007190563\n",
      "Starting epoch 1411\n",
      "Train Loss: 0.022002258234553866\n",
      "Val Loss: 0.021884816664236563\n",
      "Starting epoch 1412\n",
      "Train Loss: 0.02204320772930428\n",
      "Val Loss: 0.02191697116251345\n",
      "Starting epoch 1413\n",
      "Train Loss: 0.02197414360664509\n",
      "Val Loss: 0.021969698093555593\n",
      "Starting epoch 1414\n",
      "Train Loss: 0.021872977415720623\n",
      "Val Loss: 0.022589829784852487\n",
      "Starting epoch 1415\n",
      "Train Loss: 0.021973473054391367\n",
      "Val Loss: 0.022123457656966314\n",
      "Starting epoch 1416\n",
      "Train Loss: 0.021881269084082708\n",
      "Val Loss: 0.022008013946038706\n",
      "Starting epoch 1417\n",
      "Train Loss: 0.02188782173174399\n",
      "Val Loss: 0.022233601521562646\n",
      "Starting epoch 1418\n",
      "Train Loss: 0.022032678679183678\n",
      "Val Loss: 0.021958722560494033\n",
      "Starting epoch 1419\n",
      "Train Loss: 0.021910688943333097\n",
      "Val Loss: 0.02198713465973183\n",
      "Starting epoch 1420\n",
      "Train Loss: 0.022272454919638456\n",
      "Val Loss: 0.02216557992829217\n",
      "Starting epoch 1421\n",
      "Train Loss: 0.021869425972302754\n",
      "Val Loss: 0.022033313358271564\n",
      "Starting epoch 1422\n",
      "Train Loss: 0.02201119617179588\n",
      "Val Loss: 0.022068150065563345\n",
      "Starting epoch 1423\n",
      "Train Loss: 0.02190502263881542\n",
      "Val Loss: 0.021938614271305227\n",
      "Starting epoch 1424\n",
      "Train Loss: 0.022044759105753015\n",
      "Val Loss: 0.0222761912478341\n",
      "Starting epoch 1425\n",
      "Train Loss: 0.02191987633705139\n",
      "Val Loss: 0.021891181115750915\n",
      "Starting epoch 1426\n",
      "Train Loss: 0.021923623151249357\n",
      "Val Loss: 0.0219090790660293\n",
      "Starting epoch 1427\n",
      "Train Loss: 0.021897134957490145\n",
      "Val Loss: 0.021852338203677425\n",
      "Starting epoch 1428\n",
      "Train Loss: 0.021911539413310862\n",
      "Val Loss: 0.02240383790598975\n",
      "Starting epoch 1429\n",
      "Train Loss: 0.02217217672754217\n",
      "Val Loss: 0.021877891487545438\n",
      "Starting epoch 1430\n",
      "Train Loss: 0.02193833390871684\n",
      "Val Loss: 0.022402913482100877\n",
      "Starting epoch 1431\n",
      "Train Loss: 0.02188997632927365\n",
      "Val Loss: 0.021902226739459567\n",
      "Starting epoch 1432\n",
      "Train Loss: 0.021910569734043546\n",
      "Val Loss: 0.021970310144954257\n",
      "Starting epoch 1433\n",
      "Train Loss: 0.022013000316090055\n",
      "Val Loss: 0.021969584955109492\n",
      "Starting epoch 1434\n",
      "Train Loss: 0.022195904343216506\n",
      "Val Loss: 0.02214160837509014\n",
      "Starting epoch 1435\n",
      "Train Loss: 0.021884354728239554\n",
      "Val Loss: 0.021872073963836388\n",
      "Starting epoch 1436\n",
      "Train Loss: 0.02198262347115411\n",
      "Val Loss: 0.02210314185531051\n",
      "Starting epoch 1437\n",
      "Train Loss: 0.022165353099505108\n",
      "Val Loss: 0.022381715752460337\n",
      "Starting epoch 1438\n",
      "Train Loss: 0.021857187703803734\n",
      "Val Loss: 0.022016149428155687\n",
      "Starting epoch 1439\n",
      "Train Loss: 0.022105676156503183\n",
      "Val Loss: 0.0221640478681635\n",
      "Starting epoch 1440\n",
      "Train Loss: 0.021990842841289663\n",
      "Val Loss: 0.021851956292434974\n",
      "Starting epoch 1441\n",
      "Train Loss: 0.022040880388683744\n",
      "Val Loss: 0.021862977080874972\n",
      "Starting epoch 1442\n",
      "Train Loss: 0.02195817121752986\n",
      "Val Loss: 0.02210386649326042\n",
      "Starting epoch 1443\n",
      "Train Loss: 0.021920922729704116\n",
      "Val Loss: 0.021939195968486643\n",
      "Starting epoch 1444\n",
      "Train Loss: 0.022057574656274583\n",
      "Val Loss: 0.021862499139927053\n",
      "Starting epoch 1445\n",
      "Train Loss: 0.021902632382180955\n",
      "Val Loss: 0.0218075778749254\n",
      "Starting epoch 1446\n",
      "Train Loss: 0.021885085437032912\n",
      "Val Loss: 0.021825045347213745\n",
      "Starting epoch 1447\n",
      "Train Loss: 0.021874914014780963\n",
      "Val Loss: 0.021980265776316326\n",
      "Starting epoch 1448\n",
      "Train Loss: 0.0219631509648429\n",
      "Val Loss: 0.021847745886555425\n",
      "Starting epoch 1449\n",
      "Train Loss: 0.02202406249664448\n",
      "Val Loss: 0.021831729345851474\n",
      "Starting epoch 1450\n",
      "Train Loss: 0.021918751023433828\n",
      "Val Loss: 0.021962859012462473\n",
      "Starting epoch 1451\n",
      "Train Loss: 0.02189160441910779\n",
      "Val Loss: 0.021933109120086388\n",
      "Starting epoch 1452\n",
      "Train Loss: 0.021908806981863798\n",
      "Val Loss: 0.02186218676743684\n",
      "Starting epoch 1453\n",
      "Train Loss: 0.02208412962931174\n",
      "Val Loss: 0.021854207471564965\n",
      "Starting epoch 1454\n",
      "Train Loss: 0.021859404113557603\n",
      "Val Loss: 0.022053270980163856\n",
      "Starting epoch 1455\n",
      "Train Loss: 0.021927823623021443\n",
      "Val Loss: 0.021906087795893352\n",
      "Starting epoch 1456\n",
      "Train Loss: 0.022369051973025005\n",
      "Val Loss: 0.021927895369353117\n",
      "Starting epoch 1457\n",
      "Train Loss: 0.02191067073080275\n",
      "Val Loss: 0.02175905031186563\n",
      "Starting epoch 1458\n",
      "Train Loss: 0.021892616042384395\n",
      "Val Loss: 0.02197377383708954\n",
      "Starting epoch 1459\n",
      "Train Loss: 0.02178126518373136\n",
      "Val Loss: 0.02194214363892873\n",
      "Starting epoch 1460\n",
      "Train Loss: 0.021950960159301758\n",
      "Val Loss: 0.02190793443609167\n",
      "Starting epoch 1461\n",
      "Train Loss: 0.021878831916385226\n",
      "Val Loss: 0.02194354655566039\n",
      "Starting epoch 1462\n",
      "Train Loss: 0.021963520734398452\n",
      "Val Loss: 0.021781176328659058\n",
      "Starting epoch 1463\n",
      "Train Loss: 0.021989223029878404\n",
      "Val Loss: 0.022005380855666265\n",
      "Starting epoch 1464\n",
      "Train Loss: 0.021982489360703364\n",
      "Val Loss: 0.02185347455519217\n",
      "Starting epoch 1465\n",
      "Train Loss: 0.02192857199245029\n",
      "Val Loss: 0.0221002322656137\n",
      "Starting epoch 1466\n",
      "Train Loss: 0.022007792636200233\n",
      "Val Loss: 0.021961678509359008\n",
      "Starting epoch 1467\n",
      "Train Loss: 0.021998196840286255\n",
      "Val Loss: 0.02179808031629633\n",
      "Starting epoch 1468\n",
      "Train Loss: 0.02186403175195058\n",
      "Val Loss: 0.021955227410351788\n",
      "Starting epoch 1469\n",
      "Train Loss: 0.02208394584832368\n",
      "Val Loss: 0.02197738709273162\n",
      "Starting epoch 1470\n",
      "Train Loss: 0.021944288854245788\n",
      "Val Loss: 0.021915003657341003\n",
      "Starting epoch 1471\n",
      "Train Loss: 0.021813335242094816\n",
      "Val Loss: 0.021772334973017376\n",
      "Starting epoch 1472\n",
      "Train Loss: 0.021835754866953248\n",
      "Val Loss: 0.021756695928397\n",
      "Starting epoch 1473\n",
      "Train Loss: 0.021753080465175486\n",
      "Val Loss: 0.021877493571352075\n",
      "Starting epoch 1474\n",
      "Train Loss: 0.02177848473743156\n",
      "Val Loss: 0.02183827813024874\n",
      "Starting epoch 1475\n",
      "Train Loss: 0.021806874208980136\n",
      "Val Loss: 0.021832699025118793\n",
      "Starting epoch 1476\n",
      "Train Loss: 0.02213774014402319\n",
      "Val Loss: 0.02196485024911386\n",
      "Starting epoch 1477\n",
      "Train Loss: 0.021772626373502944\n",
      "Val Loss: 0.021880041118021363\n",
      "Starting epoch 1478\n",
      "Train Loss: 0.022322430102913467\n",
      "Val Loss: 0.02177895881511547\n",
      "Starting epoch 1479\n",
      "Train Loss: 0.021833233811237193\n",
      "Val Loss: 0.02187194702801881\n",
      "Starting epoch 1480\n",
      "Train Loss: 0.02211936425279688\n",
      "Val Loss: 0.02187030017375946\n",
      "Starting epoch 1481\n",
      "Train Loss: 0.021758479652581392\n",
      "Val Loss: 0.021734774112701416\n",
      "Starting epoch 1482\n",
      "Train Loss: 0.02178953808766824\n",
      "Val Loss: 0.022173417387185274\n",
      "Starting epoch 1483\n",
      "Train Loss: 0.021834200731030217\n",
      "Val Loss: 0.021849651027608802\n",
      "Starting epoch 1484\n",
      "Train Loss: 0.02220220035976834\n",
      "Val Loss: 0.021812340727558843\n",
      "Starting epoch 1485\n",
      "Train Loss: 0.021869408311667265\n",
      "Val Loss: 0.021869180930985346\n",
      "Starting epoch 1486\n",
      "Train Loss: 0.02185924627162792\n",
      "Val Loss: 0.021902688675456576\n",
      "Starting epoch 1487\n",
      "Train Loss: 0.02221627367867364\n",
      "Val Loss: 0.021813461074122676\n",
      "Starting epoch 1488\n",
      "Train Loss: 0.021757448712984722\n",
      "Val Loss: 0.02230984193307382\n",
      "Starting epoch 1489\n",
      "Train Loss: 0.021830755251425284\n",
      "Val Loss: 0.022038060757848952\n",
      "Starting epoch 1490\n",
      "Train Loss: 0.021838678805916396\n",
      "Val Loss: 0.021860641461831552\n",
      "Starting epoch 1491\n",
      "Train Loss: 0.021908382574717205\n",
      "Val Loss: 0.02175830911706995\n",
      "Starting epoch 1492\n",
      "Train Loss: 0.02179314582436173\n",
      "Val Loss: 0.022197877367337544\n",
      "Starting epoch 1493\n",
      "Train Loss: 0.021821321160705003\n",
      "Val Loss: 0.021995068148330407\n",
      "Starting epoch 1494\n",
      "Train Loss: 0.02192455419787654\n",
      "Val Loss: 0.021847963885024742\n",
      "Starting epoch 1495\n",
      "Train Loss: 0.0217132568359375\n",
      "Val Loss: 0.02176950485618026\n",
      "Starting epoch 1496\n",
      "Train Loss: 0.021993626598958618\n",
      "Val Loss: 0.021722480102821632\n",
      "Starting epoch 1497\n",
      "Train Loss: 0.021744661309100962\n",
      "Val Loss: 0.02179446761254911\n",
      "Starting epoch 1498\n",
      "Train Loss: 0.02192631087921284\n",
      "Val Loss: 0.022053044703271654\n",
      "Starting epoch 1499\n",
      "Train Loss: 0.02187450009363669\n",
      "Val Loss: 0.021707566248046026\n",
      "Starting epoch 1500\n",
      "Train Loss: 0.021873186583872193\n",
      "Val Loss: 0.021835233878206323\n",
      "Starting epoch 1501\n",
      "Train Loss: 0.021869449703781692\n",
      "Val Loss: 0.021736573841836717\n",
      "Starting epoch 1502\n",
      "Train Loss: 0.02219823389141648\n",
      "Val Loss: 0.02217800473725354\n",
      "Starting epoch 1503\n",
      "Train Loss: 0.021755123028048762\n",
      "Val Loss: 0.02182331570872554\n",
      "Starting epoch 1504\n",
      "Train Loss: 0.02191653185420566\n",
      "Val Loss: 0.021790355443954468\n",
      "Starting epoch 1505\n",
      "Train Loss: 0.021782825390497845\n",
      "Val Loss: 0.021909261191332782\n",
      "Starting epoch 1506\n",
      "Train Loss: 0.021755047418453074\n",
      "Val Loss: 0.021813754682187683\n",
      "Starting epoch 1507\n",
      "Train Loss: 0.02181443847991802\n",
      "Val Loss: 0.021907847236703942\n",
      "Starting epoch 1508\n",
      "Train Loss: 0.022071554153053848\n",
      "Val Loss: 0.021698928541607328\n",
      "Starting epoch 1509\n",
      "Train Loss: 0.021798757491288363\n",
      "Val Loss: 0.02216585808330112\n",
      "Starting epoch 1510\n",
      "Train Loss: 0.021883281292738737\n",
      "Val Loss: 0.02222590093259458\n",
      "Starting epoch 1511\n",
      "Train Loss: 0.021781200612032856\n",
      "Val Loss: 0.021765035059716966\n",
      "Starting epoch 1512\n",
      "Train Loss: 0.022074878767684655\n",
      "Val Loss: 0.02187859239401641\n",
      "Starting epoch 1513\n",
      "Train Loss: 0.021825095569645916\n",
      "Val Loss: 0.02179912394947476\n",
      "Starting epoch 1514\n",
      "Train Loss: 0.02209752025427642\n",
      "Val Loss: 0.021723100984538044\n",
      "Starting epoch 1515\n",
      "Train Loss: 0.021937530349802087\n",
      "Val Loss: 0.021943874381206655\n",
      "Starting epoch 1516\n",
      "Train Loss: 0.021855652884200768\n",
      "Val Loss: 0.021883606358810707\n",
      "Starting epoch 1517\n",
      "Train Loss: 0.0217530291389536\n",
      "Val Loss: 0.02180140217145284\n",
      "Starting epoch 1518\n",
      "Train Loss: 0.021782692935731676\n",
      "Val Loss: 0.02180099818441603\n",
      "Starting epoch 1519\n",
      "Train Loss: 0.021831929131790443\n",
      "Val Loss: 0.022052296333842807\n",
      "Starting epoch 1520\n",
      "Train Loss: 0.022258814838197496\n",
      "Val Loss: 0.02190827661090427\n",
      "Starting epoch 1521\n",
      "Train Loss: 0.022200648431424743\n",
      "Val Loss: 0.021790555229893437\n",
      "Starting epoch 1522\n",
      "Train Loss: 0.0219200419055091\n",
      "Val Loss: 0.021799033438717877\n",
      "Starting epoch 1523\n",
      "Train Loss: 0.02173125081592136\n",
      "Val Loss: 0.021772723506998132\n",
      "Starting epoch 1524\n",
      "Train Loss: 0.022051466835869685\n",
      "Val Loss: 0.021765471056655602\n",
      "Starting epoch 1525\n",
      "Train Loss: 0.021805782009054114\n",
      "Val Loss: 0.021774846094625967\n",
      "Starting epoch 1526\n",
      "Train Loss: 0.021957268869435345\n",
      "Val Loss: 0.02179129918416341\n",
      "Starting epoch 1527\n",
      "Train Loss: 0.021787982296060632\n",
      "Val Loss: 0.022100641771599098\n",
      "Starting epoch 1528\n",
      "Train Loss: 0.021695837378501892\n",
      "Val Loss: 0.021663780013720196\n",
      "Starting epoch 1529\n",
      "Train Loss: 0.022353380366607948\n",
      "Val Loss: 0.021710798696235375\n",
      "Starting epoch 1530\n",
      "Train Loss: 0.021668088656884653\n",
      "Val Loss: 0.02176679450052756\n",
      "Starting epoch 1531\n",
      "Train Loss: 0.02209195273893851\n",
      "Val Loss: 0.02179148296515147\n",
      "Starting epoch 1532\n",
      "Train Loss: 0.02209756826912915\n",
      "Val Loss: 0.021757833935596323\n",
      "Starting epoch 1533\n",
      "Train Loss: 0.021687253205864516\n",
      "Val Loss: 0.02195073608998899\n",
      "Starting epoch 1534\n",
      "Train Loss: 0.02196952755804415\n",
      "Val Loss: 0.021886115272839863\n",
      "Starting epoch 1535\n",
      "Train Loss: 0.021912087444905883\n",
      "Val Loss: 0.022119541962941486\n",
      "Starting epoch 1536\n",
      "Train Loss: 0.021706240596594633\n",
      "Val Loss: 0.021887681550449796\n",
      "Starting epoch 1537\n",
      "Train Loss: 0.02179511664090333\n",
      "Val Loss: 0.02181734475824568\n",
      "Starting epoch 1538\n",
      "Train Loss: 0.02181736241888117\n",
      "Val Loss: 0.021835040163110803\n",
      "Starting epoch 1539\n",
      "Train Loss: 0.02194095264982294\n",
      "Val Loss: 0.021742454833454557\n",
      "Starting epoch 1540\n",
      "Train Loss: 0.021898250337000245\n",
      "Val Loss: 0.02182635444181937\n",
      "Starting epoch 1541\n",
      "Train Loss: 0.02239584591653612\n",
      "Val Loss: 0.02182098008968212\n",
      "Starting epoch 1542\n",
      "Train Loss: 0.021821586622132197\n",
      "Val Loss: 0.021867386720798635\n",
      "Starting epoch 1543\n",
      "Train Loss: 0.021972990146389714\n",
      "Val Loss: 0.021787084915019846\n",
      "Starting epoch 1544\n",
      "Train Loss: 0.02175184808395527\n",
      "Val Loss: 0.02175181441836887\n",
      "Starting epoch 1545\n",
      "Train Loss: 0.021814853504852013\n",
      "Val Loss: 0.021901239399556762\n",
      "Starting epoch 1546\n",
      "Train Loss: 0.021785446891078242\n",
      "Val Loss: 0.02173996799521976\n",
      "Starting epoch 1547\n",
      "Train Loss: 0.021693927270394785\n",
      "Val Loss: 0.02180673568337052\n",
      "Starting epoch 1548\n",
      "Train Loss: 0.02181464323291072\n",
      "Val Loss: 0.02172928993348722\n",
      "Starting epoch 1549\n",
      "Train Loss: 0.021928328606817458\n",
      "Val Loss: 0.02183599383742721\n",
      "Starting epoch 1550\n",
      "Train Loss: 0.0219682686858707\n",
      "Val Loss: 0.022108537179452402\n",
      "Starting epoch 1551\n",
      "Train Loss: 0.021804903392438537\n",
      "Val Loss: 0.021837044645238807\n",
      "Starting epoch 1552\n",
      "Train Loss: 0.02190760274728139\n",
      "Val Loss: 0.021856586690302247\n",
      "Starting epoch 1553\n",
      "Train Loss: 0.02167265503494828\n",
      "Val Loss: 0.022105304731263056\n",
      "Starting epoch 1554\n",
      "Train Loss: 0.02216718042338336\n",
      "Val Loss: 0.02167932689189911\n",
      "Starting epoch 1555\n",
      "Train Loss: 0.02172685773284347\n",
      "Val Loss: 0.02174395709126084\n",
      "Starting epoch 1556\n",
      "Train Loss: 0.021838582776210928\n",
      "Val Loss: 0.021849095821380615\n",
      "Starting epoch 1557\n",
      "Train Loss: 0.021752775819213303\n",
      "Val Loss: 0.02200266718864441\n",
      "Starting epoch 1558\n",
      "Train Loss: 0.02176426240691432\n",
      "Val Loss: 0.02170717164322182\n",
      "Starting epoch 1559\n",
      "Train Loss: 0.021697767906718783\n",
      "Val Loss: 0.021778755717807345\n",
      "Starting epoch 1560\n",
      "Train Loss: 0.021717346928737783\n",
      "Val Loss: 0.021769188620426035\n",
      "Starting epoch 1561\n",
      "Train Loss: 0.021649281183878582\n",
      "Val Loss: 0.021754955252011616\n",
      "Starting epoch 1562\n",
      "Train Loss: 0.021673983445873967\n",
      "Val Loss: 0.021818807279622113\n",
      "Starting epoch 1563\n",
      "Train Loss: 0.021684399909443326\n",
      "Val Loss: 0.02165173159705268\n",
      "Starting epoch 1564\n",
      "Train Loss: 0.02178041085048958\n",
      "Val Loss: 0.02177389297220442\n",
      "Starting epoch 1565\n",
      "Train Loss: 0.021647855639457703\n",
      "Val Loss: 0.02172605969287731\n",
      "Starting epoch 1566\n",
      "Train Loss: 0.021776625955546344\n",
      "Val Loss: 0.021708040325729934\n",
      "Starting epoch 1567\n",
      "Train Loss: 0.021697413590219285\n",
      "Val Loss: 0.021628852243776673\n",
      "Starting epoch 1568\n",
      "Train Loss: 0.021748341895915842\n",
      "Val Loss: 0.02189854946401384\n",
      "Starting epoch 1569\n",
      "Train Loss: 0.02170455069453628\n",
      "Val Loss: 0.022067162725660536\n",
      "Starting epoch 1570\n",
      "Train Loss: 0.021622203014515066\n",
      "Val Loss: 0.02210236865061301\n",
      "Starting epoch 1571\n",
      "Train Loss: 0.021888074499589426\n",
      "Val Loss: 0.021982476667121605\n",
      "Starting epoch 1572\n",
      "Train Loss: 0.021709942707309016\n",
      "Val Loss: 0.02172191109922197\n",
      "Starting epoch 1573\n",
      "Train Loss: 0.021732040025569773\n",
      "Val Loss: 0.02185970820762493\n",
      "Starting epoch 1574\n",
      "Train Loss: 0.021801035713266442\n",
      "Val Loss: 0.021624778155927307\n",
      "Starting epoch 1575\n",
      "Train Loss: 0.021658657325638667\n",
      "Val Loss: 0.0217657337586085\n",
      "Starting epoch 1576\n",
      "Train Loss: 0.02193313671482934\n",
      "Val Loss: 0.021817709560747498\n",
      "Starting epoch 1577\n",
      "Train Loss: 0.021750346929938706\n",
      "Val Loss: 0.02164109327174999\n",
      "Starting epoch 1578\n",
      "Train Loss: 0.021631309831583942\n",
      "Val Loss: 0.02165835764673021\n",
      "Starting epoch 1579\n",
      "Train Loss: 0.02174886895550622\n",
      "Val Loss: 0.021637847026189167\n",
      "Starting epoch 1580\n",
      "Train Loss: 0.021677614362151536\n",
      "Val Loss: 0.021896844108899433\n",
      "Starting epoch 1581\n",
      "Train Loss: 0.021744590666559007\n",
      "Val Loss: 0.021668270782188134\n",
      "Starting epoch 1582\n",
      "Train Loss: 0.021771235598458186\n",
      "Val Loss: 0.02173716492123074\n",
      "Starting epoch 1583\n",
      "Train Loss: 0.021670438625194407\n",
      "Val Loss: 0.022135349887388724\n",
      "Starting epoch 1584\n",
      "Train Loss: 0.021630977038983947\n",
      "Val Loss: 0.02168014645576477\n",
      "Starting epoch 1585\n",
      "Train Loss: 0.021621147791544598\n",
      "Val Loss: 0.02186951372358534\n",
      "Starting epoch 1586\n",
      "Train Loss: 0.021777912974357605\n",
      "Val Loss: 0.02168288219858099\n",
      "Starting epoch 1587\n",
      "Train Loss: 0.021885153320100572\n",
      "Val Loss: 0.021646430646931683\n",
      "Starting epoch 1588\n",
      "Train Loss: 0.02169877345915194\n",
      "Val Loss: 0.021816162047562777\n",
      "Starting epoch 1589\n",
      "Train Loss: 0.021686381763882108\n",
      "Val Loss: 0.021715948979059856\n",
      "Starting epoch 1590\n",
      "Train Loss: 0.021888793618590745\n",
      "Val Loss: 0.021727288762728374\n",
      "Starting epoch 1591\n",
      "Train Loss: 0.02162954983887849\n",
      "Val Loss: 0.02207248740726047\n",
      "Starting epoch 1592\n",
      "Train Loss: 0.02177356680234273\n",
      "Val Loss: 0.021707322862413194\n",
      "Starting epoch 1593\n",
      "Train Loss: 0.021721499385657133\n",
      "Val Loss: 0.021648206092693186\n",
      "Starting epoch 1594\n",
      "Train Loss: 0.02179783472308406\n",
      "Val Loss: 0.02207260054570657\n",
      "Starting epoch 1595\n",
      "Train Loss: 0.021699287273265696\n",
      "Val Loss: 0.021849163704448275\n",
      "Starting epoch 1596\n",
      "Train Loss: 0.02211569470387918\n",
      "Val Loss: 0.0218674855099784\n",
      "Starting epoch 1597\n",
      "Train Loss: 0.02175690288896914\n",
      "Val Loss: 0.021673875274481596\n",
      "Starting epoch 1598\n",
      "Train Loss: 0.021613091782287316\n",
      "Val Loss: 0.021657501105908996\n",
      "Starting epoch 1599\n",
      "Train Loss: 0.022123072986249572\n",
      "Val Loss: 0.021594096665029174\n",
      "Starting epoch 1600\n",
      "Train Loss: 0.02162397846027657\n",
      "Val Loss: 0.02188722844477053\n",
      "Starting epoch 1601\n",
      "Train Loss: 0.021697207181542007\n",
      "Val Loss: 0.021918980611695185\n",
      "Starting epoch 1602\n",
      "Train Loss: 0.02166701356569926\n",
      "Val Loss: 0.02169457961011816\n",
      "Starting epoch 1603\n",
      "Train Loss: 0.02164026708514602\n",
      "Val Loss: 0.02163267687514976\n",
      "Starting epoch 1604\n",
      "Train Loss: 0.02160555676177696\n",
      "Val Loss: 0.021655940899142512\n",
      "Starting epoch 1605\n",
      "Train Loss: 0.02167980428095217\n",
      "Val Loss: 0.021717500355508592\n",
      "Starting epoch 1606\n",
      "Train Loss: 0.021611593939639902\n",
      "Val Loss: 0.0218326383166843\n",
      "Starting epoch 1607\n",
      "Train Loss: 0.02166241462583895\n",
      "Val Loss: 0.02164790365431044\n",
      "Starting epoch 1608\n",
      "Train Loss: 0.02200817620312726\n",
      "Val Loss: 0.021713288845839323\n",
      "Starting epoch 1609\n",
      "Train Loss: 0.021609752266495315\n",
      "Val Loss: 0.022001444741531654\n",
      "Starting epoch 1610\n",
      "Train Loss: 0.021610241245340417\n",
      "Val Loss: 0.02206878364086151\n",
      "Starting epoch 1611\n",
      "Train Loss: 0.02180144080409297\n",
      "Val Loss: 0.022236617626967253\n",
      "Starting epoch 1612\n",
      "Train Loss: 0.021585079254927458\n",
      "Val Loss: 0.021681304883073876\n",
      "Starting epoch 1613\n",
      "Train Loss: 0.021660373718650254\n",
      "Val Loss: 0.021586960112607037\n",
      "Starting epoch 1614\n",
      "Train Loss: 0.02169844784118511\n",
      "Val Loss: 0.02188868820667267\n",
      "Starting epoch 1615\n",
      "Train Loss: 0.021765271822611492\n",
      "Val Loss: 0.0217394447988934\n",
      "Starting epoch 1616\n",
      "Train Loss: 0.021638960198119835\n",
      "Val Loss: 0.021650576481112727\n",
      "Starting epoch 1617\n",
      "Train Loss: 0.021659077869521245\n",
      "Val Loss: 0.021605962404498347\n",
      "Starting epoch 1618\n",
      "Train Loss: 0.021862835795791062\n",
      "Val Loss: 0.021587786299211008\n",
      "Starting epoch 1619\n",
      "Train Loss: 0.021728004570360535\n",
      "Val Loss: 0.02167984070601287\n",
      "Starting epoch 1620\n",
      "Train Loss: 0.022040537661976285\n",
      "Val Loss: 0.02163346994806219\n",
      "Starting epoch 1621\n",
      "Train Loss: 0.021682884958055284\n",
      "Val Loss: 0.021723110918645507\n",
      "Starting epoch 1622\n",
      "Train Loss: 0.02173824166810071\n",
      "Val Loss: 0.021560878665358933\n",
      "Starting epoch 1623\n",
      "Train Loss: 0.02169399736104188\n",
      "Val Loss: 0.021604948573642306\n",
      "Starting epoch 1624\n",
      "Train Loss: 0.021746866129062795\n",
      "Val Loss: 0.021699402619291236\n",
      "Starting epoch 1625\n",
      "Train Loss: 0.022025187810262043\n",
      "Val Loss: 0.021759054727024503\n",
      "Starting epoch 1626\n",
      "Train Loss: 0.021945490329353896\n",
      "Val Loss: 0.021746209926075406\n",
      "Starting epoch 1627\n",
      "Train Loss: 0.021649866744324012\n",
      "Val Loss: 0.021691250580328482\n",
      "Starting epoch 1628\n",
      "Train Loss: 0.021623226227583708\n",
      "Val Loss: 0.021695059206750657\n",
      "Starting epoch 1629\n",
      "Train Loss: 0.02183443307876587\n",
      "Val Loss: 0.02161724313541695\n",
      "Starting epoch 1630\n",
      "Train Loss: 0.02160621186097463\n",
      "Val Loss: 0.02169982757833269\n",
      "Starting epoch 1631\n",
      "Train Loss: 0.02160397227163668\n",
      "Val Loss: 0.021746882134013705\n",
      "Starting epoch 1632\n",
      "Train Loss: 0.021556967386492976\n",
      "Val Loss: 0.021537340901516103\n",
      "Starting epoch 1633\n",
      "Train Loss: 0.021685174769825406\n",
      "Val Loss: 0.02158543798658583\n",
      "Starting epoch 1634\n",
      "Train Loss: 0.021679441686029786\n",
      "Val Loss: 0.021679358901800932\n",
      "Starting epoch 1635\n",
      "Train Loss: 0.021649717180817214\n",
      "Val Loss: 0.021775167849328782\n",
      "Starting epoch 1636\n",
      "Train Loss: 0.021638339316403424\n",
      "Val Loss: 0.021674188198866667\n",
      "Starting epoch 1637\n",
      "Train Loss: 0.021547213748649315\n",
      "Val Loss: 0.021609400157575256\n",
      "Starting epoch 1638\n",
      "Train Loss: 0.021807417273521423\n",
      "Val Loss: 0.021610306368933782\n",
      "Starting epoch 1639\n",
      "Train Loss: 0.021593831755496836\n",
      "Val Loss: 0.021700548904913443\n",
      "Starting epoch 1640\n",
      "Train Loss: 0.02171130643950568\n",
      "Val Loss: 0.021764301039554453\n",
      "Starting epoch 1641\n",
      "Train Loss: 0.02185323061766448\n",
      "Val Loss: 0.02154244151380327\n",
      "Starting epoch 1642\n",
      "Train Loss: 0.02168221440580156\n",
      "Val Loss: 0.021573493878046673\n",
      "Starting epoch 1643\n",
      "Train Loss: 0.02163626308794375\n",
      "Val Loss: 0.02163910700215234\n",
      "Starting epoch 1644\n",
      "Train Loss: 0.021658281485239666\n",
      "Val Loss: 0.021727442741394043\n",
      "Starting epoch 1645\n",
      "Train Loss: 0.02201602635560212\n",
      "Val Loss: 0.021637839851556002\n",
      "Starting epoch 1646\n",
      "Train Loss: 0.02164769779752802\n",
      "Val Loss: 0.021645739674568176\n",
      "Starting epoch 1647\n",
      "Train Loss: 0.02183652917544047\n",
      "Val Loss: 0.02163488997353448\n",
      "Starting epoch 1648\n",
      "Train Loss: 0.021533548280044838\n",
      "Val Loss: 0.02166862454679277\n",
      "Starting epoch 1649\n",
      "Train Loss: 0.02163696785767873\n",
      "Val Loss: 0.021630749658302025\n",
      "Starting epoch 1650\n",
      "Train Loss: 0.02170027295748393\n",
      "Val Loss: 0.021559731827841863\n",
      "Starting epoch 1651\n",
      "Train Loss: 0.02165610150054649\n",
      "Val Loss: 0.021530565840226633\n",
      "Starting epoch 1652\n",
      "Train Loss: 0.021654019753138225\n",
      "Val Loss: 0.02165403906945829\n",
      "Starting epoch 1653\n",
      "Train Loss: 0.022004229602990328\n",
      "Val Loss: 0.02199417021539476\n",
      "Starting epoch 1654\n",
      "Train Loss: 0.02166814770963457\n",
      "Val Loss: 0.021610972506028635\n",
      "Starting epoch 1655\n",
      "Train Loss: 0.02159143101286005\n",
      "Val Loss: 0.02164465409738046\n",
      "Starting epoch 1656\n",
      "Train Loss: 0.02158978029533669\n",
      "Val Loss: 0.021562790981045476\n",
      "Starting epoch 1657\n",
      "Train Loss: 0.021722742252879672\n",
      "Val Loss: 0.021591269859561214\n",
      "Starting epoch 1658\n",
      "Train Loss: 0.021581183981012414\n",
      "Val Loss: 0.0216528144147661\n",
      "Starting epoch 1659\n",
      "Train Loss: 0.021820744982472173\n",
      "Val Loss: 0.021705081617390667\n",
      "Starting epoch 1660\n",
      "Train Loss: 0.021778107793242844\n",
      "Val Loss: 0.02153757987199006\n",
      "Starting epoch 1661\n",
      "Train Loss: 0.021524297970312613\n",
      "Val Loss: 0.02160837639261175\n",
      "Starting epoch 1662\n",
      "Train Loss: 0.021762447776617826\n",
      "Val Loss: 0.02171538163114477\n",
      "Starting epoch 1663\n",
      "Train Loss: 0.021566658660217567\n",
      "Val Loss: 0.021737542417314317\n",
      "Starting epoch 1664\n",
      "Train Loss: 0.02164996498160892\n",
      "Val Loss: 0.021575371424357098\n",
      "Starting epoch 1665\n",
      "Train Loss: 0.021671442521942988\n",
      "Val Loss: 0.021653540708400584\n",
      "Starting epoch 1666\n",
      "Train Loss: 0.021659211428077134\n",
      "Val Loss: 0.021905563495777273\n",
      "Starting epoch 1667\n",
      "Train Loss: 0.021872440973917644\n",
      "Val Loss: 0.02161243944256394\n",
      "Starting epoch 1668\n",
      "Train Loss: 0.02166502453662731\n",
      "Val Loss: 0.021567405925856695\n",
      "Starting epoch 1669\n",
      "Train Loss: 0.021656656706774677\n",
      "Val Loss: 0.021706672178374395\n",
      "Starting epoch 1670\n",
      "Train Loss: 0.021728687264301157\n",
      "Val Loss: 0.02173399538905532\n",
      "Starting epoch 1671\n",
      "Train Loss: 0.02163804018938983\n",
      "Val Loss: 0.02165904199635541\n",
      "Starting epoch 1672\n",
      "Train Loss: 0.02192655647242511\n",
      "Val Loss: 0.02186447768299668\n",
      "Starting epoch 1673\n",
      "Train Loss: 0.021521058899384958\n",
      "Val Loss: 0.021596049820935284\n",
      "Starting epoch 1674\n",
      "Train Loss: 0.021553048932993854\n",
      "Val Loss: 0.02155976990858714\n",
      "Starting epoch 1675\n",
      "Train Loss: 0.021543821802845708\n",
      "Val Loss: 0.021952119690400583\n",
      "Starting epoch 1676\n",
      "Train Loss: 0.021884581005131756\n",
      "Val Loss: 0.02158027501017959\n",
      "Starting epoch 1677\n",
      "Train Loss: 0.021528866004060815\n",
      "Val Loss: 0.021702483296394348\n",
      "Starting epoch 1678\n",
      "Train Loss: 0.02170004392111743\n",
      "Val Loss: 0.02151654495133294\n",
      "Starting epoch 1679\n",
      "Train Loss: 0.021641107069121465\n",
      "Val Loss: 0.021582558199211403\n",
      "Starting epoch 1680\n",
      "Train Loss: 0.02153362057827137\n",
      "Val Loss: 0.021587150516333403\n",
      "Starting epoch 1681\n",
      "Train Loss: 0.02153836190700531\n",
      "Val Loss: 0.021605826086468168\n",
      "Starting epoch 1682\n",
      "Train Loss: 0.021662549288184556\n",
      "Val Loss: 0.021584293908543058\n",
      "Starting epoch 1683\n",
      "Train Loss: 0.021543489010245713\n",
      "Val Loss: 0.02181278169155121\n",
      "Starting epoch 1684\n",
      "Train Loss: 0.021594057480494182\n",
      "Val Loss: 0.02157115881089811\n",
      "Starting epoch 1685\n",
      "Train Loss: 0.021723183768766897\n",
      "Val Loss: 0.02151622540420956\n",
      "Starting epoch 1686\n",
      "Train Loss: 0.0219176372996083\n",
      "Val Loss: 0.021680182328930608\n",
      "Starting epoch 1687\n",
      "Train Loss: 0.021521020266744826\n",
      "Val Loss: 0.0216593775484297\n",
      "Starting epoch 1688\n",
      "Train Loss: 0.021581663577644912\n",
      "Val Loss: 0.021780517366197374\n",
      "Starting epoch 1689\n",
      "Train Loss: 0.021564967654369497\n",
      "Val Loss: 0.02157720316339422\n",
      "Starting epoch 1690\n",
      "Train Loss: 0.021967746593334055\n",
      "Val Loss: 0.021603481637107\n",
      "Starting epoch 1691\n",
      "Train Loss: 0.02157109644677904\n",
      "Val Loss: 0.021562482471819275\n",
      "Starting epoch 1692\n",
      "Train Loss: 0.02154393438939695\n",
      "Val Loss: 0.02152905695968204\n",
      "Starting epoch 1693\n",
      "Train Loss: 0.021552141617845605\n",
      "Val Loss: 0.021528410690802115\n",
      "Starting epoch 1694\n",
      "Train Loss: 0.021595405759634794\n",
      "Val Loss: 0.02161175674862332\n",
      "Starting epoch 1695\n",
      "Train Loss: 0.021500091309900635\n",
      "Val Loss: 0.021959809241471468\n",
      "Starting epoch 1696\n",
      "Train Loss: 0.02158990391978511\n",
      "Val Loss: 0.021531174580256145\n",
      "Starting epoch 1697\n",
      "Train Loss: 0.021795369960643626\n",
      "Val Loss: 0.021554261997894005\n",
      "Starting epoch 1698\n",
      "Train Loss: 0.02153898278872172\n",
      "Val Loss: 0.02147041537143566\n",
      "Starting epoch 1699\n",
      "Train Loss: 0.02198040540571566\n",
      "Val Loss: 0.021484091326042457\n",
      "Starting epoch 1700\n",
      "Train Loss: 0.021515010131729975\n",
      "Val Loss: 0.02151871113865464\n",
      "Starting epoch 1701\n",
      "Train Loss: 0.021526912296259845\n",
      "Val Loss: 0.02147028567614379\n",
      "Starting epoch 1702\n",
      "Train Loss: 0.02165682558660154\n",
      "Val Loss: 0.02159901625580258\n",
      "Starting epoch 1703\n",
      "Train Loss: 0.021481585723382456\n",
      "Val Loss: 0.021485414218019555\n",
      "Starting epoch 1704\n",
      "Train Loss: 0.0215661746484262\n",
      "Val Loss: 0.02181624593558135\n",
      "Starting epoch 1705\n",
      "Train Loss: 0.021507136247776174\n",
      "Val Loss: 0.02189008394877116\n",
      "Starting epoch 1706\n",
      "Train Loss: 0.021522872977786593\n",
      "Val Loss: 0.021749781789603056\n",
      "Starting epoch 1707\n",
      "Train Loss: 0.021574934323628742\n",
      "Val Loss: 0.021550874467249268\n",
      "Starting epoch 1708\n",
      "Train Loss: 0.021487020783954196\n",
      "Val Loss: 0.021547412982693425\n",
      "Starting epoch 1709\n",
      "Train Loss: 0.02156209835299739\n",
      "Val Loss: 0.02147138505070298\n",
      "Starting epoch 1710\n",
      "Train Loss: 0.021541014865592675\n",
      "Val Loss: 0.021526593852926185\n",
      "Starting epoch 1711\n",
      "Train Loss: 0.021656467958732887\n",
      "Val Loss: 0.021663312558774597\n",
      "Starting epoch 1712\n",
      "Train Loss: 0.02150940508754165\n",
      "Val Loss: 0.021953600424307364\n",
      "Starting epoch 1713\n",
      "Train Loss: 0.021610482975288673\n",
      "Val Loss: 0.021572307304099755\n",
      "Starting epoch 1714\n",
      "Train Loss: 0.021521779674070853\n",
      "Val Loss: 0.02154772425139392\n",
      "Starting epoch 1715\n",
      "Train Loss: 0.021621534117945918\n",
      "Val Loss: 0.021581895925380564\n",
      "Starting epoch 1716\n",
      "Train Loss: 0.021544426127716346\n",
      "Val Loss: 0.021519277382780005\n",
      "Starting epoch 1717\n",
      "Train Loss: 0.021900519176765724\n",
      "Val Loss: 0.021455466195389076\n",
      "Starting epoch 1718\n",
      "Train Loss: 0.021526125294190866\n",
      "Val Loss: 0.02155478353853579\n",
      "Starting epoch 1719\n",
      "Train Loss: 0.02157264175238433\n",
      "Val Loss: 0.0215145504033124\n",
      "Starting epoch 1720\n",
      "Train Loss: 0.021942409652250784\n",
      "Val Loss: 0.021476062359633268\n",
      "Starting epoch 1721\n",
      "Train Loss: 0.02151323468596847\n",
      "Val Loss: 0.021783861297148245\n",
      "Starting epoch 1722\n",
      "Train Loss: 0.02166126337316301\n",
      "Val Loss: 0.02167049491847003\n",
      "Starting epoch 1723\n",
      "Train Loss: 0.021532102315514175\n",
      "Val Loss: 0.021514646433017873\n",
      "Starting epoch 1724\n",
      "Train Loss: 0.0215939548280504\n",
      "Val Loss: 0.02168396998334814\n",
      "Starting epoch 1725\n",
      "Train Loss: 0.02156668018411707\n",
      "Val Loss: 0.0214845460874063\n",
      "Starting epoch 1726\n",
      "Train Loss: 0.021634647139796504\n",
      "Val Loss: 0.02156990932093726\n",
      "Starting epoch 1727\n",
      "Train Loss: 0.021458903948465984\n",
      "Val Loss: 0.021691071214499296\n",
      "Starting epoch 1728\n",
      "Train Loss: 0.02168598219200417\n",
      "Val Loss: 0.021601115111951476\n",
      "Starting epoch 1729\n",
      "Train Loss: 0.02161082128683726\n",
      "Val Loss: 0.021474623017840914\n",
      "Starting epoch 1730\n",
      "Train Loss: 0.02159061751983784\n",
      "Val Loss: 0.021521801749865215\n",
      "Starting epoch 1731\n",
      "Train Loss: 0.021611327374422992\n",
      "Val Loss: 0.021526175516623038\n",
      "Starting epoch 1732\n",
      "Train Loss: 0.0216002580192354\n",
      "Val Loss: 0.021612035455527128\n",
      "Starting epoch 1733\n",
      "Train Loss: 0.02153701859491843\n",
      "Val Loss: 0.021560465848004376\n",
      "Starting epoch 1734\n",
      "Train Loss: 0.021470913180598506\n",
      "Val Loss: 0.021541770409654687\n",
      "Starting epoch 1735\n",
      "Train Loss: 0.02151015676833965\n",
      "Val Loss: 0.02163083244253088\n",
      "Starting epoch 1736\n",
      "Train Loss: 0.021932450709519564\n",
      "Val Loss: 0.021622589892811246\n",
      "Starting epoch 1737\n",
      "Train Loss: 0.02152123329816041\n",
      "Val Loss: 0.021551993158128526\n",
      "Starting epoch 1738\n",
      "Train Loss: 0.021994522324314824\n",
      "Val Loss: 0.02155485142160345\n",
      "Starting epoch 1739\n",
      "Train Loss: 0.021630355605372676\n",
      "Val Loss: 0.021487183041042753\n",
      "Starting epoch 1740\n",
      "Train Loss: 0.021672285817287588\n",
      "Val Loss: 0.02151235717314261\n",
      "Starting epoch 1741\n",
      "Train Loss: 0.021609907348950703\n",
      "Val Loss: 0.02153310731605247\n",
      "Starting epoch 1742\n",
      "Train Loss: 0.021443619220345107\n",
      "Val Loss: 0.021449018407751014\n",
      "Starting epoch 1743\n",
      "Train Loss: 0.021428253363679955\n",
      "Val Loss: 0.021508097096725746\n",
      "Starting epoch 1744\n",
      "Train Loss: 0.021459769871499803\n",
      "Val Loss: 0.02155036175692523\n",
      "Starting epoch 1745\n",
      "Train Loss: 0.021588008712839196\n",
      "Val Loss: 0.021517641566417837\n",
      "Starting epoch 1746\n",
      "Train Loss: 0.02150155824643594\n",
      "Val Loss: 0.02146598807087651\n",
      "Starting epoch 1747\n",
      "Train Loss: 0.021827267275916204\n",
      "Val Loss: 0.021504973923718487\n",
      "Starting epoch 1748\n",
      "Train Loss: 0.021551229335643626\n",
      "Val Loss: 0.021484663641011273\n",
      "Starting epoch 1749\n",
      "Train Loss: 0.021600226561228435\n",
      "Val Loss: 0.021591495584558557\n",
      "Starting epoch 1750\n",
      "Train Loss: 0.02155901105315597\n",
      "Val Loss: 0.0214772527968442\n",
      "Starting epoch 1751\n",
      "Train Loss: 0.021560572915607028\n",
      "Val Loss: 0.02146251058136975\n",
      "Starting epoch 1752\n",
      "Train Loss: 0.021464663523214834\n",
      "Val Loss: 0.02145941997015918\n",
      "Starting epoch 1753\n",
      "Train Loss: 0.021448717073157982\n",
      "Val Loss: 0.02165402637587653\n",
      "Starting epoch 1754\n",
      "Train Loss: 0.021442475142302336\n",
      "Val Loss: 0.02147401096644225\n",
      "Starting epoch 1755\n",
      "Train Loss: 0.021669796771473356\n",
      "Val Loss: 0.021933112431455543\n",
      "Starting epoch 1756\n",
      "Train Loss: 0.021568425275661326\n",
      "Val Loss: 0.02142222280855532\n",
      "Starting epoch 1757\n",
      "Train Loss: 0.021472075471171626\n",
      "Val Loss: 0.021454966730541654\n",
      "Starting epoch 1758\n",
      "Train Loss: 0.021460908982488845\n",
      "Val Loss: 0.02150175196153146\n",
      "Starting epoch 1759\n",
      "Train Loss: 0.021865490961957862\n",
      "Val Loss: 0.02144291224303069\n",
      "Starting epoch 1760\n",
      "Train Loss: 0.021474661098586187\n",
      "Val Loss: 0.02162972147817965\n",
      "Starting epoch 1761\n",
      "Train Loss: 0.021589098153290926\n",
      "Val Loss: 0.021534810463587444\n",
      "Starting epoch 1762\n",
      "Train Loss: 0.021552324846938805\n",
      "Val Loss: 0.021610606047842238\n",
      "Starting epoch 1763\n",
      "Train Loss: 0.021456521970254404\n",
      "Val Loss: 0.02153675478917581\n",
      "Starting epoch 1764\n",
      "Train Loss: 0.021857397423850164\n",
      "Val Loss: 0.021427736238197045\n",
      "Starting epoch 1765\n",
      "Train Loss: 0.021519888330388953\n",
      "Val Loss: 0.021422008121455158\n",
      "Starting epoch 1766\n",
      "Train Loss: 0.021425888494209008\n",
      "Val Loss: 0.02141288529943537\n",
      "Starting epoch 1767\n",
      "Train Loss: 0.021534627234494244\n",
      "Val Loss: 0.021479038176713167\n",
      "Starting epoch 1768\n",
      "Train Loss: 0.0218689430643011\n",
      "Val Loss: 0.0219572263735312\n",
      "Starting epoch 1769\n",
      "Train Loss: 0.021502423617574904\n",
      "Val Loss: 0.02149865252000314\n",
      "Starting epoch 1770\n",
      "Train Loss: 0.021560376441037213\n",
      "Val Loss: 0.021543851053273236\n",
      "Starting epoch 1771\n",
      "Train Loss: 0.021646582969912776\n",
      "Val Loss: 0.02148101892736223\n",
      "Starting epoch 1772\n",
      "Train Loss: 0.0214424972180967\n",
      "Val Loss: 0.02147315608130561\n",
      "Starting epoch 1773\n",
      "Train Loss: 0.02177017209706483\n",
      "Val Loss: 0.021493520449709008\n",
      "Starting epoch 1774\n",
      "Train Loss: 0.021506982821005362\n",
      "Val Loss: 0.021850610772768658\n",
      "Starting epoch 1775\n",
      "Train Loss: 0.02154902120431264\n",
      "Val Loss: 0.021638158846784522\n",
      "Starting epoch 1776\n",
      "Train Loss: 0.021455067175405997\n",
      "Val Loss: 0.02160786257849799\n",
      "Starting epoch 1777\n",
      "Train Loss: 0.021457843206546926\n",
      "Val Loss: 0.021548421846495733\n",
      "Starting epoch 1778\n",
      "Train Loss: 0.02199251453081767\n",
      "Val Loss: 0.021466664693973684\n",
      "Starting epoch 1779\n",
      "Train Loss: 0.021860782195020606\n",
      "Val Loss: 0.02156038913461897\n",
      "Starting epoch 1780\n",
      "Train Loss: 0.021594495133117394\n",
      "Val Loss: 0.021458871938564158\n",
      "Starting epoch 1781\n",
      "Train Loss: 0.02146310055697406\n",
      "Val Loss: 0.02186675038602617\n",
      "Starting epoch 1782\n",
      "Train Loss: 0.021495288168942486\n",
      "Val Loss: 0.02150994152934463\n",
      "Starting epoch 1783\n",
      "Train Loss: 0.021615713282867714\n",
      "Val Loss: 0.021492178793306702\n",
      "Starting epoch 1784\n",
      "Train Loss: 0.021504969508559617\n",
      "Val Loss: 0.021580885405893677\n",
      "Starting epoch 1785\n",
      "Train Loss: 0.02143353334179631\n",
      "Val Loss: 0.021564772835484258\n",
      "Starting epoch 1786\n",
      "Train Loss: 0.021592891878551908\n",
      "Val Loss: 0.02153783650309951\n",
      "Starting epoch 1787\n",
      "Train Loss: 0.021480019445772523\n",
      "Val Loss: 0.021561162339316473\n",
      "Starting epoch 1788\n",
      "Train Loss: 0.02156214416027069\n",
      "Val Loss: 0.02149950298998091\n",
      "Starting epoch 1789\n",
      "Train Loss: 0.02200881474547916\n",
      "Val Loss: 0.02190464238325755\n",
      "Starting epoch 1790\n",
      "Train Loss: 0.02185136797251525\n",
      "Val Loss: 0.021517260207070246\n",
      "Starting epoch 1791\n",
      "Train Loss: 0.02148319946395026\n",
      "Val Loss: 0.021559503895265085\n",
      "Starting epoch 1792\n",
      "Train Loss: 0.02154748307334052\n",
      "Val Loss: 0.02160418861442142\n",
      "Starting epoch 1793\n",
      "Train Loss: 0.021614372730255127\n",
      "Val Loss: 0.02144702551541505\n",
      "Starting epoch 1794\n",
      "Train Loss: 0.021386478234220435\n",
      "Val Loss: 0.021818886752481812\n",
      "Starting epoch 1795\n",
      "Train Loss: 0.021502445141474407\n",
      "Val Loss: 0.02148697387289118\n",
      "Starting epoch 1796\n",
      "Train Loss: 0.021575986235230056\n",
      "Val Loss: 0.02150866996358942\n",
      "Starting epoch 1797\n",
      "Train Loss: 0.021453872323036194\n",
      "Val Loss: 0.021444721906273452\n",
      "Starting epoch 1798\n",
      "Train Loss: 0.021783182466471637\n",
      "Val Loss: 0.02150494522518582\n",
      "Starting epoch 1799\n",
      "Train Loss: 0.021427029812777484\n",
      "Val Loss: 0.021918180916044448\n",
      "Starting epoch 1800\n",
      "Train Loss: 0.021816749263692786\n",
      "Val Loss: 0.021448509008796128\n",
      "Starting epoch 1801\n",
      "Train Loss: 0.02143103767324377\n",
      "Val Loss: 0.02146459784772661\n",
      "Starting epoch 1802\n",
      "Train Loss: 0.02140764781722316\n",
      "Val Loss: 0.021435349075882522\n",
      "Starting epoch 1803\n",
      "Train Loss: 0.021377847150520043\n",
      "Val Loss: 0.02146605098689044\n",
      "Starting epoch 1804\n",
      "Train Loss: 0.021567224904342933\n",
      "Val Loss: 0.021474667169429636\n",
      "Starting epoch 1805\n",
      "Train Loss: 0.021466758516099717\n",
      "Val Loss: 0.02154293711538668\n",
      "Starting epoch 1806\n",
      "Train Loss: 0.021451430740179838\n",
      "Val Loss: 0.021525195903248258\n",
      "Starting epoch 1807\n",
      "Train Loss: 0.021496280475899025\n",
      "Val Loss: 0.02141112861809907\n",
      "Starting epoch 1808\n",
      "Train Loss: 0.021596775010780053\n",
      "Val Loss: 0.021634022394816082\n",
      "Starting epoch 1809\n",
      "Train Loss: 0.021586882847326773\n",
      "Val Loss: 0.02153765603348061\n",
      "Starting epoch 1810\n",
      "Train Loss: 0.02185135472703863\n",
      "Val Loss: 0.02142527147575661\n",
      "Starting epoch 1811\n",
      "Train Loss: 0.021481290459632874\n",
      "Val Loss: 0.02150227846922698\n",
      "Starting epoch 1812\n",
      "Train Loss: 0.021597935645668594\n",
      "Val Loss: 0.021451266827406706\n",
      "Starting epoch 1813\n",
      "Train Loss: 0.021884042907644202\n",
      "Val Loss: 0.021479631463686626\n",
      "Starting epoch 1814\n",
      "Train Loss: 0.0215937743584315\n",
      "Val Loss: 0.0214113869048931\n",
      "Starting epoch 1815\n",
      "Train Loss: 0.02143632979304702\n",
      "Val Loss: 0.021459009360384057\n",
      "Starting epoch 1816\n",
      "Train Loss: 0.021539822772697167\n",
      "Val Loss: 0.021514278319146898\n",
      "Starting epoch 1817\n",
      "Train Loss: 0.021560159546357614\n",
      "Val Loss: 0.021540975129162823\n",
      "Starting epoch 1818\n",
      "Train Loss: 0.021430471429118404\n",
      "Val Loss: 0.02157358438880355\n",
      "Starting epoch 1819\n",
      "Train Loss: 0.021559702025519475\n",
      "Val Loss: 0.02144144254702109\n",
      "Starting epoch 1820\n",
      "Train Loss: 0.02184573257410968\n",
      "Val Loss: 0.0215711185225734\n",
      "Starting epoch 1821\n",
      "Train Loss: 0.02146703060026522\n",
      "Val Loss: 0.021457063931005972\n",
      "Starting epoch 1822\n",
      "Train Loss: 0.02200543604515217\n",
      "Val Loss: 0.02141992140699316\n",
      "Starting epoch 1823\n",
      "Train Loss: 0.02142212677884985\n",
      "Val Loss: 0.021451266827406706\n",
      "Starting epoch 1824\n",
      "Train Loss: 0.021404261390368145\n",
      "Val Loss: 0.021516683476942557\n",
      "Starting epoch 1825\n",
      "Train Loss: 0.021436299438829774\n",
      "Val Loss: 0.02154950687178859\n",
      "Starting epoch 1826\n",
      "Train Loss: 0.02140012604218942\n",
      "Val Loss: 0.021407427611174406\n",
      "Starting epoch 1827\n",
      "Train Loss: 0.021482360583764536\n",
      "Val Loss: 0.02151484290758769\n",
      "Starting epoch 1828\n",
      "Train Loss: 0.021453956211054767\n",
      "Val Loss: 0.021460567359571105\n",
      "Starting epoch 1829\n",
      "Train Loss: 0.021451291110780504\n",
      "Val Loss: 0.02155014044708676\n",
      "Starting epoch 1830\n",
      "Train Loss: 0.021675412301664\n",
      "Val Loss: 0.02165928096682937\n",
      "Starting epoch 1831\n",
      "Train Loss: 0.021492301865860267\n",
      "Val Loss: 0.021361607644293044\n",
      "Starting epoch 1832\n",
      "Train Loss: 0.021442832770170988\n",
      "Val Loss: 0.02152169081899855\n",
      "Starting epoch 1833\n",
      "Train Loss: 0.02158567640516493\n",
      "Val Loss: 0.021405873475251375\n",
      "Starting epoch 1834\n",
      "Train Loss: 0.021761053690203914\n",
      "Val Loss: 0.02191629398752142\n",
      "Starting epoch 1835\n",
      "Train Loss: 0.02144605693993745\n",
      "Val Loss: 0.021474148388262147\n",
      "Starting epoch 1836\n",
      "Train Loss: 0.021378039209930984\n",
      "Val Loss: 0.021401065919134352\n",
      "Starting epoch 1837\n",
      "Train Loss: 0.021428935505725718\n",
      "Val Loss: 0.02177796540436921\n",
      "Starting epoch 1838\n",
      "Train Loss: 0.0215356449286143\n",
      "Val Loss: 0.021441689795917936\n",
      "Starting epoch 1839\n",
      "Train Loss: 0.021451215501184815\n",
      "Val Loss: 0.02150247604758651\n",
      "Starting epoch 1840\n",
      "Train Loss: 0.021385690680256596\n",
      "Val Loss: 0.021443858742713928\n",
      "Starting epoch 1841\n",
      "Train Loss: 0.021427798050421255\n",
      "Val Loss: 0.021434350698082534\n",
      "Starting epoch 1842\n",
      "Train Loss: 0.021793605000884446\n",
      "Val Loss: 0.02147440943453047\n",
      "Starting epoch 1843\n",
      "Train Loss: 0.021860536601808336\n",
      "Val Loss: 0.021499580807156034\n",
      "Starting epoch 1844\n",
      "Train Loss: 0.02146606257668248\n",
      "Val Loss: 0.021411503354708355\n",
      "Starting epoch 1845\n",
      "Train Loss: 0.021787060079751192\n",
      "Val Loss: 0.021667227700904564\n",
      "Starting epoch 1846\n",
      "Train Loss: 0.021887305158155936\n",
      "Val Loss: 0.021493716924278823\n",
      "Starting epoch 1847\n",
      "Train Loss: 0.02148286446377083\n",
      "Val Loss: 0.021346636392452097\n",
      "Starting epoch 1848\n",
      "Train Loss: 0.021421107980940077\n",
      "Val Loss: 0.021374174290233187\n",
      "Starting epoch 1849\n",
      "Train Loss: 0.021402932979442454\n",
      "Val Loss: 0.02152010632885827\n",
      "Starting epoch 1850\n",
      "Train Loss: 0.02136221969569171\n",
      "Val Loss: 0.021550854599034344\n",
      "Starting epoch 1851\n",
      "Train Loss: 0.021457370232652734\n",
      "Val Loss: 0.021396090035085327\n",
      "Starting epoch 1852\n",
      "Train Loss: 0.021477066256381846\n",
      "Val Loss: 0.021375885716191045\n",
      "Starting epoch 1853\n",
      "Train Loss: 0.021763314251546508\n",
      "Val Loss: 0.02144033599782873\n",
      "Starting epoch 1854\n",
      "Train Loss: 0.021464257328598586\n",
      "Val Loss: 0.02151386053473861\n",
      "Starting epoch 1855\n",
      "Train Loss: 0.02146566300480454\n",
      "Val Loss: 0.021581042695928504\n",
      "Starting epoch 1856\n",
      "Train Loss: 0.02143709306363706\n",
      "Val Loss: 0.021410146245249995\n",
      "Starting epoch 1857\n",
      "Train Loss: 0.021441797415415447\n",
      "Val Loss: 0.021446414015911245\n",
      "Starting epoch 1858\n",
      "Train Loss: 0.021421241539495962\n",
      "Val Loss: 0.02189630545951702\n",
      "Starting epoch 1859\n",
      "Train Loss: 0.021506815596863075\n",
      "Val Loss: 0.02176182082405797\n",
      "Starting epoch 1860\n",
      "Train Loss: 0.021344142379584135\n",
      "Val Loss: 0.021431597294630827\n",
      "Starting epoch 1861\n",
      "Train Loss: 0.021433471529572097\n",
      "Val Loss: 0.021421149924949364\n",
      "Starting epoch 1862\n",
      "Train Loss: 0.021712502947560063\n",
      "Val Loss: 0.021452293903739365\n",
      "Starting epoch 1863\n",
      "Train Loss: 0.02139415564360442\n",
      "Val Loss: 0.021440177604004188\n",
      "Starting epoch 1864\n",
      "Train Loss: 0.021345961425039504\n",
      "Val Loss: 0.02136178701012223\n",
      "Starting epoch 1865\n",
      "Train Loss: 0.02137383708247432\n",
      "Val Loss: 0.021908087862862483\n",
      "Starting epoch 1866\n",
      "Train Loss: 0.021848423613442317\n",
      "Val Loss: 0.02134173998126277\n",
      "Starting epoch 1867\n",
      "Train Loss: 0.021751315505416306\n",
      "Val Loss: 0.021444619253829674\n",
      "Starting epoch 1868\n",
      "Train Loss: 0.02164245093310321\n",
      "Val Loss: 0.021576966952394555\n",
      "Starting epoch 1869\n",
      "Train Loss: 0.02143211883527261\n",
      "Val Loss: 0.021403132765381423\n",
      "Starting epoch 1870\n",
      "Train Loss: 0.021427952029086924\n",
      "Val Loss: 0.021373971192925063\n",
      "Starting epoch 1871\n",
      "Train Loss: 0.02138512333234151\n",
      "Val Loss: 0.02140137553215027\n",
      "Starting epoch 1872\n",
      "Train Loss: 0.021358394512423762\n",
      "Val Loss: 0.02142334039564486\n",
      "Starting epoch 1873\n",
      "Train Loss: 0.02137008309364319\n",
      "Val Loss: 0.021483819241876954\n",
      "Starting epoch 1874\n",
      "Train Loss: 0.021349152481114422\n",
      "Val Loss: 0.021393219629923504\n",
      "Starting epoch 1875\n",
      "Train Loss: 0.021429580118921068\n",
      "Val Loss: 0.021343742807706196\n",
      "Starting epoch 1876\n",
      "Train Loss: 0.021398597293429904\n",
      "Val Loss: 0.02149434056546953\n",
      "Starting epoch 1877\n",
      "Train Loss: 0.021351362820024842\n",
      "Val Loss: 0.021344879711115802\n",
      "Starting epoch 1878\n",
      "Train Loss: 0.021443480142840633\n",
      "Val Loss: 0.021459716889593337\n",
      "Starting epoch 1879\n",
      "Train Loss: 0.021356417073143855\n",
      "Val Loss: 0.021535287300745647\n",
      "Starting epoch 1880\n",
      "Train Loss: 0.021411001130386634\n",
      "Val Loss: 0.021360459702986258\n",
      "Starting epoch 1881\n",
      "Train Loss: 0.021764016261807195\n",
      "Val Loss: 0.021442830562591553\n",
      "Starting epoch 1882\n",
      "Train Loss: 0.021508109238412645\n",
      "Val Loss: 0.021525340499701322\n",
      "Starting epoch 1883\n",
      "Train Loss: 0.021395287579960294\n",
      "Val Loss: 0.02138233791898798\n",
      "Starting epoch 1884\n",
      "Train Loss: 0.021371754231276335\n",
      "Val Loss: 0.021315150238849497\n",
      "Starting epoch 1885\n",
      "Train Loss: 0.021385731520476164\n",
      "Val Loss: 0.021398030497409678\n",
      "Starting epoch 1886\n",
      "Train Loss: 0.021510402913446778\n",
      "Val Loss: 0.021375522569373803\n",
      "Starting epoch 1887\n",
      "Train Loss: 0.02150706284575992\n",
      "Val Loss: 0.021551049969814443\n",
      "Starting epoch 1888\n",
      "Train Loss: 0.02159608624599598\n",
      "Val Loss: 0.021409028658160457\n",
      "Starting epoch 1889\n",
      "Train Loss: 0.02141809021985089\n",
      "Val Loss: 0.02150918984854663\n",
      "Starting epoch 1890\n",
      "Train Loss: 0.02182809677388933\n",
      "Val Loss: 0.021767214492515282\n",
      "Starting epoch 1891\n",
      "Train Loss: 0.02141078092433788\n",
      "Val Loss: 0.021368724880395113\n",
      "Starting epoch 1892\n",
      "Train Loss: 0.02141384835596438\n",
      "Val Loss: 0.02136273682117462\n",
      "Starting epoch 1893\n",
      "Train Loss: 0.021433526719058002\n",
      "Val Loss: 0.021375987816739966\n",
      "Starting epoch 1894\n",
      "Train Loss: 0.021315112709999084\n",
      "Val Loss: 0.02138343894923175\n",
      "Starting epoch 1895\n",
      "Train Loss: 0.021456015882668673\n",
      "Val Loss: 0.021670228905147977\n",
      "Starting epoch 1896\n",
      "Train Loss: 0.021344170526221947\n",
      "Val Loss: 0.021428223009462708\n",
      "Starting epoch 1897\n",
      "Train Loss: 0.021451717725506535\n",
      "Val Loss: 0.021373661579909147\n",
      "Starting epoch 1898\n",
      "Train Loss: 0.021373960155027884\n",
      "Val Loss: 0.021328648483311688\n",
      "Starting epoch 1899\n",
      "Train Loss: 0.021495799775476807\n",
      "Val Loss: 0.02137154119986075\n",
      "Starting epoch 1900\n",
      "Train Loss: 0.021469790626455237\n",
      "Val Loss: 0.02131595324586939\n",
      "Starting epoch 1901\n",
      "Train Loss: 0.021394694292986835\n",
      "Val Loss: 0.021422585403477704\n",
      "Starting epoch 1902\n",
      "Train Loss: 0.021440310058770357\n",
      "Val Loss: 0.021387897155903005\n",
      "Starting epoch 1903\n",
      "Train Loss: 0.02133741036609367\n",
      "Val Loss: 0.021385604032763728\n",
      "Starting epoch 1904\n",
      "Train Loss: 0.021417753012092026\n",
      "Val Loss: 0.021479306949509516\n",
      "Starting epoch 1905\n",
      "Train Loss: 0.021396074030134413\n",
      "Val Loss: 0.021946142117182415\n",
      "Starting epoch 1906\n",
      "Train Loss: 0.021396009458435908\n",
      "Val Loss: 0.02141947161268305\n",
      "Starting epoch 1907\n",
      "Train Loss: 0.02135934321968644\n",
      "Val Loss: 0.02152090933587816\n",
      "Starting epoch 1908\n",
      "Train Loss: 0.021296128630638123\n",
      "Val Loss: 0.02146718402703603\n",
      "Starting epoch 1909\n",
      "Train Loss: 0.021368602911631267\n",
      "Val Loss: 0.02136435608069102\n",
      "Starting epoch 1910\n",
      "Train Loss: 0.021381475859218173\n",
      "Val Loss: 0.021375190328668664\n",
      "Starting epoch 1911\n",
      "Train Loss: 0.0215144924543522\n",
      "Val Loss: 0.021394386887550354\n",
      "Starting epoch 1912\n",
      "Train Loss: 0.021376848220825195\n",
      "Val Loss: 0.021751119582741348\n",
      "Starting epoch 1913\n",
      "Train Loss: 0.021557995014720492\n",
      "Val Loss: 0.021409096541228117\n",
      "Starting epoch 1914\n",
      "Train Loss: 0.021407120757632785\n",
      "Val Loss: 0.021445859361577918\n",
      "Starting epoch 1915\n",
      "Train Loss: 0.021770891216066148\n",
      "Val Loss: 0.021386180762891418\n",
      "Starting epoch 1916\n",
      "Train Loss: 0.021362974135964004\n",
      "Val Loss: 0.021329115938257287\n",
      "Starting epoch 1917\n",
      "Train Loss: 0.021371282361171865\n",
      "Val Loss: 0.021419934652469778\n",
      "Starting epoch 1918\n",
      "Train Loss: 0.02136173458011062\n",
      "Val Loss: 0.021358987247502362\n",
      "Starting epoch 1919\n",
      "Train Loss: 0.021490239986666927\n",
      "Val Loss: 0.021334050982086745\n",
      "Starting epoch 1920\n",
      "Train Loss: 0.021777137010185806\n",
      "Val Loss: 0.0218087512033957\n",
      "Starting epoch 1921\n",
      "Train Loss: 0.02135487011185399\n",
      "Val Loss: 0.021383132095690125\n",
      "Starting epoch 1922\n",
      "Train Loss: 0.021408652265866596\n",
      "Val Loss: 0.02132158202153665\n",
      "Starting epoch 1923\n",
      "Train Loss: 0.02132032259746834\n",
      "Val Loss: 0.021324353637518705\n",
      "Starting epoch 1924\n",
      "Train Loss: 0.02134866405416418\n",
      "Val Loss: 0.021340938078032598\n",
      "Starting epoch 1925\n",
      "Train Loss: 0.021506503776267723\n",
      "Val Loss: 0.021365793766798796\n",
      "Starting epoch 1926\n",
      "Train Loss: 0.02147086626953549\n",
      "Val Loss: 0.02130682600869073\n",
      "Starting epoch 1927\n",
      "Train Loss: 0.02134212796334867\n",
      "Val Loss: 0.021383936758394593\n",
      "Starting epoch 1928\n",
      "Train Loss: 0.02133509351147546\n",
      "Val Loss: 0.021500372224383883\n",
      "Starting epoch 1929\n",
      "Train Loss: 0.0213689257701238\n",
      "Val Loss: 0.021371669791362905\n",
      "Starting epoch 1930\n",
      "Train Loss: 0.021323342566136962\n",
      "Val Loss: 0.021431240218657034\n",
      "Starting epoch 1931\n",
      "Train Loss: 0.021338278496706928\n",
      "Val Loss: 0.021437144389858952\n",
      "Starting epoch 1932\n",
      "Train Loss: 0.021479903547852126\n",
      "Val Loss: 0.02144780092769199\n",
      "Starting epoch 1933\n",
      "Train Loss: 0.021578141384654574\n",
      "Val Loss: 0.021306333718476473\n",
      "Starting epoch 1934\n",
      "Train Loss: 0.021398773347889935\n",
      "Val Loss: 0.021746655857121502\n",
      "Starting epoch 1935\n",
      "Train Loss: 0.02141825247693945\n",
      "Val Loss: 0.021765224911548472\n",
      "Starting epoch 1936\n",
      "Train Loss: 0.02171525745480149\n",
      "Val Loss: 0.021487558329546894\n",
      "Starting epoch 1937\n",
      "Train Loss: 0.02140074747580069\n",
      "Val Loss: 0.02131034654599649\n",
      "Starting epoch 1938\n",
      "Train Loss: 0.02147086019869204\n",
      "Val Loss: 0.021367174607736093\n",
      "Starting epoch 1939\n",
      "Train Loss: 0.021403445689766494\n",
      "Val Loss: 0.021494587814366375\n",
      "Starting epoch 1940\n",
      "Train Loss: 0.021308895614412095\n",
      "Val Loss: 0.021493471331066556\n",
      "Starting epoch 1941\n",
      "Train Loss: 0.021307896684717248\n",
      "Val Loss: 0.021692763324137086\n",
      "Starting epoch 1942\n",
      "Train Loss: 0.02141841528592286\n",
      "Val Loss: 0.021482001300211304\n",
      "Starting epoch 1943\n",
      "Train Loss: 0.021319150924682617\n",
      "Val Loss: 0.021387690195330867\n",
      "Starting epoch 1944\n",
      "Train Loss: 0.021389422593293368\n",
      "Val Loss: 0.02147166375760679\n",
      "Starting epoch 1945\n",
      "Train Loss: 0.02138796172760151\n",
      "Val Loss: 0.02132540499722516\n",
      "Starting epoch 1946\n",
      "Train Loss: 0.021322057754905137\n",
      "Val Loss: 0.02178929966908914\n",
      "Starting epoch 1947\n",
      "Train Loss: 0.021959179529437312\n",
      "Val Loss: 0.021365623231287354\n",
      "Starting epoch 1948\n",
      "Train Loss: 0.021397959302972863\n",
      "Val Loss: 0.021801545112221328\n",
      "Starting epoch 1949\n",
      "Train Loss: 0.021342230063897592\n",
      "Val Loss: 0.021330828468004864\n",
      "Starting epoch 1950\n",
      "Train Loss: 0.021795428461498685\n",
      "Val Loss: 0.02135731942123837\n",
      "Starting epoch 1951\n",
      "Train Loss: 0.021347801994394372\n",
      "Val Loss: 0.02129685823564176\n",
      "Starting epoch 1952\n",
      "Train Loss: 0.02146942858342771\n",
      "Val Loss: 0.021389962898360357\n",
      "Starting epoch 1953\n",
      "Train Loss: 0.021559895740614995\n",
      "Val Loss: 0.02132732117617572\n",
      "Starting epoch 1954\n",
      "Train Loss: 0.021429516099117422\n",
      "Val Loss: 0.021298529373274908\n",
      "Starting epoch 1955\n",
      "Train Loss: 0.02135227565412168\n",
      "Val Loss: 0.021334528923034668\n",
      "Starting epoch 1956\n",
      "Train Loss: 0.02171292073196835\n",
      "Val Loss: 0.021299563624240733\n",
      "Starting epoch 1957\n",
      "Train Loss: 0.021752774163528724\n",
      "Val Loss: 0.02128515585705086\n",
      "Starting epoch 1958\n",
      "Train Loss: 0.021416892056111938\n",
      "Val Loss: 0.021389869628129183\n",
      "Starting epoch 1959\n",
      "Train Loss: 0.02129789469418702\n",
      "Val Loss: 0.02144640904885751\n",
      "Starting epoch 1960\n",
      "Train Loss: 0.02126686716521228\n",
      "Val Loss: 0.02132106434415888\n",
      "Starting epoch 1961\n",
      "Train Loss: 0.021486161483658686\n",
      "Val Loss: 0.021337765234488028\n",
      "Starting epoch 1962\n",
      "Train Loss: 0.021426921641385113\n",
      "Val Loss: 0.021304468865747803\n",
      "Starting epoch 1963\n",
      "Train Loss: 0.021422931441554317\n",
      "Val Loss: 0.02176167677949976\n",
      "Starting epoch 1964\n",
      "Train Loss: 0.021290704056068702\n",
      "Val Loss: 0.02179039959554319\n",
      "Starting epoch 1965\n",
      "Train Loss: 0.021302658650610182\n",
      "Val Loss: 0.021306426988707647\n",
      "Starting epoch 1966\n",
      "Train Loss: 0.02130093397917571\n",
      "Val Loss: 0.021441878543959722\n",
      "Starting epoch 1967\n",
      "Train Loss: 0.021369450622134738\n",
      "Val Loss: 0.021369064847628277\n",
      "Starting epoch 1968\n",
      "Train Loss: 0.021453678607940674\n",
      "Val Loss: 0.021688000471503648\n",
      "Starting epoch 1969\n",
      "Train Loss: 0.021313458681106567\n",
      "Val Loss: 0.02144798360489033\n",
      "Starting epoch 1970\n",
      "Train Loss: 0.021310610351739107\n",
      "Val Loss: 0.02127164491900691\n",
      "Starting epoch 1971\n",
      "Train Loss: 0.02171105256787053\n",
      "Val Loss: 0.021773541967074077\n",
      "Starting epoch 1972\n",
      "Train Loss: 0.02130095771065465\n",
      "Val Loss: 0.02139914587691978\n",
      "Starting epoch 1973\n",
      "Train Loss: 0.02170066590662356\n",
      "Val Loss: 0.021298659068566782\n",
      "Starting epoch 1974\n",
      "Train Loss: 0.02176071924191934\n",
      "Val Loss: 0.021338877302628977\n",
      "Starting epoch 1975\n",
      "Train Loss: 0.02131554263609427\n",
      "Val Loss: 0.021368978752030268\n",
      "Starting epoch 1976\n",
      "Train Loss: 0.021399800424222595\n",
      "Val Loss: 0.021410327266763757\n",
      "Starting epoch 1977\n",
      "Train Loss: 0.02130961804478257\n",
      "Val Loss: 0.021406960708123667\n",
      "Starting epoch 1978\n",
      "Train Loss: 0.021730457191114074\n",
      "Val Loss: 0.02132495575480991\n",
      "Starting epoch 1979\n",
      "Train Loss: 0.02171937569423958\n",
      "Val Loss: 0.021299944431693467\n",
      "Starting epoch 1980\n",
      "Train Loss: 0.021743415130509272\n",
      "Val Loss: 0.02133742195588571\n",
      "Starting epoch 1981\n",
      "Train Loss: 0.02151536610391405\n",
      "Val Loss: 0.02147725886768765\n",
      "Starting epoch 1982\n",
      "Train Loss: 0.021334276707084092\n",
      "Val Loss: 0.02142605240698214\n",
      "Starting epoch 1983\n",
      "Train Loss: 0.0217295421494378\n",
      "Val Loss: 0.021394034226735432\n",
      "Starting epoch 1984\n",
      "Train Loss: 0.021261543587402062\n",
      "Val Loss: 0.02139354690357491\n",
      "Starting epoch 1985\n",
      "Train Loss: 0.0213694268906558\n",
      "Val Loss: 0.021402122245894536\n",
      "Starting epoch 1986\n",
      "Train Loss: 0.021310284181877418\n",
      "Val Loss: 0.02129569704885836\n",
      "Starting epoch 1987\n",
      "Train Loss: 0.021464696085011517\n",
      "Val Loss: 0.021463204865102416\n",
      "Starting epoch 1988\n",
      "Train Loss: 0.0213681740893258\n",
      "Val Loss: 0.02159467891410545\n",
      "Starting epoch 1989\n",
      "Train Loss: 0.02129116654396057\n",
      "Val Loss: 0.02129810827749747\n",
      "Starting epoch 1990\n",
      "Train Loss: 0.021309921586955036\n",
      "Val Loss: 0.021327179339196947\n",
      "Starting epoch 1991\n",
      "Train Loss: 0.021274656057357788\n",
      "Val Loss: 0.021389694677458868\n",
      "Starting epoch 1992\n",
      "Train Loss: 0.02138129428580955\n",
      "Val Loss: 0.021333946122063532\n",
      "Starting epoch 1993\n",
      "Train Loss: 0.02141569885942671\n",
      "Val Loss: 0.021379088362058003\n",
      "Starting epoch 1994\n",
      "Train Loss: 0.02126956703486266\n",
      "Val Loss: 0.02133606539832221\n",
      "Starting epoch 1995\n",
      "Train Loss: 0.021344661160751625\n",
      "Val Loss: 0.021259279162795457\n",
      "Starting epoch 1996\n",
      "Train Loss: 0.021311842732959323\n",
      "Val Loss: 0.021343070599767897\n",
      "Starting epoch 1997\n",
      "Train Loss: 0.021325158300223173\n",
      "Val Loss: 0.02131632798247867\n",
      "Starting epoch 1998\n",
      "Train Loss: 0.021307499872313604\n",
      "Val Loss: 0.021358273095554776\n",
      "Starting epoch 1999\n",
      "Train Loss: 0.021374629603491888\n",
      "Val Loss: 0.02131857419455493\n",
      "Starting epoch 2000\n",
      "Train Loss: 0.021370956743205036\n",
      "Val Loss: 0.021314788747716834\n",
      "Starting epoch 2001\n",
      "Train Loss: 0.021556427081425984\n",
      "Val Loss: 0.021461496198618854\n",
      "Starting epoch 2002\n",
      "Train Loss: 0.021724220779207017\n",
      "Val Loss: 0.021260072235707885\n",
      "Starting epoch 2003\n",
      "Train Loss: 0.02126149778012876\n",
      "Val Loss: 0.021249495170734548\n",
      "Starting epoch 2004\n",
      "Train Loss: 0.021489059483563458\n",
      "Val Loss: 0.02128091840832322\n",
      "Starting epoch 2005\n",
      "Train Loss: 0.021778612225143996\n",
      "Val Loss: 0.02133118775155809\n",
      "Starting epoch 2006\n",
      "Train Loss: 0.021309094848456205\n",
      "Val Loss: 0.021314689958537067\n",
      "Starting epoch 2007\n",
      "Train Loss: 0.02133836128093578\n",
      "Val Loss: 0.021361176062513282\n",
      "Starting epoch 2008\n",
      "Train Loss: 0.021885180914843524\n",
      "Val Loss: 0.021284532767755014\n",
      "Starting epoch 2009\n",
      "Train Loss: 0.02130642478112821\n",
      "Val Loss: 0.021269809316705773\n",
      "Starting epoch 2010\n",
      "Train Loss: 0.02129630192562386\n",
      "Val Loss: 0.02126849525504642\n",
      "Starting epoch 2011\n",
      "Train Loss: 0.021923721940429124\n",
      "Val Loss: 0.021724267690270034\n",
      "Starting epoch 2012\n",
      "Train Loss: 0.021382121576203242\n",
      "Val Loss: 0.021267307577309786\n",
      "Starting epoch 2013\n",
      "Train Loss: 0.02131542729006873\n",
      "Val Loss: 0.021351890983404936\n",
      "Starting epoch 2014\n",
      "Train Loss: 0.021394279819947702\n",
      "Val Loss: 0.02125968149414769\n",
      "Starting epoch 2015\n",
      "Train Loss: 0.021308083777074462\n",
      "Val Loss: 0.02131580368236259\n",
      "Starting epoch 2016\n",
      "Train Loss: 0.021704530274426495\n",
      "Val Loss: 0.021363726368656865\n",
      "Starting epoch 2017\n",
      "Train Loss: 0.021305452342386597\n",
      "Val Loss: 0.02125892926145483\n",
      "Starting epoch 2018\n",
      "Train Loss: 0.021723286973105535\n",
      "Val Loss: 0.021333025561438665\n",
      "Starting epoch 2019\n",
      "Train Loss: 0.021334970438921894\n",
      "Val Loss: 0.021343530880080328\n",
      "Starting epoch 2020\n",
      "Train Loss: 0.021323031849331327\n",
      "Val Loss: 0.021461198727289837\n",
      "Starting epoch 2021\n",
      "Train Loss: 0.021241594243932654\n",
      "Val Loss: 0.021375134587287903\n",
      "Starting epoch 2022\n",
      "Train Loss: 0.021294368086037813\n",
      "Val Loss: 0.021335315925103647\n",
      "Starting epoch 2023\n",
      "Train Loss: 0.0212863529170001\n",
      "Val Loss: 0.021395735718585825\n",
      "Starting epoch 2024\n",
      "Train Loss: 0.021320382202113117\n",
      "Val Loss: 0.021454286796075327\n",
      "Starting epoch 2025\n",
      "Train Loss: 0.021337692384366638\n",
      "Val Loss: 0.021288469985679345\n",
      "Starting epoch 2026\n",
      "Train Loss: 0.021458165513144598\n",
      "Val Loss: 0.021318087423289264\n",
      "Starting epoch 2027\n",
      "Train Loss: 0.021272203436604253\n",
      "Val Loss: 0.02127406166659461\n",
      "Starting epoch 2028\n",
      "Train Loss: 0.021307678134353074\n",
      "Val Loss: 0.021359879109594557\n",
      "Starting epoch 2029\n",
      "Train Loss: 0.021304308816238685\n",
      "Val Loss: 0.021482366102713125\n",
      "Starting epoch 2030\n",
      "Train Loss: 0.021320451188970496\n",
      "Val Loss: 0.02126907695222784\n",
      "Starting epoch 2031\n",
      "Train Loss: 0.021379753947257996\n",
      "Val Loss: 0.021256891113740427\n",
      "Starting epoch 2032\n",
      "Train Loss: 0.021254492578683077\n",
      "Val Loss: 0.021226880726990877\n",
      "Starting epoch 2033\n",
      "Train Loss: 0.02125024022879424\n",
      "Val Loss: 0.02129923524679961\n",
      "Starting epoch 2034\n",
      "Train Loss: 0.021324900013429147\n",
      "Val Loss: 0.021448149173348037\n",
      "Starting epoch 2035\n",
      "Train Loss: 0.02134861327983715\n",
      "Val Loss: 0.02148959813294587\n",
      "Starting epoch 2036\n",
      "Train Loss: 0.021267044875356887\n",
      "Val Loss: 0.021285461606802763\n",
      "Starting epoch 2037\n",
      "Train Loss: 0.021681415813940542\n",
      "Val Loss: 0.021416185630692378\n",
      "Starting epoch 2038\n",
      "Train Loss: 0.02141764815206881\n",
      "Val Loss: 0.021347497900327046\n",
      "Starting epoch 2039\n",
      "Train Loss: 0.02131419270126908\n",
      "Val Loss: 0.02140858879795781\n",
      "Starting epoch 2040\n",
      "Train Loss: 0.021283268928527832\n",
      "Val Loss: 0.021253634382177283\n",
      "Starting epoch 2041\n",
      "Train Loss: 0.021331327380957426\n",
      "Val Loss: 0.02127422778694718\n",
      "Starting epoch 2042\n",
      "Train Loss: 0.02123499910036723\n",
      "Val Loss: 0.021320809920628864\n",
      "Starting epoch 2043\n",
      "Train Loss: 0.021406642264790006\n",
      "Val Loss: 0.0213746119428564\n",
      "Starting epoch 2044\n",
      "Train Loss: 0.021253426869710285\n",
      "Val Loss: 0.021335669137813425\n",
      "Starting epoch 2045\n",
      "Train Loss: 0.021298023285689176\n",
      "Val Loss: 0.02165668816478164\n",
      "Starting epoch 2046\n",
      "Train Loss: 0.021304663684633043\n",
      "Val Loss: 0.021235218754521123\n",
      "Starting epoch 2047\n",
      "Train Loss: 0.021324377368997643\n",
      "Val Loss: 0.021443918347358704\n",
      "Starting epoch 2048\n",
      "Train Loss: 0.02130095550307521\n",
      "Val Loss: 0.021528267198138766\n",
      "Starting epoch 2049\n",
      "Train Loss: 0.021353264649709065\n",
      "Val Loss: 0.02136224121959121\n",
      "Starting epoch 2050\n",
      "Train Loss: 0.02127622178307286\n",
      "Val Loss: 0.021249680055512324\n",
      "Starting epoch 2051\n",
      "Train Loss: 0.02147220958162237\n",
      "Val Loss: 0.021451006333033245\n",
      "Starting epoch 2052\n",
      "Train Loss: 0.021394124185597455\n",
      "Val Loss: 0.021277323365211487\n",
      "Starting epoch 2053\n",
      "Train Loss: 0.02126840474428954\n",
      "Val Loss: 0.021330984654249967\n",
      "Starting epoch 2054\n",
      "Train Loss: 0.021245438743520667\n",
      "Val Loss: 0.021391038541440612\n",
      "Starting epoch 2055\n",
      "Train Loss: 0.021288168651086313\n",
      "Val Loss: 0.0212564159322668\n",
      "Starting epoch 2056\n",
      "Train Loss: 0.02125729951593611\n",
      "Val Loss: 0.021253244744406805\n",
      "Starting epoch 2057\n",
      "Train Loss: 0.02142709604016057\n",
      "Val Loss: 0.021258669318976225\n",
      "Starting epoch 2058\n",
      "Train Loss: 0.021443569549807796\n",
      "Val Loss: 0.021314250098334417\n",
      "Starting epoch 2059\n",
      "Train Loss: 0.02143805722395579\n",
      "Val Loss: 0.021324651660742582\n",
      "Starting epoch 2060\n",
      "Train Loss: 0.021490105876216182\n",
      "Val Loss: 0.021238660370862042\n",
      "Starting epoch 2061\n",
      "Train Loss: 0.02126298568866871\n",
      "Val Loss: 0.021291923743707163\n",
      "Starting epoch 2062\n",
      "Train Loss: 0.021234238037356624\n",
      "Val Loss: 0.021276528636614483\n",
      "Starting epoch 2063\n",
      "Train Loss: 0.021286220462233933\n",
      "Val Loss: 0.02126777668793996\n",
      "Starting epoch 2064\n",
      "Train Loss: 0.021219718787405226\n",
      "Val Loss: 0.02169933087295956\n",
      "Starting epoch 2065\n",
      "Train Loss: 0.021243895645494813\n",
      "Val Loss: 0.021277741701514634\n",
      "Starting epoch 2066\n",
      "Train Loss: 0.021329771589349816\n",
      "Val Loss: 0.02133599254820082\n",
      "Starting epoch 2067\n",
      "Train Loss: 0.021385410317668208\n",
      "Val Loss: 0.02175909060019034\n",
      "Starting epoch 2068\n",
      "Train Loss: 0.021355295070895442\n",
      "Val Loss: 0.02127200089119099\n",
      "Starting epoch 2069\n",
      "Train Loss: 0.021241769194602966\n",
      "Val Loss: 0.02124165881563116\n",
      "Starting epoch 2070\n",
      "Train Loss: 0.021366155257931462\n",
      "Val Loss: 0.021247933860178345\n",
      "Starting epoch 2071\n",
      "Train Loss: 0.02122989959186978\n",
      "Val Loss: 0.021301136524588975\n",
      "Starting epoch 2072\n",
      "Train Loss: 0.02128737833764818\n",
      "Val Loss: 0.02134614134276355\n",
      "Starting epoch 2073\n",
      "Train Loss: 0.021754077739185758\n",
      "Val Loss: 0.02125518631052088\n",
      "Starting epoch 2074\n",
      "Train Loss: 0.02124684993867521\n",
      "Val Loss: 0.021287476023038227\n",
      "Starting epoch 2075\n",
      "Train Loss: 0.02141914213145221\n",
      "Val Loss: 0.02128393672130726\n",
      "Starting epoch 2076\n",
      "Train Loss: 0.02125770571055236\n",
      "Val Loss: 0.021254528451848914\n",
      "Starting epoch 2077\n",
      "Train Loss: 0.021378124201739276\n",
      "Val Loss: 0.02168926265504625\n",
      "Starting epoch 2078\n",
      "Train Loss: 0.02141539200588509\n",
      "Val Loss: 0.021381995744175382\n",
      "Starting epoch 2079\n",
      "Train Loss: 0.021285214357905917\n",
      "Val Loss: 0.021273330957801255\n",
      "Starting epoch 2080\n",
      "Train Loss: 0.02125821069434837\n",
      "Val Loss: 0.021635781835626672\n",
      "Starting epoch 2081\n",
      "Train Loss: 0.02133918857132947\n",
      "Val Loss: 0.021278225713306002\n",
      "Starting epoch 2082\n",
      "Train Loss: 0.021291162128801697\n",
      "Val Loss: 0.021378034242877254\n",
      "Starting epoch 2083\n",
      "Train Loss: 0.021230614295712224\n",
      "Val Loss: 0.02123067886741073\n",
      "Starting epoch 2084\n",
      "Train Loss: 0.02129854593012068\n",
      "Val Loss: 0.021298509505059984\n",
      "Starting epoch 2085\n",
      "Train Loss: 0.021280098292562697\n",
      "Val Loss: 0.021264675038832205\n",
      "Starting epoch 2086\n",
      "Train Loss: 0.021309165490998164\n",
      "Val Loss: 0.021265137526724074\n",
      "Starting epoch 2087\n",
      "Train Loss: 0.02141526782954181\n",
      "Val Loss: 0.021299923459688824\n",
      "Starting epoch 2088\n",
      "Train Loss: 0.021218823062049016\n",
      "Val Loss: 0.021230404023770934\n",
      "Starting epoch 2089\n",
      "Train Loss: 0.021694985252839548\n",
      "Val Loss: 0.02122954969052915\n",
      "Starting epoch 2090\n",
      "Train Loss: 0.021316598410959595\n",
      "Val Loss: 0.021685030725267198\n",
      "Starting epoch 2091\n",
      "Train Loss: 0.02128529217508104\n",
      "Val Loss: 0.021697562601831224\n",
      "Starting epoch 2092\n",
      "Train Loss: 0.02123723151507201\n",
      "Val Loss: 0.021203017345181218\n",
      "Starting epoch 2093\n",
      "Train Loss: 0.021273698519777368\n",
      "Val Loss: 0.02138000119615484\n",
      "Starting epoch 2094\n",
      "Train Loss: 0.02140154993092572\n",
      "Val Loss: 0.02170953044184932\n",
      "Starting epoch 2095\n",
      "Train Loss: 0.021351673536830477\n",
      "Val Loss: 0.02127483707887155\n",
      "Starting epoch 2096\n",
      "Train Loss: 0.021209683683183458\n",
      "Val Loss: 0.021252676292702003\n",
      "Starting epoch 2097\n",
      "Train Loss: 0.02136184275150299\n",
      "Val Loss: 0.02123029143721969\n",
      "Starting epoch 2098\n",
      "Train Loss: 0.02124946978357103\n",
      "Val Loss: 0.021257077102307922\n",
      "Starting epoch 2099\n",
      "Train Loss: 0.021253746416833665\n",
      "Val Loss: 0.021466321967266225\n",
      "Starting epoch 2100\n",
      "Train Loss: 0.02123034938617989\n",
      "Val Loss: 0.02164633516912107\n",
      "Starting epoch 2101\n",
      "Train Loss: 0.021251387066311307\n",
      "Val Loss: 0.021249837897442007\n",
      "Starting epoch 2102\n",
      "Train Loss: 0.02123358624952811\n",
      "Val Loss: 0.021273740463786654\n",
      "Starting epoch 2103\n",
      "Train Loss: 0.0212621600539596\n",
      "Val Loss: 0.021300941705703735\n",
      "Starting epoch 2104\n",
      "Train Loss: 0.021264594462182786\n",
      "Val Loss: 0.021230191544250206\n",
      "Starting epoch 2105\n",
      "Train Loss: 0.021238705626240483\n",
      "Val Loss: 0.021284071383652865\n",
      "Starting epoch 2106\n",
      "Train Loss: 0.02128457360797458\n",
      "Val Loss: 0.021203366694626986\n",
      "Starting epoch 2107\n",
      "Train Loss: 0.021238654851913452\n",
      "Val Loss: 0.02166875700155894\n",
      "Starting epoch 2108\n",
      "Train Loss: 0.021351909195935284\n",
      "Val Loss: 0.021213696510703477\n",
      "Starting epoch 2109\n",
      "Train Loss: 0.02137277082160667\n",
      "Val Loss: 0.021291802878733033\n",
      "Starting epoch 2110\n",
      "Train Loss: 0.0213339869622831\n",
      "Val Loss: 0.021243494969827158\n",
      "Starting epoch 2111\n",
      "Train Loss: 0.021242237753338285\n",
      "Val Loss: 0.02128924705364086\n",
      "Starting epoch 2112\n",
      "Train Loss: 0.021728694438934326\n",
      "Val Loss: 0.021390170962722214\n",
      "Starting epoch 2113\n",
      "Train Loss: 0.021217635936207242\n",
      "Val Loss: 0.021355953481462266\n",
      "Starting epoch 2114\n",
      "Train Loss: 0.02131991861043153\n",
      "Val Loss: 0.021266070780930697\n",
      "Starting epoch 2115\n",
      "Train Loss: 0.021312869809291982\n",
      "Val Loss: 0.021235896481408015\n",
      "Starting epoch 2116\n",
      "Train Loss: 0.02125317465375971\n",
      "Val Loss: 0.021223075411937856\n",
      "Starting epoch 2117\n",
      "Train Loss: 0.021246168348524306\n",
      "Val Loss: 0.021369497533197754\n",
      "Starting epoch 2118\n",
      "Train Loss: 0.021234400846340037\n",
      "Val Loss: 0.02120856554419906\n",
      "Starting epoch 2119\n",
      "Train Loss: 0.02150125856752749\n",
      "Val Loss: 0.021702475569866323\n",
      "Starting epoch 2120\n",
      "Train Loss: 0.021385077525068213\n",
      "Val Loss: 0.021277837731220103\n",
      "Starting epoch 2121\n",
      "Train Loss: 0.021330159571435716\n",
      "Val Loss: 0.02168281265982875\n",
      "Starting epoch 2122\n",
      "Train Loss: 0.02123237704789197\n",
      "Val Loss: 0.02163908271877854\n",
      "Starting epoch 2123\n",
      "Train Loss: 0.02144543605822104\n",
      "Val Loss: 0.021660886428974294\n",
      "Starting epoch 2124\n",
      "Train Loss: 0.0212264452819471\n",
      "Val Loss: 0.02136693729294671\n",
      "Starting epoch 2125\n",
      "Train Loss: 0.021239632809603656\n",
      "Val Loss: 0.02135679512112229\n",
      "Starting epoch 2126\n",
      "Train Loss: 0.021193715709227103\n",
      "Val Loss: 0.021603861892664875\n",
      "Starting epoch 2127\n",
      "Train Loss: 0.021219816472795274\n",
      "Val Loss: 0.021206188533041213\n",
      "Starting epoch 2128\n",
      "Train Loss: 0.02118101771231051\n",
      "Val Loss: 0.021369924699818646\n",
      "Starting epoch 2129\n",
      "Train Loss: 0.021211114194658067\n",
      "Val Loss: 0.021359876902015122\n",
      "Starting epoch 2130\n",
      "Train Loss: 0.02125284848389802\n",
      "Val Loss: 0.02120476519619977\n",
      "Starting epoch 2131\n",
      "Train Loss: 0.0213139647686923\n",
      "Val Loss: 0.021220563738434402\n",
      "Starting epoch 2132\n",
      "Train Loss: 0.021243176526493497\n",
      "Val Loss: 0.021202377147144742\n",
      "Starting epoch 2133\n",
      "Train Loss: 0.02120760248767005\n",
      "Val Loss: 0.021649542230146902\n",
      "Starting epoch 2134\n",
      "Train Loss: 0.021241436953897828\n",
      "Val Loss: 0.021331244596728572\n",
      "Starting epoch 2135\n",
      "Train Loss: 0.021381229162216187\n",
      "Val Loss: 0.021204107889422664\n",
      "Starting epoch 2136\n",
      "Train Loss: 0.02124576656906693\n",
      "Val Loss: 0.021194510437824107\n",
      "Starting epoch 2137\n",
      "Train Loss: 0.021224220593770344\n",
      "Val Loss: 0.021393440939761973\n",
      "Starting epoch 2138\n",
      "Train Loss: 0.021351537770695157\n",
      "Val Loss: 0.021660984114364342\n",
      "Starting epoch 2139\n",
      "Train Loss: 0.021212198116161204\n",
      "Val Loss: 0.021231732434696622\n",
      "Starting epoch 2140\n",
      "Train Loss: 0.021218859487109713\n",
      "Val Loss: 0.021200990235363995\n",
      "Starting epoch 2141\n",
      "Train Loss: 0.02123006405653777\n",
      "Val Loss: 0.021605195822539152\n",
      "Starting epoch 2142\n",
      "Train Loss: 0.02122877648583165\n",
      "Val Loss: 0.021218516760402255\n",
      "Starting epoch 2143\n",
      "Train Loss: 0.02117900053660075\n",
      "Val Loss: 0.021202585211506596\n",
      "Starting epoch 2144\n",
      "Train Loss: 0.02135485686637737\n",
      "Val Loss: 0.02127115262879266\n",
      "Starting epoch 2145\n",
      "Train Loss: 0.02123221037564454\n",
      "Val Loss: 0.02118903895219167\n",
      "Starting epoch 2146\n",
      "Train Loss: 0.021194923255178664\n",
      "Val Loss: 0.021826572992183543\n",
      "Starting epoch 2147\n",
      "Train Loss: 0.021216613275033457\n",
      "Val Loss: 0.02130212993533523\n",
      "Starting epoch 2148\n",
      "Train Loss: 0.021309797410611755\n",
      "Val Loss: 0.021223256985346477\n",
      "Starting epoch 2149\n",
      "Train Loss: 0.02123297971707803\n",
      "Val Loss: 0.021267499084825867\n",
      "Starting epoch 2150\n",
      "Train Loss: 0.021657603206457914\n",
      "Val Loss: 0.02159496424374757\n",
      "Starting epoch 2151\n",
      "Train Loss: 0.021268367767333984\n",
      "Val Loss: 0.021181180521293922\n",
      "Starting epoch 2152\n",
      "Train Loss: 0.021332993551536842\n",
      "Val Loss: 0.02130662511896204\n",
      "Starting epoch 2153\n",
      "Train Loss: 0.02124313458248421\n",
      "Val Loss: 0.02134711985234861\n",
      "Starting epoch 2154\n",
      "Train Loss: 0.021258172613603098\n",
      "Val Loss: 0.021206826523498253\n",
      "Starting epoch 2155\n",
      "Train Loss: 0.0212155861987008\n",
      "Val Loss: 0.021232977509498596\n",
      "Starting epoch 2156\n",
      "Train Loss: 0.021344080015465065\n",
      "Val Loss: 0.02143569952911801\n",
      "Starting epoch 2157\n",
      "Train Loss: 0.021601723851980986\n",
      "Val Loss: 0.021269686244152212\n",
      "Starting epoch 2158\n",
      "Train Loss: 0.02176920407348209\n",
      "Val Loss: 0.02165895093370367\n",
      "Starting epoch 2159\n",
      "Train Loss: 0.0211983323097229\n",
      "Val Loss: 0.02136805432814139\n",
      "Starting epoch 2160\n",
      "Train Loss: 0.021256865174682053\n",
      "Val Loss: 0.02117372386985355\n",
      "Starting epoch 2161\n",
      "Train Loss: 0.021662337912453547\n",
      "Val Loss: 0.02121540241771274\n",
      "Starting epoch 2162\n",
      "Train Loss: 0.02159182948094827\n",
      "Val Loss: 0.021642396847407024\n",
      "Starting epoch 2163\n",
      "Train Loss: 0.021248210359502723\n",
      "Val Loss: 0.021232430581693298\n",
      "Starting epoch 2164\n",
      "Train Loss: 0.021257904944596468\n",
      "Val Loss: 0.02160623945571758\n",
      "Starting epoch 2165\n",
      "Train Loss: 0.021317376030815974\n",
      "Val Loss: 0.021181334499959594\n",
      "Starting epoch 2166\n",
      "Train Loss: 0.02121134047155027\n",
      "Val Loss: 0.02163140254992026\n",
      "Starting epoch 2167\n",
      "Train Loss: 0.021254804951173288\n",
      "Val Loss: 0.02136195699373881\n",
      "Starting epoch 2168\n",
      "Train Loss: 0.021195184853341844\n",
      "Val Loss: 0.02117693589793311\n",
      "Starting epoch 2169\n",
      "Train Loss: 0.021386857385988587\n",
      "Val Loss: 0.021220797189959773\n",
      "Starting epoch 2170\n",
      "Train Loss: 0.021189578705363803\n",
      "Val Loss: 0.021172634429401822\n",
      "Starting epoch 2171\n",
      "Train Loss: 0.02129243314266205\n",
      "Val Loss: 0.02160328461064233\n",
      "Starting epoch 2172\n",
      "Train Loss: 0.0216538409392039\n",
      "Val Loss: 0.021186887114136306\n",
      "Starting epoch 2173\n",
      "Train Loss: 0.021195317308108013\n",
      "Val Loss: 0.021206226613786485\n",
      "Starting epoch 2174\n",
      "Train Loss: 0.021230892450721177\n",
      "Val Loss: 0.021236446168687608\n",
      "Starting epoch 2175\n",
      "Train Loss: 0.021220551044852647\n",
      "Val Loss: 0.02133063640859392\n",
      "Starting epoch 2176\n",
      "Train Loss: 0.021177288006853173\n",
      "Val Loss: 0.021223452908021433\n",
      "Starting epoch 2177\n",
      "Train Loss: 0.021226014252062195\n",
      "Val Loss: 0.021173215574688382\n",
      "Starting epoch 2178\n",
      "Train Loss: 0.021194894004751136\n",
      "Val Loss: 0.02128149293087147\n",
      "Starting epoch 2179\n",
      "Train Loss: 0.02124325931072235\n",
      "Val Loss: 0.021314363788675378\n",
      "Starting epoch 2180\n",
      "Train Loss: 0.021279583926554078\n",
      "Val Loss: 0.021248412904915987\n",
      "Starting epoch 2181\n",
      "Train Loss: 0.021239568789800007\n",
      "Val Loss: 0.02121418548954858\n",
      "Starting epoch 2182\n",
      "Train Loss: 0.021220786152062594\n",
      "Val Loss: 0.021747351796538743\n",
      "Starting epoch 2183\n",
      "Train Loss: 0.021596712094766123\n",
      "Val Loss: 0.021160036325454712\n",
      "Starting epoch 2184\n",
      "Train Loss: 0.02123066065488038\n",
      "Val Loss: 0.021621438088240446\n",
      "Starting epoch 2185\n",
      "Train Loss: 0.021369633299333078\n",
      "Val Loss: 0.021226959647955717\n",
      "Starting epoch 2186\n",
      "Train Loss: 0.02159736829775351\n",
      "Val Loss: 0.021238430782600685\n",
      "Starting epoch 2187\n",
      "Train Loss: 0.021213561296463013\n",
      "Val Loss: 0.02129702545978405\n",
      "Starting epoch 2188\n",
      "Train Loss: 0.02115366304362262\n",
      "Val Loss: 0.021252840757369995\n",
      "Starting epoch 2189\n",
      "Train Loss: 0.021172198432463187\n",
      "Val Loss: 0.021201698316468134\n",
      "Starting epoch 2190\n",
      "Train Loss: 0.021163124729085853\n",
      "Val Loss: 0.02135281761487325\n",
      "Starting epoch 2191\n",
      "Train Loss: 0.021212375826305814\n",
      "Val Loss: 0.021171479313461868\n",
      "Starting epoch 2192\n",
      "Train Loss: 0.021195636303336533\n",
      "Val Loss: 0.021209170972859417\n",
      "Starting epoch 2193\n",
      "Train Loss: 0.02127746409840054\n",
      "Val Loss: 0.021220927437146504\n",
      "Starting epoch 2194\n",
      "Train Loss: 0.021250800402076157\n",
      "Val Loss: 0.021217318044768438\n",
      "Starting epoch 2195\n",
      "Train Loss: 0.021184061964352924\n",
      "Val Loss: 0.021168824699189927\n",
      "Starting epoch 2196\n",
      "Train Loss: 0.021161995552204275\n",
      "Val Loss: 0.021195854301805848\n",
      "Starting epoch 2197\n",
      "Train Loss: 0.021190627305595962\n",
      "Val Loss: 0.021174748186711913\n",
      "Starting epoch 2198\n",
      "Train Loss: 0.021292998282997695\n",
      "Val Loss: 0.021252440081702337\n",
      "Starting epoch 2199\n",
      "Train Loss: 0.021180243955718145\n",
      "Val Loss: 0.021168529435440345\n",
      "Starting epoch 2200\n",
      "Train Loss: 0.021171737048361037\n",
      "Val Loss: 0.021259308965117844\n",
      "Starting epoch 2201\n",
      "Train Loss: 0.02124275377503148\n",
      "Val Loss: 0.021232683349538733\n",
      "Starting epoch 2202\n",
      "Train Loss: 0.02117816938294305\n",
      "Val Loss: 0.021182182762357924\n",
      "Starting epoch 2203\n",
      "Train Loss: 0.021194684284704703\n",
      "Val Loss: 0.02120842425911515\n",
      "Starting epoch 2204\n",
      "Train Loss: 0.021355841446805884\n",
      "Val Loss: 0.02118612715491542\n",
      "Starting epoch 2205\n",
      "Train Loss: 0.0212999830643336\n",
      "Val Loss: 0.021279277624907316\n",
      "Starting epoch 2206\n",
      "Train Loss: 0.02132570798750277\n",
      "Val Loss: 0.021730626622835796\n",
      "Starting epoch 2207\n",
      "Train Loss: 0.021179427703221638\n",
      "Val Loss: 0.021218894256485835\n",
      "Starting epoch 2208\n",
      "Train Loss: 0.021176614695125155\n",
      "Val Loss: 0.021158170920831186\n",
      "Starting epoch 2209\n",
      "Train Loss: 0.02124690788763541\n",
      "Val Loss: 0.021227815084987216\n",
      "Starting epoch 2210\n",
      "Train Loss: 0.021250378754403856\n",
      "Val Loss: 0.02134192431414569\n",
      "Starting epoch 2211\n",
      "Train Loss: 0.021239312158690557\n",
      "Val Loss: 0.02125303723193981\n",
      "Starting epoch 2212\n",
      "Train Loss: 0.021204078087100276\n",
      "Val Loss: 0.02122728747350198\n",
      "Starting epoch 2213\n",
      "Train Loss: 0.02114518373100846\n",
      "Val Loss: 0.021317511245056434\n",
      "Starting epoch 2214\n",
      "Train Loss: 0.0212450099212152\n",
      "Val Loss: 0.021651620114291156\n",
      "Starting epoch 2215\n",
      "Train Loss: 0.021228779245305945\n",
      "Val Loss: 0.021201006792209768\n",
      "Starting epoch 2216\n",
      "Train Loss: 0.021762990289264254\n",
      "Val Loss: 0.02122820030759882\n",
      "Starting epoch 2217\n",
      "Train Loss: 0.021574450311837374\n",
      "Val Loss: 0.021179123057259455\n",
      "Starting epoch 2218\n",
      "Train Loss: 0.021690804649282386\n",
      "Val Loss: 0.021184677879015606\n",
      "Starting epoch 2219\n",
      "Train Loss: 0.021298760065325984\n",
      "Val Loss: 0.02116692011003141\n",
      "Starting epoch 2220\n",
      "Train Loss: 0.021597777251844055\n",
      "Val Loss: 0.021200541544843604\n",
      "Starting epoch 2221\n",
      "Train Loss: 0.021184358331892226\n",
      "Val Loss: 0.021149476921116864\n",
      "Starting epoch 2222\n",
      "Train Loss: 0.021625213049076223\n",
      "Val Loss: 0.02116101814640893\n",
      "Starting epoch 2223\n",
      "Train Loss: 0.021139698448004545\n",
      "Val Loss: 0.02122213167172891\n",
      "Starting epoch 2224\n",
      "Train Loss: 0.021176188632293983\n",
      "Val Loss: 0.021164205891114694\n",
      "Starting epoch 2225\n",
      "Train Loss: 0.02127464943461948\n",
      "Val Loss: 0.021612671238404733\n",
      "Starting epoch 2226\n",
      "Train Loss: 0.02126233610841963\n",
      "Val Loss: 0.02115085776205416\n",
      "Starting epoch 2227\n",
      "Train Loss: 0.021235482560263738\n",
      "Val Loss: 0.02115631820978942\n",
      "Starting epoch 2228\n",
      "Train Loss: 0.02163086058916869\n",
      "Val Loss: 0.021344415015644498\n",
      "Starting epoch 2229\n",
      "Train Loss: 0.0216049082853176\n",
      "Val Loss: 0.02120340367158254\n",
      "Starting epoch 2230\n",
      "Train Loss: 0.02115974050981027\n",
      "Val Loss: 0.02126517395178477\n",
      "Starting epoch 2231\n",
      "Train Loss: 0.021160947503866972\n",
      "Val Loss: 0.02116340895493825\n",
      "Starting epoch 2232\n",
      "Train Loss: 0.021153881593986793\n",
      "Val Loss: 0.02127831787974746\n",
      "Starting epoch 2233\n",
      "Train Loss: 0.021588422082088613\n",
      "Val Loss: 0.021359408343279804\n",
      "Starting epoch 2234\n",
      "Train Loss: 0.02142972692295357\n",
      "Val Loss: 0.021182410143039846\n",
      "Starting epoch 2235\n",
      "Train Loss: 0.02124275156745204\n",
      "Val Loss: 0.021218853416266264\n",
      "Starting epoch 2236\n",
      "Train Loss: 0.02120440701643626\n",
      "Val Loss: 0.021210670471191406\n",
      "Starting epoch 2237\n",
      "Train Loss: 0.021594749556647405\n",
      "Val Loss: 0.021241431986844098\n",
      "Starting epoch 2238\n",
      "Train Loss: 0.021276019237659597\n",
      "Val Loss: 0.02123564923251117\n",
      "Starting epoch 2239\n",
      "Train Loss: 0.02119011073200791\n",
      "Val Loss: 0.02114142256754416\n",
      "Starting epoch 2240\n",
      "Train Loss: 0.021181209219826594\n",
      "Val Loss: 0.021254044440057542\n",
      "Starting epoch 2241\n",
      "Train Loss: 0.02127017025594358\n",
      "Val Loss: 0.02118766142262353\n",
      "Starting epoch 2242\n",
      "Train Loss: 0.021586858563952975\n",
      "Val Loss: 0.021198569072617426\n",
      "Starting epoch 2243\n",
      "Train Loss: 0.021146320634418063\n",
      "Val Loss: 0.021171812657956725\n",
      "Starting epoch 2244\n",
      "Train Loss: 0.021136171287960477\n",
      "Val Loss: 0.02120679340980671\n",
      "Starting epoch 2245\n",
      "Train Loss: 0.021187932402999314\n",
      "Val Loss: 0.021612534368479694\n",
      "Starting epoch 2246\n",
      "Train Loss: 0.02158666208938316\n",
      "Val Loss: 0.02129388572993102\n",
      "Starting epoch 2247\n",
      "Train Loss: 0.02121016824686969\n",
      "Val Loss: 0.02114660210079617\n",
      "Starting epoch 2248\n",
      "Train Loss: 0.021145323912302654\n",
      "Val Loss: 0.02118433294472871\n",
      "Starting epoch 2249\n",
      "Train Loss: 0.021284776705282706\n",
      "Val Loss: 0.02130681221131925\n",
      "Starting epoch 2250\n",
      "Train Loss: 0.021147112603540772\n",
      "Val Loss: 0.021154052129498235\n",
      "Starting epoch 2251\n",
      "Train Loss: 0.021261352631780837\n",
      "Val Loss: 0.021131989028718736\n",
      "Starting epoch 2252\n",
      "Train Loss: 0.02158312389144191\n",
      "Val Loss: 0.02116433944967058\n",
      "Starting epoch 2253\n",
      "Train Loss: 0.021192563352761446\n",
      "Val Loss: 0.02116218485214092\n",
      "Starting epoch 2254\n",
      "Train Loss: 0.02118685179286533\n",
      "Val Loss: 0.02124831246005164\n",
      "Starting epoch 2255\n",
      "Train Loss: 0.021279160071302344\n",
      "Val Loss: 0.021172268523110285\n",
      "Starting epoch 2256\n",
      "Train Loss: 0.021141044519565725\n",
      "Val Loss: 0.02132970094680786\n",
      "Starting epoch 2257\n",
      "Train Loss: 0.021176676507349366\n",
      "Val Loss: 0.02126753275041227\n",
      "Starting epoch 2258\n",
      "Train Loss: 0.021204848532323486\n",
      "Val Loss: 0.021197402918780292\n",
      "Starting epoch 2259\n",
      "Train Loss: 0.021201734741528828\n",
      "Val Loss: 0.02122426198588477\n",
      "Starting epoch 2260\n",
      "Train Loss: 0.02119058315400724\n",
      "Val Loss: 0.021225403856348107\n",
      "Starting epoch 2261\n",
      "Train Loss: 0.02156120042006175\n",
      "Val Loss: 0.021162480667785363\n",
      "Starting epoch 2262\n",
      "Train Loss: 0.021266568038198683\n",
      "Val Loss: 0.021224124012170015\n",
      "Starting epoch 2263\n",
      "Train Loss: 0.021138887162561768\n",
      "Val Loss: 0.02120854898735329\n",
      "Starting epoch 2264\n",
      "Train Loss: 0.021294907839209946\n",
      "Val Loss: 0.021150053099349694\n",
      "Starting epoch 2265\n",
      "Train Loss: 0.021154016256332397\n",
      "Val Loss: 0.02130815828288043\n",
      "Starting epoch 2266\n",
      "Train Loss: 0.02112773778261962\n",
      "Val Loss: 0.021607185403505962\n",
      "Starting epoch 2267\n",
      "Train Loss: 0.021345168352127075\n",
      "Val Loss: 0.02135771181848314\n",
      "Starting epoch 2268\n",
      "Train Loss: 0.021119826369815402\n",
      "Val Loss: 0.021294969099539297\n",
      "Starting epoch 2269\n",
      "Train Loss: 0.021125529099393775\n",
      "Val Loss: 0.0212686100491771\n",
      "Starting epoch 2270\n",
      "Train Loss: 0.021149977489754005\n",
      "Val Loss: 0.021141437468705355\n",
      "Starting epoch 2271\n",
      "Train Loss: 0.021237617289578473\n",
      "Val Loss: 0.021144465163902\n",
      "Starting epoch 2272\n",
      "Train Loss: 0.021154524551497564\n",
      "Val Loss: 0.021236926869109825\n",
      "Starting epoch 2273\n",
      "Train Loss: 0.021188607922306767\n",
      "Val Loss: 0.021153648142461425\n",
      "Starting epoch 2274\n",
      "Train Loss: 0.021268017865993357\n",
      "Val Loss: 0.02130225631925795\n",
      "Starting epoch 2275\n",
      "Train Loss: 0.02117598056793213\n",
      "Val Loss: 0.021198659031479446\n",
      "Starting epoch 2276\n",
      "Train Loss: 0.021148197628833628\n",
      "Val Loss: 0.0211528186444883\n",
      "Starting epoch 2277\n",
      "Train Loss: 0.02117679516474406\n",
      "Val Loss: 0.021181223569092928\n",
      "Starting epoch 2278\n",
      "Train Loss: 0.021280924479166668\n",
      "Val Loss: 0.021124970029901574\n",
      "Starting epoch 2279\n",
      "Train Loss: 0.021202744709120855\n",
      "Val Loss: 0.021179527596191124\n",
      "Starting epoch 2280\n",
      "Train Loss: 0.021295248910232826\n",
      "Val Loss: 0.021155557146778813\n",
      "Starting epoch 2281\n",
      "Train Loss: 0.021690114780708595\n",
      "Val Loss: 0.021145985634238633\n",
      "Starting epoch 2282\n",
      "Train Loss: 0.0212713446882036\n",
      "Val Loss: 0.021142816102063214\n",
      "Starting epoch 2283\n",
      "Train Loss: 0.021150919574278372\n",
      "Val Loss: 0.021132652406339294\n",
      "Starting epoch 2284\n",
      "Train Loss: 0.021139267970014503\n",
      "Val Loss: 0.02156273082450584\n",
      "Starting epoch 2285\n",
      "Train Loss: 0.02117191144713649\n",
      "Val Loss: 0.02171966819851487\n",
      "Starting epoch 2286\n",
      "Train Loss: 0.021560571259922452\n",
      "Val Loss: 0.021607432652402808\n",
      "Starting epoch 2287\n",
      "Train Loss: 0.021266339553727046\n",
      "Val Loss: 0.02126868510687793\n",
      "Starting epoch 2288\n",
      "Train Loss: 0.02121213244067298\n",
      "Val Loss: 0.02120414983343195\n",
      "Starting epoch 2289\n",
      "Train Loss: 0.021156676941447787\n",
      "Val Loss: 0.021193445280746178\n",
      "Starting epoch 2290\n",
      "Train Loss: 0.02157579638339855\n",
      "Val Loss: 0.021199840086477774\n",
      "Starting epoch 2291\n",
      "Train Loss: 0.02112171936918188\n",
      "Val Loss: 0.021168499633117958\n",
      "Starting epoch 2292\n",
      "Train Loss: 0.02116856144534217\n",
      "Val Loss: 0.02159959188214055\n",
      "Starting epoch 2293\n",
      "Train Loss: 0.021128805699171842\n",
      "Val Loss: 0.02113962118272428\n",
      "Starting epoch 2294\n",
      "Train Loss: 0.021225799564962036\n",
      "Val Loss: 0.021173391629148414\n",
      "Starting epoch 2295\n",
      "Train Loss: 0.021183077383924415\n",
      "Val Loss: 0.02111626112902606\n",
      "Starting epoch 2296\n",
      "Train Loss: 0.021198054154713947\n",
      "Val Loss: 0.021233023868666753\n",
      "Starting epoch 2297\n",
      "Train Loss: 0.02115671612598278\n",
      "Val Loss: 0.021294906183525367\n",
      "Starting epoch 2298\n",
      "Train Loss: 0.02132511414863445\n",
      "Val Loss: 0.021113923854298063\n",
      "Starting epoch 2299\n",
      "Train Loss: 0.021144234471850924\n",
      "Val Loss: 0.021163368114718684\n",
      "Starting epoch 2300\n",
      "Train Loss: 0.02119674340442375\n",
      "Val Loss: 0.021181498964627583\n",
      "Starting epoch 2301\n",
      "Train Loss: 0.021588583787282307\n",
      "Val Loss: 0.021176653327765287\n",
      "Starting epoch 2302\n",
      "Train Loss: 0.021192174266885827\n",
      "Val Loss: 0.02171086271603902\n",
      "Starting epoch 2303\n",
      "Train Loss: 0.021577485733562045\n",
      "Val Loss: 0.021155744791030884\n",
      "Starting epoch 2304\n",
      "Train Loss: 0.021211555710545293\n",
      "Val Loss: 0.02122252462086854\n",
      "Starting epoch 2305\n",
      "Train Loss: 0.021154377195570204\n",
      "Val Loss: 0.02131102372098852\n",
      "Starting epoch 2306\n",
      "Train Loss: 0.021300463212860957\n",
      "Val Loss: 0.02113505756413495\n",
      "Starting epoch 2307\n",
      "Train Loss: 0.021174452371067472\n",
      "Val Loss: 0.021222960065912316\n",
      "Starting epoch 2308\n",
      "Train Loss: 0.021605719570760375\n",
      "Val Loss: 0.021206644398194772\n",
      "Starting epoch 2309\n",
      "Train Loss: 0.02125635301625287\n",
      "Val Loss: 0.021128549068062392\n",
      "Starting epoch 2310\n",
      "Train Loss: 0.02116625397293656\n",
      "Val Loss: 0.021564501303213614\n",
      "Starting epoch 2311\n",
      "Train Loss: 0.021296115385161504\n",
      "Val Loss: 0.021208263105816312\n",
      "Starting epoch 2312\n",
      "Train Loss: 0.021141335368156433\n",
      "Val Loss: 0.02112712628311581\n",
      "Starting epoch 2313\n",
      "Train Loss: 0.021147172208185547\n",
      "Val Loss: 0.02111941189677627\n",
      "Starting epoch 2314\n",
      "Train Loss: 0.021278157830238342\n",
      "Val Loss: 0.02120644019709693\n",
      "Starting epoch 2315\n",
      "Train Loss: 0.021122359015323496\n",
      "Val Loss: 0.021161033047570124\n",
      "Starting epoch 2316\n",
      "Train Loss: 0.02115902966923184\n",
      "Val Loss: 0.021131152908007305\n",
      "Starting epoch 2317\n",
      "Train Loss: 0.021545082330703735\n",
      "Val Loss: 0.021116860486842966\n",
      "Starting epoch 2318\n",
      "Train Loss: 0.021135362210097135\n",
      "Val Loss: 0.021213685472806294\n",
      "Starting epoch 2319\n",
      "Train Loss: 0.021109997122376052\n",
      "Val Loss: 0.02123544889467734\n",
      "Starting epoch 2320\n",
      "Train Loss: 0.02121397963276616\n",
      "Val Loss: 0.021155562113832543\n",
      "Starting epoch 2321\n",
      "Train Loss: 0.02119252692770075\n",
      "Val Loss: 0.02122226909354881\n",
      "Starting epoch 2322\n",
      "Train Loss: 0.02113794066287853\n",
      "Val Loss: 0.02111415785771829\n",
      "Starting epoch 2323\n",
      "Train Loss: 0.021281821860207453\n",
      "Val Loss: 0.021123817121541058\n",
      "Starting epoch 2324\n",
      "Train Loss: 0.021146631903118558\n",
      "Val Loss: 0.021245519872064942\n",
      "Starting epoch 2325\n",
      "Train Loss: 0.02123561943018878\n",
      "Val Loss: 0.021109352509180706\n",
      "Starting epoch 2326\n",
      "Train Loss: 0.021140637773054617\n",
      "Val Loss: 0.021157488778785424\n",
      "Starting epoch 2327\n",
      "Train Loss: 0.02159965369436476\n",
      "Val Loss: 0.021145167174162687\n",
      "Starting epoch 2328\n",
      "Train Loss: 0.021115864316622417\n",
      "Val Loss: 0.021297666209715384\n",
      "Starting epoch 2329\n",
      "Train Loss: 0.02112515491467935\n",
      "Val Loss: 0.02114110191663106\n",
      "Starting epoch 2330\n",
      "Train Loss: 0.021122354600164626\n",
      "Val Loss: 0.021161343212480897\n",
      "Starting epoch 2331\n",
      "Train Loss: 0.021203884923899616\n",
      "Val Loss: 0.021146386309906288\n",
      "Starting epoch 2332\n",
      "Train Loss: 0.02133088089801647\n",
      "Val Loss: 0.021101774992766203\n",
      "Starting epoch 2333\n",
      "Train Loss: 0.021165704285656964\n",
      "Val Loss: 0.021202181776364643\n",
      "Starting epoch 2334\n",
      "Train Loss: 0.02114143912438993\n",
      "Val Loss: 0.02124403913815816\n",
      "Starting epoch 2335\n",
      "Train Loss: 0.021162609259287517\n",
      "Val Loss: 0.02112451692422231\n",
      "Starting epoch 2336\n",
      "Train Loss: 0.021119296550750732\n",
      "Val Loss: 0.021336161428027682\n",
      "Starting epoch 2337\n",
      "Train Loss: 0.021195780899789598\n",
      "Val Loss: 0.021100001754584135\n",
      "Starting epoch 2338\n",
      "Train Loss: 0.021252521210246615\n",
      "Val Loss: 0.021145751078923542\n",
      "Starting epoch 2339\n",
      "Train Loss: 0.021113344364696078\n",
      "Val Loss: 0.021218718202025803\n",
      "Starting epoch 2340\n",
      "Train Loss: 0.021221862347037705\n",
      "Val Loss: 0.02124683945267289\n",
      "Starting epoch 2341\n",
      "Train Loss: 0.02117887580836261\n",
      "Val Loss: 0.02115715984944944\n",
      "Starting epoch 2342\n",
      "Train Loss: 0.021558441497661448\n",
      "Val Loss: 0.021156984898779128\n",
      "Starting epoch 2343\n",
      "Train Loss: 0.021125469494749\n",
      "Val Loss: 0.021760491309342562\n",
      "Starting epoch 2344\n",
      "Train Loss: 0.021137531708787988\n",
      "Val Loss: 0.02116556520815249\n",
      "Starting epoch 2345\n",
      "Train Loss: 0.021166933907402888\n",
      "Val Loss: 0.021197054121229384\n",
      "Starting epoch 2346\n",
      "Train Loss: 0.021242216229438782\n",
      "Val Loss: 0.0210950650550701\n",
      "Starting epoch 2347\n",
      "Train Loss: 0.02119828815813418\n",
      "Val Loss: 0.021249061933270207\n",
      "Starting epoch 2348\n",
      "Train Loss: 0.02114556895362006\n",
      "Val Loss: 0.02137570635036186\n",
      "Starting epoch 2349\n",
      "Train Loss: 0.02112337174238982\n",
      "Val Loss: 0.021106325365878916\n",
      "Starting epoch 2350\n",
      "Train Loss: 0.02113553053802914\n",
      "Val Loss: 0.0212981469101376\n",
      "Starting epoch 2351\n",
      "Train Loss: 0.021101690000957914\n",
      "Val Loss: 0.021235206612834224\n",
      "Starting epoch 2352\n",
      "Train Loss: 0.0211280667119556\n",
      "Val Loss: 0.02114084528552161\n",
      "Starting epoch 2353\n",
      "Train Loss: 0.021106158141736633\n",
      "Val Loss: 0.021154344081878662\n",
      "Starting epoch 2354\n",
      "Train Loss: 0.021245695926524973\n",
      "Val Loss: 0.02113848207173524\n",
      "Starting epoch 2355\n",
      "Train Loss: 0.02117667374787507\n",
      "Val Loss: 0.021347482447270996\n",
      "Starting epoch 2356\n",
      "Train Loss: 0.021546981952808523\n",
      "Val Loss: 0.02112349150357423\n",
      "Starting epoch 2357\n",
      "Train Loss: 0.021093562797263817\n",
      "Val Loss: 0.0212675835247393\n",
      "Starting epoch 2358\n",
      "Train Loss: 0.02113477775344142\n",
      "Val Loss: 0.021566484813336975\n",
      "Starting epoch 2359\n",
      "Train Loss: 0.02122290763590071\n",
      "Val Loss: 0.02122167083952162\n",
      "Starting epoch 2360\n",
      "Train Loss: 0.021127641752914147\n",
      "Val Loss: 0.021178929342163935\n",
      "Starting epoch 2361\n",
      "Train Loss: 0.02111042594468152\n",
      "Val Loss: 0.021141853597429063\n",
      "Starting epoch 2362\n",
      "Train Loss: 0.02121299339665307\n",
      "Val Loss: 0.021114059620433383\n",
      "Starting epoch 2363\n",
      "Train Loss: 0.021180614277168556\n",
      "Val Loss: 0.02114990188015832\n",
      "Starting epoch 2364\n",
      "Train Loss: 0.021289170340255455\n",
      "Val Loss: 0.02113955385155148\n",
      "Starting epoch 2365\n",
      "Train Loss: 0.021220154784343862\n",
      "Val Loss: 0.021105409220412926\n",
      "Starting epoch 2366\n",
      "Train Loss: 0.021229161708443252\n",
      "Val Loss: 0.021152427351033246\n",
      "Starting epoch 2367\n",
      "Train Loss: 0.02114854532259482\n",
      "Val Loss: 0.021094835466808744\n",
      "Starting epoch 2368\n",
      "Train Loss: 0.02155924560847106\n",
      "Val Loss: 0.021359305690836022\n",
      "Starting epoch 2369\n",
      "Train Loss: 0.021275152762730915\n",
      "Val Loss: 0.021574143458295753\n",
      "Starting epoch 2370\n",
      "Train Loss: 0.021099192676720797\n",
      "Val Loss: 0.021158883417094196\n",
      "Starting epoch 2371\n",
      "Train Loss: 0.021110943070164433\n",
      "Val Loss: 0.02116879434497268\n",
      "Starting epoch 2372\n",
      "Train Loss: 0.02156867473213761\n",
      "Val Loss: 0.021145652289743775\n",
      "Starting epoch 2373\n",
      "Train Loss: 0.021548471517033048\n",
      "Val Loss: 0.02110592469021126\n",
      "Starting epoch 2374\n",
      "Train Loss: 0.021152616099075035\n",
      "Val Loss: 0.021214154031541612\n",
      "Starting epoch 2375\n",
      "Train Loss: 0.021101895305845473\n",
      "Val Loss: 0.021160227281075937\n",
      "Starting epoch 2376\n",
      "Train Loss: 0.02111970660863099\n",
      "Val Loss: 0.021218140920003254\n",
      "Starting epoch 2377\n",
      "Train Loss: 0.02121132832986337\n",
      "Val Loss: 0.02113554267971604\n",
      "Starting epoch 2378\n",
      "Train Loss: 0.021588523630742675\n",
      "Val Loss: 0.021136947804027133\n",
      "Starting epoch 2379\n",
      "Train Loss: 0.021119298758330168\n",
      "Val Loss: 0.021188282304339938\n",
      "Starting epoch 2380\n",
      "Train Loss: 0.021157790665273315\n",
      "Val Loss: 0.02116541067759196\n",
      "Starting epoch 2381\n",
      "Train Loss: 0.02109998188636921\n",
      "Val Loss: 0.021208843147313153\n",
      "Starting epoch 2382\n",
      "Train Loss: 0.021262958645820618\n",
      "Val Loss: 0.021246404007629113\n",
      "Starting epoch 2383\n",
      "Train Loss: 0.021678593423631456\n",
      "Val Loss: 0.02112913186903353\n",
      "Starting epoch 2384\n",
      "Train Loss: 0.02111266498212461\n",
      "Val Loss: 0.0211034980085161\n",
      "Starting epoch 2385\n",
      "Train Loss: 0.02112815777460734\n",
      "Val Loss: 0.021128214619777822\n",
      "Starting epoch 2386\n",
      "Train Loss: 0.021096705838486\n",
      "Val Loss: 0.021213687680385732\n",
      "Starting epoch 2387\n",
      "Train Loss: 0.021092930325755366\n",
      "Val Loss: 0.02114995706964422\n",
      "Starting epoch 2388\n",
      "Train Loss: 0.02117694969530459\n",
      "Val Loss: 0.02112373654489164\n",
      "Starting epoch 2389\n",
      "Train Loss: 0.021100235758004366\n",
      "Val Loss: 0.021102827456262376\n",
      "Starting epoch 2390\n",
      "Train Loss: 0.0211133763745979\n",
      "Val Loss: 0.021523811750941806\n",
      "Starting epoch 2391\n",
      "Train Loss: 0.02111391336829574\n",
      "Val Loss: 0.021139774057600234\n",
      "Starting epoch 2392\n",
      "Train Loss: 0.021121146502318205\n",
      "Val Loss: 0.021079193110819214\n",
      "Starting epoch 2393\n",
      "Train Loss: 0.021180872563962585\n",
      "Val Loss: 0.021098947083508526\n",
      "Starting epoch 2394\n",
      "Train Loss: 0.0211664029845485\n",
      "Val Loss: 0.021109857492976718\n",
      "Starting epoch 2395\n",
      "Train Loss: 0.021183765044918767\n",
      "Val Loss: 0.021139375037617154\n",
      "Starting epoch 2396\n",
      "Train Loss: 0.021142897230607492\n",
      "Val Loss: 0.021120485332277086\n",
      "Starting epoch 2397\n",
      "Train Loss: 0.021095997757381864\n",
      "Val Loss: 0.021248066314944514\n",
      "Starting epoch 2398\n",
      "Train Loss: 0.021090732128531846\n",
      "Val Loss: 0.02113176551130083\n",
      "Starting epoch 2399\n",
      "Train Loss: 0.021113864801548147\n",
      "Val Loss: 0.021114641317614802\n",
      "Starting epoch 2400\n",
      "Train Loss: 0.021088249705455923\n",
      "Val Loss: 0.021735912119900738\n",
      "Starting epoch 2401\n",
      "Train Loss: 0.02108080464380759\n",
      "Val Loss: 0.02120376240324091\n",
      "Starting epoch 2402\n",
      "Train Loss: 0.021101478073332045\n",
      "Val Loss: 0.02111427817079756\n",
      "Starting epoch 2403\n",
      "Train Loss: 0.021144375756934838\n",
      "Val Loss: 0.02107543581061893\n",
      "Starting epoch 2404\n",
      "Train Loss: 0.021079089906480577\n",
      "Val Loss: 0.02158963073182989\n",
      "Starting epoch 2405\n",
      "Train Loss: 0.021521751527433044\n",
      "Val Loss: 0.021086063649919298\n",
      "Starting epoch 2406\n",
      "Train Loss: 0.021079588267538283\n",
      "Val Loss: 0.02113504652623777\n",
      "Starting epoch 2407\n",
      "Train Loss: 0.02117214545055672\n",
      "Val Loss: 0.021126854198950308\n",
      "Starting epoch 2408\n",
      "Train Loss: 0.02165065485018271\n",
      "Val Loss: 0.0215417284656454\n",
      "Starting epoch 2409\n",
      "Train Loss: 0.02113651567035251\n",
      "Val Loss: 0.02113309116275222\n",
      "Starting epoch 2410\n",
      "Train Loss: 0.0210778812567393\n",
      "Val Loss: 0.021160672108332317\n",
      "Starting epoch 2411\n",
      "Train Loss: 0.021191913772512366\n",
      "Val Loss: 0.02111110422346327\n",
      "Starting epoch 2412\n",
      "Train Loss: 0.021102202159387094\n",
      "Val Loss: 0.021528167305169283\n",
      "Starting epoch 2413\n",
      "Train Loss: 0.02118159113106904\n",
      "Val Loss: 0.021114710304472182\n",
      "Starting epoch 2414\n",
      "Train Loss: 0.021576444307963055\n",
      "Val Loss: 0.021123865688288654\n",
      "Starting epoch 2415\n",
      "Train Loss: 0.021080538630485535\n",
      "Val Loss: 0.021154702813537034\n",
      "Starting epoch 2416\n",
      "Train Loss: 0.021112763219409518\n",
      "Val Loss: 0.021153630481825933\n",
      "Starting epoch 2417\n",
      "Train Loss: 0.021091618471675448\n",
      "Val Loss: 0.021097089957307885\n",
      "Starting epoch 2418\n",
      "Train Loss: 0.02158660579610754\n",
      "Val Loss: 0.02110000616974301\n",
      "Starting epoch 2419\n",
      "Train Loss: 0.021216225292947557\n",
      "Val Loss: 0.021120404203732807\n",
      "Starting epoch 2420\n",
      "Train Loss: 0.02109050033269105\n",
      "Val Loss: 0.021099780996640522\n",
      "Starting epoch 2421\n",
      "Train Loss: 0.02110472873405174\n",
      "Val Loss: 0.02168317691043571\n",
      "Starting epoch 2422\n",
      "Train Loss: 0.021535690183992737\n",
      "Val Loss: 0.021089918083614774\n",
      "Starting epoch 2423\n",
      "Train Loss: 0.02115365421330487\n",
      "Val Loss: 0.02108849695435277\n",
      "Starting epoch 2424\n",
      "Train Loss: 0.021086537727603206\n",
      "Val Loss: 0.021136173495539912\n",
      "Starting epoch 2425\n",
      "Train Loss: 0.021247853835423786\n",
      "Val Loss: 0.021235355072551303\n",
      "Starting epoch 2426\n",
      "Train Loss: 0.021169083537878813\n",
      "Val Loss: 0.021261496124444185\n",
      "Starting epoch 2427\n",
      "Train Loss: 0.021074872877862718\n",
      "Val Loss: 0.021125984964547335\n",
      "Starting epoch 2428\n",
      "Train Loss: 0.021529884801970586\n",
      "Val Loss: 0.02109107706281874\n",
      "Starting epoch 2429\n",
      "Train Loss: 0.021134290430280898\n",
      "Val Loss: 0.021507442549422936\n",
      "Starting epoch 2430\n",
      "Train Loss: 0.0216349799323965\n",
      "Val Loss: 0.021091342524245934\n",
      "Starting epoch 2431\n",
      "Train Loss: 0.0211512236683457\n",
      "Val Loss: 0.0212335338195165\n",
      "Starting epoch 2432\n",
      "Train Loss: 0.02115121042286908\n",
      "Val Loss: 0.021103170734864694\n",
      "Starting epoch 2433\n",
      "Train Loss: 0.021150751798241225\n",
      "Val Loss: 0.021576778756247625\n",
      "Starting epoch 2434\n",
      "Train Loss: 0.02115470005406274\n",
      "Val Loss: 0.021080049651640433\n",
      "Starting epoch 2435\n",
      "Train Loss: 0.021108435259924993\n",
      "Val Loss: 0.021109180869879545\n",
      "Starting epoch 2436\n",
      "Train Loss: 0.021107300012199966\n",
      "Val Loss: 0.02110115521483951\n",
      "Starting epoch 2437\n",
      "Train Loss: 0.021065383045761672\n",
      "Val Loss: 0.021084378163019817\n",
      "Starting epoch 2438\n",
      "Train Loss: 0.02108265569916478\n",
      "Val Loss: 0.02131081841610096\n",
      "Starting epoch 2439\n",
      "Train Loss: 0.021566427968166494\n",
      "Val Loss: 0.021157682493880944\n",
      "Starting epoch 2440\n",
      "Train Loss: 0.021222218871116638\n",
      "Val Loss: 0.02110768523481157\n",
      "Starting epoch 2441\n",
      "Train Loss: 0.021078105326052064\n",
      "Val Loss: 0.021084252330991957\n",
      "Starting epoch 2442\n",
      "Train Loss: 0.02112660253489459\n",
      "Val Loss: 0.021080543597539265\n",
      "Starting epoch 2443\n",
      "Train Loss: 0.02108824032324332\n",
      "Val Loss: 0.021178508246386493\n",
      "Starting epoch 2444\n",
      "Train Loss: 0.02107356819841597\n",
      "Val Loss: 0.021187332493287546\n",
      "Starting epoch 2445\n",
      "Train Loss: 0.021077960729599\n",
      "Val Loss: 0.021147642974500305\n",
      "Starting epoch 2446\n",
      "Train Loss: 0.021060714567149127\n",
      "Val Loss: 0.021542018210446393\n",
      "Starting epoch 2447\n",
      "Train Loss: 0.021119108906498662\n",
      "Val Loss: 0.021101483040385775\n",
      "Starting epoch 2448\n",
      "Train Loss: 0.021117984696670814\n",
      "Val Loss: 0.021085394753350153\n",
      "Starting epoch 2449\n",
      "Train Loss: 0.021213298042615254\n",
      "Val Loss: 0.02124791344006856\n",
      "Starting epoch 2450\n",
      "Train Loss: 0.021285039959130465\n",
      "Val Loss: 0.021104858429343613\n",
      "Starting epoch 2451\n",
      "Train Loss: 0.02151329097924409\n",
      "Val Loss: 0.02152826388676961\n",
      "Starting epoch 2452\n",
      "Train Loss: 0.021066556374231975\n",
      "Val Loss: 0.021146929374447575\n",
      "Starting epoch 2453\n",
      "Train Loss: 0.02123519723062162\n",
      "Val Loss: 0.021091441865320557\n",
      "Starting epoch 2454\n",
      "Train Loss: 0.02110283683847498\n",
      "Val Loss: 0.021064783687944764\n",
      "Starting epoch 2455\n",
      "Train Loss: 0.02106857686131089\n",
      "Val Loss: 0.02107324202855428\n",
      "Starting epoch 2456\n",
      "Train Loss: 0.02109779307135829\n",
      "Val Loss: 0.021074160933494568\n",
      "Starting epoch 2457\n",
      "Train Loss: 0.02109303132251457\n",
      "Val Loss: 0.021094760409107915\n",
      "Starting epoch 2458\n",
      "Train Loss: 0.021109870738453336\n",
      "Val Loss: 0.021059160983120953\n",
      "Starting epoch 2459\n",
      "Train Loss: 0.021148843345818697\n",
      "Val Loss: 0.02119179732269711\n",
      "Starting epoch 2460\n",
      "Train Loss: 0.02114048876144268\n",
      "Val Loss: 0.02151934912911168\n",
      "Starting epoch 2461\n",
      "Train Loss: 0.021095571142655832\n",
      "Val Loss: 0.021164289779133268\n",
      "Starting epoch 2462\n",
      "Train Loss: 0.02112573164480704\n",
      "Val Loss: 0.021133863263660006\n",
      "Starting epoch 2463\n",
      "Train Loss: 0.021661767253169307\n",
      "Val Loss: 0.02106231947739919\n",
      "Starting epoch 2464\n",
      "Train Loss: 0.021189575393994648\n",
      "Val Loss: 0.021070487521312856\n",
      "Starting epoch 2465\n",
      "Train Loss: 0.02107913350617444\n",
      "Val Loss: 0.021132850536593684\n",
      "Starting epoch 2466\n",
      "Train Loss: 0.0211288857239264\n",
      "Val Loss: 0.021268839085543598\n",
      "Starting epoch 2467\n",
      "Train Loss: 0.02121234933535258\n",
      "Val Loss: 0.021101626533049124\n",
      "Starting epoch 2468\n",
      "Train Loss: 0.021167015035947163\n",
      "Val Loss: 0.021077187524901494\n",
      "Starting epoch 2469\n",
      "Train Loss: 0.021120377160884714\n",
      "Val Loss: 0.02131108663700245\n",
      "Starting epoch 2470\n",
      "Train Loss: 0.021158261983482925\n",
      "Val Loss: 0.02110686622284077\n",
      "Starting epoch 2471\n",
      "Train Loss: 0.021124345284921152\n",
      "Val Loss: 0.02108584620334484\n",
      "Starting epoch 2472\n",
      "Train Loss: 0.021100771096017625\n",
      "Val Loss: 0.021105568166132325\n",
      "Starting epoch 2473\n",
      "Train Loss: 0.021123459493672406\n",
      "Val Loss: 0.021139381108460604\n",
      "Starting epoch 2474\n",
      "Train Loss: 0.021130879168157226\n",
      "Val Loss: 0.021102417398382117\n",
      "Starting epoch 2475\n",
      "Train Loss: 0.02167297237449222\n",
      "Val Loss: 0.02108460995886061\n",
      "Starting epoch 2476\n",
      "Train Loss: 0.02108899200404132\n",
      "Val Loss: 0.021054272298459655\n",
      "Starting epoch 2477\n",
      "Train Loss: 0.021102298740987426\n",
      "Val Loss: 0.021170017343980295\n",
      "Starting epoch 2478\n",
      "Train Loss: 0.0211314857006073\n",
      "Val Loss: 0.021086897563051293\n",
      "Starting epoch 2479\n",
      "Train Loss: 0.021164056327607896\n",
      "Val Loss: 0.021102753502351267\n",
      "Starting epoch 2480\n",
      "Train Loss: 0.02153837404869221\n",
      "Val Loss: 0.021056101829917344\n",
      "Starting epoch 2481\n",
      "Train Loss: 0.021082635279054993\n",
      "Val Loss: 0.02110609632951242\n",
      "Starting epoch 2482\n",
      "Train Loss: 0.0210804111427731\n",
      "Val Loss: 0.021093585424953036\n",
      "Starting epoch 2483\n",
      "Train Loss: 0.021204926901393466\n",
      "Val Loss: 0.02174952239901931\n",
      "Starting epoch 2484\n",
      "Train Loss: 0.021150603890419006\n",
      "Val Loss: 0.021222705090487445\n",
      "Starting epoch 2485\n",
      "Train Loss: 0.02152524502189071\n",
      "Val Loss: 0.02113741746655217\n",
      "Starting epoch 2486\n",
      "Train Loss: 0.02109009082670565\n",
      "Val Loss: 0.02109804915057288\n",
      "Starting epoch 2487\n",
      "Train Loss: 0.021533219350708857\n",
      "Val Loss: 0.02104686807703089\n",
      "Starting epoch 2488\n",
      "Train Loss: 0.02109392042513247\n",
      "Val Loss: 0.02112017020031258\n",
      "Starting epoch 2489\n",
      "Train Loss: 0.02116583342905398\n",
      "Val Loss: 0.021518918099226774\n",
      "Starting epoch 2490\n",
      "Train Loss: 0.021100339514237863\n",
      "Val Loss: 0.0211155640858191\n",
      "Starting epoch 2491\n",
      "Train Loss: 0.021061348694342154\n",
      "Val Loss: 0.02109585095334936\n",
      "Starting epoch 2492\n",
      "Train Loss: 0.02168277347529376\n",
      "Val Loss: 0.021051933919941937\n",
      "Starting epoch 2493\n",
      "Train Loss: 0.021067616012361314\n",
      "Val Loss: 0.021236519018809002\n",
      "Starting epoch 2494\n",
      "Train Loss: 0.0210734142197503\n",
      "Val Loss: 0.021168773924862896\n",
      "Starting epoch 2495\n",
      "Train Loss: 0.021092328760359023\n",
      "Val Loss: 0.02118779056602054\n",
      "Starting epoch 2496\n",
      "Train Loss: 0.021120954994802123\n",
      "Val Loss: 0.021069437265396118\n",
      "Starting epoch 2497\n",
      "Train Loss: 0.021148303592646564\n",
      "Val Loss: 0.021116837307258888\n",
      "Starting epoch 2498\n",
      "Train Loss: 0.021091080926082754\n",
      "Val Loss: 0.021093805079106933\n",
      "Starting epoch 2499\n",
      "Train Loss: 0.02105758532329842\n",
      "Val Loss: 0.021106988191604614\n",
      "Starting epoch 2500\n",
      "Train Loss: 0.021091232697168987\n",
      "Val Loss: 0.021085859448821458\n",
      "Starting epoch 2501\n",
      "Train Loss: 0.021180146270328097\n",
      "Val Loss: 0.021108138340490835\n",
      "Starting epoch 2502\n",
      "Train Loss: 0.0210855261043266\n",
      "Val Loss: 0.021080215771993\n",
      "Starting epoch 2503\n",
      "Train Loss: 0.021565212695686904\n",
      "Val Loss: 0.02111303640736474\n",
      "Starting epoch 2504\n",
      "Train Loss: 0.021069361103905573\n",
      "Val Loss: 0.021053671284958168\n",
      "Starting epoch 2505\n",
      "Train Loss: 0.021093085960105614\n",
      "Val Loss: 0.021055052677790325\n",
      "Starting epoch 2506\n",
      "Train Loss: 0.021061558966283447\n",
      "Val Loss: 0.021059751510620117\n",
      "Starting epoch 2507\n",
      "Train Loss: 0.021057480463275203\n",
      "Val Loss: 0.02109814242080406\n",
      "Starting epoch 2508\n",
      "Train Loss: 0.021053646449689514\n",
      "Val Loss: 0.02109314501285553\n",
      "Starting epoch 2509\n",
      "Train Loss: 0.02116491010895482\n",
      "Val Loss: 0.02109086568708773\n",
      "Starting epoch 2510\n",
      "Train Loss: 0.021086526137811167\n",
      "Val Loss: 0.021099778789061087\n",
      "Starting epoch 2511\n",
      "Train Loss: 0.021148734070636607\n",
      "Val Loss: 0.021054509613249037\n",
      "Starting epoch 2512\n",
      "Train Loss: 0.021054527273884526\n",
      "Val Loss: 0.021079888498341595\n",
      "Starting epoch 2513\n",
      "Train Loss: 0.02114797521520544\n",
      "Val Loss: 0.021123875622396118\n",
      "Starting epoch 2514\n",
      "Train Loss: 0.021129362561084605\n",
      "Val Loss: 0.021070685651567247\n",
      "Starting epoch 2515\n",
      "Train Loss: 0.021098646300810354\n",
      "Val Loss: 0.02109726821934735\n",
      "Starting epoch 2516\n",
      "Train Loss: 0.021547924589227746\n",
      "Val Loss: 0.021080747798637108\n",
      "Starting epoch 2517\n",
      "Train Loss: 0.02108830213546753\n",
      "Val Loss: 0.021073774607093247\n",
      "Starting epoch 2518\n",
      "Train Loss: 0.02105453113714854\n",
      "Val Loss: 0.02149149278799693\n",
      "Starting epoch 2519\n",
      "Train Loss: 0.021102372143003676\n",
      "Val Loss: 0.021073258585400052\n",
      "Starting epoch 2520\n",
      "Train Loss: 0.021174202914591187\n",
      "Val Loss: 0.021062391223730863\n",
      "Starting epoch 2521\n",
      "Train Loss: 0.021153862829561585\n",
      "Val Loss: 0.021120815365402786\n",
      "Starting epoch 2522\n",
      "Train Loss: 0.021521514764538518\n",
      "Val Loss: 0.02110304324715226\n",
      "Starting epoch 2523\n",
      "Train Loss: 0.021113091044955783\n",
      "Val Loss: 0.021093085408210754\n",
      "Starting epoch 2524\n",
      "Train Loss: 0.021204646538805078\n",
      "Val Loss: 0.021059668726391263\n",
      "Starting epoch 2525\n",
      "Train Loss: 0.02109629522871088\n",
      "Val Loss: 0.02112634590378514\n",
      "Starting epoch 2526\n",
      "Train Loss: 0.021092920943542762\n",
      "Val Loss: 0.021203533918769273\n",
      "Starting epoch 2527\n",
      "Train Loss: 0.021072122785780165\n",
      "Val Loss: 0.02106632623407576\n",
      "Starting epoch 2528\n",
      "Train Loss: 0.021183884254208318\n",
      "Val Loss: 0.021058505883923283\n",
      "Starting epoch 2529\n",
      "Train Loss: 0.021077876289685566\n",
      "Val Loss: 0.021107945729185035\n",
      "Starting epoch 2530\n",
      "Train Loss: 0.02109671687638318\n",
      "Val Loss: 0.021063434856909292\n",
      "Starting epoch 2531\n",
      "Train Loss: 0.021035508425147446\n",
      "Val Loss: 0.021036876020608126\n",
      "Starting epoch 2532\n",
      "Train Loss: 0.021074940760930378\n",
      "Val Loss: 0.021048184898164537\n",
      "Starting epoch 2533\n",
      "Train Loss: 0.02148978798477738\n",
      "Val Loss: 0.021155773489563552\n",
      "Starting epoch 2534\n",
      "Train Loss: 0.021050231876196684\n",
      "Val Loss: 0.02106416998086152\n",
      "Starting epoch 2535\n",
      "Train Loss: 0.021038056523711594\n",
      "Val Loss: 0.021478847772986802\n",
      "Starting epoch 2536\n",
      "Train Loss: 0.021079277550732647\n",
      "Val Loss: 0.021126598119735718\n",
      "Starting epoch 2537\n",
      "Train Loss: 0.02120738504109559\n",
      "Val Loss: 0.021040812134742737\n",
      "Starting epoch 2538\n",
      "Train Loss: 0.021516801582442388\n",
      "Val Loss: 0.021160911078806275\n",
      "Starting epoch 2539\n",
      "Train Loss: 0.021065374767338788\n",
      "Val Loss: 0.021081142403461314\n",
      "Starting epoch 2540\n",
      "Train Loss: 0.021034012238184612\n",
      "Val Loss: 0.021072734285283973\n",
      "Starting epoch 2541\n",
      "Train Loss: 0.021492163340250652\n",
      "Val Loss: 0.021497756242752075\n",
      "Starting epoch 2542\n",
      "Train Loss: 0.021034539849669846\n",
      "Val Loss: 0.0211118514891024\n",
      "Starting epoch 2543\n",
      "Train Loss: 0.02106353971693251\n",
      "Val Loss: 0.021206431366779185\n",
      "Starting epoch 2544\n",
      "Train Loss: 0.02149834566646152\n",
      "Val Loss: 0.02118706703186035\n",
      "Starting epoch 2545\n",
      "Train Loss: 0.021088600710586266\n",
      "Val Loss: 0.021067090608455515\n",
      "Starting epoch 2546\n",
      "Train Loss: 0.021521911025047302\n",
      "Val Loss: 0.021059235488926922\n",
      "Starting epoch 2547\n",
      "Train Loss: 0.02106683121787177\n",
      "Val Loss: 0.02107154329617818\n",
      "Starting epoch 2548\n",
      "Train Loss: 0.02109280890888638\n",
      "Val Loss: 0.02117249921516136\n",
      "Starting epoch 2549\n",
      "Train Loss: 0.021035270006568345\n",
      "Val Loss: 0.021049039231406316\n",
      "Starting epoch 2550\n",
      "Train Loss: 0.021044726724977845\n",
      "Val Loss: 0.021155540038038184\n",
      "Starting epoch 2551\n",
      "Train Loss: 0.021127832708535372\n",
      "Val Loss: 0.021083216976236413\n",
      "Starting epoch 2552\n",
      "Train Loss: 0.021051143606503803\n",
      "Val Loss: 0.02119007596263179\n",
      "Starting epoch 2553\n",
      "Train Loss: 0.021152334632696928\n",
      "Val Loss: 0.02147558828194936\n",
      "Starting epoch 2554\n",
      "Train Loss: 0.02105060385333167\n",
      "Val Loss: 0.021109730005264282\n",
      "Starting epoch 2555\n",
      "Train Loss: 0.02106196516089969\n",
      "Val Loss: 0.021078083250257704\n",
      "Starting epoch 2556\n",
      "Train Loss: 0.02104763741846438\n",
      "Val Loss: 0.021056772382171067\n",
      "Starting epoch 2557\n",
      "Train Loss: 0.02106307722904064\n",
      "Val Loss: 0.021058475529706036\n",
      "Starting epoch 2558\n",
      "Train Loss: 0.02108456470348217\n",
      "Val Loss: 0.02106089503676803\n",
      "Starting epoch 2559\n",
      "Train Loss: 0.021158745995274297\n",
      "Val Loss: 0.021599547730551824\n",
      "Starting epoch 2560\n",
      "Train Loss: 0.021156350219691242\n",
      "Val Loss: 0.021059861337697064\n",
      "Starting epoch 2561\n",
      "Train Loss: 0.021191286819952505\n",
      "Val Loss: 0.021098674447448167\n",
      "Starting epoch 2562\n",
      "Train Loss: 0.021069894786234254\n",
      "Val Loss: 0.021160126284316735\n",
      "Starting epoch 2563\n",
      "Train Loss: 0.021044566123573867\n",
      "Val Loss: 0.021076800646605314\n",
      "Starting epoch 2564\n",
      "Train Loss: 0.02106906528826113\n",
      "Val Loss: 0.021093659930759005\n",
      "Starting epoch 2565\n",
      "Train Loss: 0.02110438766302886\n",
      "Val Loss: 0.021094834914913884\n",
      "Starting epoch 2566\n",
      "Train Loss: 0.021098035353201407\n",
      "Val Loss: 0.021093435861446238\n",
      "Starting epoch 2567\n",
      "Train Loss: 0.021049947650344285\n",
      "Val Loss: 0.0216078692012363\n",
      "Starting epoch 2568\n",
      "Train Loss: 0.021063594354523554\n",
      "Val Loss: 0.021027143906663964\n",
      "Starting epoch 2569\n",
      "Train Loss: 0.02148120050077085\n",
      "Val Loss: 0.02105045649740431\n",
      "Starting epoch 2570\n",
      "Train Loss: 0.02104237013392978\n",
      "Val Loss: 0.021059791798944825\n",
      "Starting epoch 2571\n",
      "Train Loss: 0.02114792444087841\n",
      "Val Loss: 0.021060003174675837\n",
      "Starting epoch 2572\n",
      "Train Loss: 0.021034410154377972\n",
      "Val Loss: 0.021089568182274147\n",
      "Starting epoch 2573\n",
      "Train Loss: 0.021059284055674518\n",
      "Val Loss: 0.021057173057838722\n",
      "Starting epoch 2574\n",
      "Train Loss: 0.02118411770573369\n",
      "Val Loss: 0.021163749474066275\n",
      "Starting epoch 2575\n",
      "Train Loss: 0.02103717569951658\n",
      "Val Loss: 0.021103659713709796\n",
      "Starting epoch 2576\n",
      "Train Loss: 0.021099852191077337\n",
      "Val Loss: 0.021122395440384193\n",
      "Starting epoch 2577\n",
      "Train Loss: 0.02105265690220727\n",
      "Val Loss: 0.021138342994230765\n",
      "Starting epoch 2578\n",
      "Train Loss: 0.021490690884766756\n",
      "Val Loss: 0.02119456562731001\n",
      "Starting epoch 2579\n",
      "Train Loss: 0.02104420518433606\n",
      "Val Loss: 0.02164424459139506\n",
      "Starting epoch 2580\n",
      "Train Loss: 0.02104755518613038\n",
      "Val Loss: 0.021075965077788743\n",
      "Starting epoch 2581\n",
      "Train Loss: 0.021164096615932607\n",
      "Val Loss: 0.021080772082010906\n",
      "Starting epoch 2582\n",
      "Train Loss: 0.021512198779318068\n",
      "Val Loss: 0.02114695089834708\n",
      "Starting epoch 2583\n",
      "Train Loss: 0.02107082748854602\n",
      "Val Loss: 0.021045458537560922\n",
      "Starting epoch 2584\n",
      "Train Loss: 0.021044544599674368\n",
      "Val Loss: 0.021179241162759287\n",
      "Starting epoch 2585\n",
      "Train Loss: 0.021054739201510395\n",
      "Val Loss: 0.021071748049170884\n",
      "Starting epoch 2586\n",
      "Train Loss: 0.021041673642617685\n",
      "Val Loss: 0.02108519000035745\n",
      "Starting epoch 2587\n",
      "Train Loss: 0.021045409970813327\n",
      "Val Loss: 0.02105556594000922\n",
      "Starting epoch 2588\n",
      "Train Loss: 0.021061880169091402\n",
      "Val Loss: 0.0210398413516857\n",
      "Starting epoch 2589\n",
      "Train Loss: 0.02108361765190407\n",
      "Val Loss: 0.021086396442519292\n",
      "Starting epoch 2590\n",
      "Train Loss: 0.021028322754082857\n",
      "Val Loss: 0.021047150095303852\n",
      "Starting epoch 2591\n",
      "Train Loss: 0.021130375840045786\n",
      "Val Loss: 0.02107472938519937\n",
      "Starting epoch 2592\n",
      "Train Loss: 0.021036933417673463\n",
      "Val Loss: 0.02120926203551116\n",
      "Starting epoch 2593\n",
      "Train Loss: 0.02103088354622876\n",
      "Val Loss: 0.021035672889815435\n",
      "Starting epoch 2594\n",
      "Train Loss: 0.021040217192084702\n",
      "Val Loss: 0.021076183076258057\n",
      "Starting epoch 2595\n",
      "Train Loss: 0.021050902980345267\n",
      "Val Loss: 0.021175024134141428\n",
      "Starting epoch 2596\n",
      "Train Loss: 0.021085996318746497\n",
      "Val Loss: 0.02103676950490033\n",
      "Starting epoch 2597\n",
      "Train Loss: 0.02108964048050068\n",
      "Val Loss: 0.021030119171849004\n",
      "Starting epoch 2598\n",
      "Train Loss: 0.021045019229253132\n",
      "Val Loss: 0.021262038637090613\n",
      "Starting epoch 2599\n",
      "Train Loss: 0.021069836837274057\n",
      "Val Loss: 0.021038191186057195\n",
      "Starting epoch 2600\n",
      "Train Loss: 0.021055045503157156\n",
      "Val Loss: 0.02102449701892005\n",
      "Starting epoch 2601\n",
      "Train Loss: 0.021038036103601807\n",
      "Val Loss: 0.021018802567764564\n",
      "Starting epoch 2602\n",
      "Train Loss: 0.021088867275803176\n",
      "Val Loss: 0.021100943287213642\n",
      "Starting epoch 2603\n",
      "Train Loss: 0.021094989445474412\n",
      "Val Loss: 0.021192290164806223\n",
      "Starting epoch 2604\n",
      "Train Loss: 0.021065307436165987\n",
      "Val Loss: 0.02101820210615794\n",
      "Starting epoch 2605\n",
      "Train Loss: 0.021034249001079135\n",
      "Val Loss: 0.021071051005963928\n",
      "Starting epoch 2606\n",
      "Train Loss: 0.021043019162284002\n",
      "Val Loss: 0.021067660715844896\n",
      "Starting epoch 2607\n",
      "Train Loss: 0.021083462569448683\n",
      "Val Loss: 0.021538143908535992\n",
      "Starting epoch 2608\n",
      "Train Loss: 0.021465127114896423\n",
      "Val Loss: 0.021052396407833806\n",
      "Starting epoch 2609\n",
      "Train Loss: 0.021105591345716407\n",
      "Val Loss: 0.021237562651987427\n",
      "Starting epoch 2610\n",
      "Train Loss: 0.02107745298632869\n",
      "Val Loss: 0.02103726676216832\n",
      "Starting epoch 2611\n",
      "Train Loss: 0.02103861062615006\n",
      "Val Loss: 0.02111149772449776\n",
      "Starting epoch 2612\n",
      "Train Loss: 0.02101328858622798\n",
      "Val Loss: 0.021079460227930988\n",
      "Starting epoch 2613\n",
      "Train Loss: 0.021061092615127563\n",
      "Val Loss: 0.021500691219612404\n",
      "Starting epoch 2614\n",
      "Train Loss: 0.021179407835006714\n",
      "Val Loss: 0.021494206455018785\n",
      "Starting epoch 2615\n",
      "Train Loss: 0.02116755975617303\n",
      "Val Loss: 0.0210118779429683\n",
      "Starting epoch 2616\n",
      "Train Loss: 0.02102001232129556\n",
      "Val Loss: 0.0215726919748165\n",
      "Starting epoch 2617\n",
      "Train Loss: 0.021057632234361436\n",
      "Val Loss: 0.021069371589907893\n",
      "Starting epoch 2618\n",
      "Train Loss: 0.021021658071765193\n",
      "Val Loss: 0.021012917712882714\n",
      "Starting epoch 2619\n",
      "Train Loss: 0.021175933656869112\n",
      "Val Loss: 0.02103950579961141\n",
      "Starting epoch 2620\n",
      "Train Loss: 0.021477672236937063\n",
      "Val Loss: 0.021052250155696162\n",
      "Starting epoch 2621\n",
      "Train Loss: 0.021498518961447256\n",
      "Val Loss: 0.021512571308347914\n",
      "Starting epoch 2622\n",
      "Train Loss: 0.02111771316440017\n",
      "Val Loss: 0.021185949996665673\n",
      "Starting epoch 2623\n",
      "Train Loss: 0.021017384749871713\n",
      "Val Loss: 0.021028050118022494\n",
      "Starting epoch 2624\n",
      "Train Loss: 0.021175816103264137\n",
      "Val Loss: 0.021140945178491098\n",
      "Starting epoch 2625\n",
      "Train Loss: 0.02110355485368658\n",
      "Val Loss: 0.021020027222456755\n",
      "Starting epoch 2626\n",
      "Train Loss: 0.021556764289184852\n",
      "Val Loss: 0.021034079017462553\n",
      "Starting epoch 2627\n",
      "Train Loss: 0.02103502165388178\n",
      "Val Loss: 0.021477044732482346\n",
      "Starting epoch 2628\n",
      "Train Loss: 0.021046235605522438\n",
      "Val Loss: 0.02104049148382964\n",
      "Starting epoch 2629\n",
      "Train Loss: 0.021053224802017212\n",
      "Val Loss: 0.021102152488849783\n",
      "Starting epoch 2630\n",
      "Train Loss: 0.021029582730046025\n",
      "Val Loss: 0.021052727544749225\n",
      "Starting epoch 2631\n",
      "Train Loss: 0.021499517891142104\n",
      "Val Loss: 0.021097177156695613\n",
      "Starting epoch 2632\n",
      "Train Loss: 0.02101043528980679\n",
      "Val Loss: 0.021093432550077087\n",
      "Starting epoch 2633\n",
      "Train Loss: 0.02150088272712849\n",
      "Val Loss: 0.021077545704665007\n",
      "Starting epoch 2634\n",
      "Train Loss: 0.021071534465860436\n",
      "Val Loss: 0.021015548043780856\n",
      "Starting epoch 2635\n",
      "Train Loss: 0.021484594654153893\n",
      "Val Loss: 0.021064281463623047\n",
      "Starting epoch 2636\n",
      "Train Loss: 0.02107806669341193\n",
      "Val Loss: 0.02118613322575887\n",
      "Starting epoch 2637\n",
      "Train Loss: 0.021034608836527222\n",
      "Val Loss: 0.021048104873409978\n",
      "Starting epoch 2638\n",
      "Train Loss: 0.021089930225301673\n",
      "Val Loss: 0.02111328641573588\n",
      "Starting epoch 2639\n",
      "Train Loss: 0.02145534588230981\n",
      "Val Loss: 0.021468388261618437\n",
      "Starting epoch 2640\n",
      "Train Loss: 0.021073313774885954\n",
      "Val Loss: 0.02148778681401853\n",
      "Starting epoch 2641\n",
      "Train Loss: 0.021092293439088045\n",
      "Val Loss: 0.021040567645320186\n",
      "Starting epoch 2642\n",
      "Train Loss: 0.02104866118342788\n",
      "Val Loss: 0.021029714632917335\n",
      "Starting epoch 2643\n",
      "Train Loss: 0.021044515349246836\n",
      "Val Loss: 0.021020772832411307\n",
      "Starting epoch 2644\n",
      "Train Loss: 0.021012735587579233\n",
      "Val Loss: 0.02147460866857458\n",
      "Starting epoch 2645\n",
      "Train Loss: 0.021009498172336154\n",
      "Val Loss: 0.021018646933414317\n",
      "Starting epoch 2646\n",
      "Train Loss: 0.021490769253836736\n",
      "Val Loss: 0.02104960161226767\n",
      "Starting epoch 2647\n",
      "Train Loss: 0.021055478188726637\n",
      "Val Loss: 0.02108125499001256\n",
      "Starting epoch 2648\n",
      "Train Loss: 0.021592453122138977\n",
      "Val Loss: 0.02101387690614771\n",
      "Starting epoch 2649\n",
      "Train Loss: 0.021031799691694754\n",
      "Val Loss: 0.021047328357343322\n",
      "Starting epoch 2650\n",
      "Train Loss: 0.02101449723596926\n",
      "Val Loss: 0.02112373764868136\n",
      "Starting epoch 2651\n",
      "Train Loss: 0.021153027260745014\n",
      "Val Loss: 0.0210505293475257\n",
      "Starting epoch 2652\n",
      "Train Loss: 0.0211038186594292\n",
      "Val Loss: 0.021012011501524184\n",
      "Starting epoch 2653\n",
      "Train Loss: 0.021030251626615173\n",
      "Val Loss: 0.02144928276538849\n",
      "Starting epoch 2654\n",
      "Train Loss: 0.021038271762706614\n",
      "Val Loss: 0.021070611697656137\n",
      "Starting epoch 2655\n",
      "Train Loss: 0.021050061340685242\n",
      "Val Loss: 0.021023883863731666\n",
      "Starting epoch 2656\n",
      "Train Loss: 0.02101042370001475\n",
      "Val Loss: 0.021092394435847248\n",
      "Starting epoch 2657\n",
      "Train Loss: 0.021494287583563063\n",
      "Val Loss: 0.021463433901468914\n",
      "Starting epoch 2658\n",
      "Train Loss: 0.021023680214528686\n",
      "Val Loss: 0.021016330078796105\n",
      "Starting epoch 2659\n",
      "Train Loss: 0.021028111930246705\n",
      "Val Loss: 0.021024279020450735\n",
      "Starting epoch 2660\n",
      "Train Loss: 0.021171329749955073\n",
      "Val Loss: 0.021258561147583857\n",
      "Starting epoch 2661\n",
      "Train Loss: 0.02106715738773346\n",
      "Val Loss: 0.02106881969504886\n",
      "Starting epoch 2662\n",
      "Train Loss: 0.021488009227646723\n",
      "Val Loss: 0.021186877180028846\n",
      "Starting epoch 2663\n",
      "Train Loss: 0.021020934537605004\n",
      "Val Loss: 0.02110111713409424\n",
      "Starting epoch 2664\n",
      "Train Loss: 0.021025683592866967\n",
      "Val Loss: 0.021019901390428895\n",
      "Starting epoch 2665\n",
      "Train Loss: 0.021038349027986878\n",
      "Val Loss: 0.021013052375228318\n",
      "Starting epoch 2666\n",
      "Train Loss: 0.021160592083577758\n",
      "Val Loss: 0.02102982942704801\n",
      "Starting epoch 2667\n",
      "Train Loss: 0.02148717200314557\n",
      "Val Loss: 0.021061267013903016\n",
      "Starting epoch 2668\n",
      "Train Loss: 0.02105589873260922\n",
      "Val Loss: 0.021027778033856994\n",
      "Starting epoch 2669\n",
      "Train Loss: 0.021009993222024705\n",
      "Val Loss: 0.021026587044751202\n",
      "Starting epoch 2670\n",
      "Train Loss: 0.021032412846883137\n",
      "Val Loss: 0.021134176188045077\n",
      "Starting epoch 2671\n",
      "Train Loss: 0.021049268819667673\n",
      "Val Loss: 0.02149251710485529\n",
      "Starting epoch 2672\n",
      "Train Loss: 0.021023658138734323\n",
      "Val Loss: 0.021015178826120164\n",
      "Starting epoch 2673\n",
      "Train Loss: 0.021002389214656973\n",
      "Val Loss: 0.02102644631156215\n",
      "Starting epoch 2674\n",
      "Train Loss: 0.02146509400120488\n",
      "Val Loss: 0.02106424448666749\n",
      "Starting epoch 2675\n",
      "Train Loss: 0.02101052690435339\n",
      "Val Loss: 0.021567190686861675\n",
      "Starting epoch 2676\n",
      "Train Loss: 0.021034728597711633\n",
      "Val Loss: 0.02121341394053565\n",
      "Starting epoch 2677\n",
      "Train Loss: 0.02101567718717787\n",
      "Val Loss: 0.021197371460773325\n",
      "Starting epoch 2678\n",
      "Train Loss: 0.021463901908309373\n",
      "Val Loss: 0.02108504154064037\n",
      "Starting epoch 2679\n",
      "Train Loss: 0.0210287195664865\n",
      "Val Loss: 0.021106781782927336\n",
      "Starting epoch 2680\n",
      "Train Loss: 0.021467004109311988\n",
      "Val Loss: 0.02108286100405234\n",
      "Starting epoch 2681\n",
      "Train Loss: 0.021006773467417115\n",
      "Val Loss: 0.021123761932055157\n",
      "Starting epoch 2682\n",
      "Train Loss: 0.021111843762574373\n",
      "Val Loss: 0.02107764173437048\n",
      "Starting epoch 2683\n",
      "Train Loss: 0.021017753415637545\n",
      "Val Loss: 0.021124066026122483\n",
      "Starting epoch 2684\n",
      "Train Loss: 0.02117279337512122\n",
      "Val Loss: 0.021008465577054908\n",
      "Starting epoch 2685\n",
      "Train Loss: 0.02100845233157829\n",
      "Val Loss: 0.021004618869887456\n",
      "Starting epoch 2686\n",
      "Train Loss: 0.021027622951401606\n",
      "Val Loss: 0.021018716472166556\n",
      "Starting epoch 2687\n",
      "Train Loss: 0.021036295427216425\n",
      "Val Loss: 0.021027795694492483\n",
      "Starting epoch 2688\n",
      "Train Loss: 0.02122723669917495\n",
      "Val Loss: 0.02145714009249652\n",
      "Starting epoch 2689\n",
      "Train Loss: 0.021028635678467928\n",
      "Val Loss: 0.02101884561556357\n",
      "Starting epoch 2690\n",
      "Train Loss: 0.021148177208723844\n",
      "Val Loss: 0.021032718596635042\n",
      "Starting epoch 2691\n",
      "Train Loss: 0.021099239035888954\n",
      "Val Loss: 0.021015263817928457\n",
      "Starting epoch 2692\n",
      "Train Loss: 0.021002302015269245\n",
      "Val Loss: 0.021041331467805086\n",
      "Starting epoch 2693\n",
      "Train Loss: 0.020995606426839477\n",
      "Val Loss: 0.021453753665641503\n",
      "Starting epoch 2694\n",
      "Train Loss: 0.021126149429215327\n",
      "Val Loss: 0.02112306268126876\n",
      "Starting epoch 2695\n",
      "Train Loss: 0.0210090732132947\n",
      "Val Loss: 0.02100895952295374\n",
      "Starting epoch 2696\n",
      "Train Loss: 0.02149704650596336\n",
      "Val Loss: 0.021040745907359652\n",
      "Starting epoch 2697\n",
      "Train Loss: 0.02103801237212287\n",
      "Val Loss: 0.021037538294438964\n",
      "Starting epoch 2698\n",
      "Train Loss: 0.02109806129225978\n",
      "Val Loss: 0.021074995950416283\n",
      "Starting epoch 2699\n",
      "Train Loss: 0.021482502420743305\n",
      "Val Loss: 0.021020915773179796\n",
      "Starting epoch 2700\n",
      "Train Loss: 0.02100274187547189\n",
      "Val Loss: 0.021181738486996404\n",
      "Starting epoch 2701\n",
      "Train Loss: 0.021139327574659278\n",
      "Val Loss: 0.021111473441123962\n",
      "Starting epoch 2702\n",
      "Train Loss: 0.021047970762959233\n",
      "Val Loss: 0.021013593232190167\n",
      "Starting epoch 2703\n",
      "Train Loss: 0.021033170598524588\n",
      "Val Loss: 0.02146453493171268\n",
      "Starting epoch 2704\n",
      "Train Loss: 0.02100721498330434\n",
      "Val Loss: 0.021047120844876324\n",
      "Starting epoch 2705\n",
      "Train Loss: 0.021066817972395156\n",
      "Val Loss: 0.02115394064673671\n",
      "Starting epoch 2706\n",
      "Train Loss: 0.021039398180113897\n",
      "Val Loss: 0.02149172568762744\n",
      "Starting epoch 2707\n",
      "Train Loss: 0.021051964826054044\n",
      "Val Loss: 0.02109946255330686\n",
      "Starting epoch 2708\n",
      "Train Loss: 0.02102972291134022\n",
      "Val Loss: 0.02099749997810081\n",
      "Starting epoch 2709\n",
      "Train Loss: 0.021065105442647582\n",
      "Val Loss: 0.02103449680187084\n",
      "Starting epoch 2710\n",
      "Train Loss: 0.02100644619376571\n",
      "Val Loss: 0.02105737339567255\n",
      "Starting epoch 2711\n",
      "Train Loss: 0.021008471647898357\n",
      "Val Loss: 0.020991664241861413\n",
      "Starting epoch 2712\n",
      "Train Loss: 0.02104492982228597\n",
      "Val Loss: 0.02100522705802211\n",
      "Starting epoch 2713\n",
      "Train Loss: 0.021003538259753474\n",
      "Val Loss: 0.02148002220524682\n",
      "Starting epoch 2714\n",
      "Train Loss: 0.021014608718730784\n",
      "Val Loss: 0.02104000636824855\n",
      "Starting epoch 2715\n",
      "Train Loss: 0.021133556962013245\n",
      "Val Loss: 0.021058249804708693\n",
      "Starting epoch 2716\n",
      "Train Loss: 0.020996119137163514\n",
      "Val Loss: 0.02102170443093335\n",
      "Starting epoch 2717\n",
      "Train Loss: 0.02103522695876934\n",
      "Val Loss: 0.021003709347159776\n",
      "Starting epoch 2718\n",
      "Train Loss: 0.02103710726455406\n",
      "Val Loss: 0.020997104821381746\n",
      "Starting epoch 2719\n",
      "Train Loss: 0.02102585412837841\n",
      "Val Loss: 0.021015385786692303\n",
      "Starting epoch 2720\n",
      "Train Loss: 0.02107434361069291\n",
      "Val Loss: 0.021003481966477854\n",
      "Starting epoch 2721\n",
      "Train Loss: 0.021040179663234286\n",
      "Val Loss: 0.021002957666361774\n",
      "Starting epoch 2722\n",
      "Train Loss: 0.02101064059469435\n",
      "Val Loss: 0.021030079987314012\n",
      "Starting epoch 2723\n",
      "Train Loss: 0.02103525952056602\n",
      "Val Loss: 0.021443398462401494\n",
      "Starting epoch 2724\n",
      "Train Loss: 0.021004779471291438\n",
      "Val Loss: 0.021480726974981802\n",
      "Starting epoch 2725\n",
      "Train Loss: 0.021069986400780855\n",
      "Val Loss: 0.021123108488542063\n",
      "Starting epoch 2726\n",
      "Train Loss: 0.021001733563564443\n",
      "Val Loss: 0.02111998255606051\n",
      "Starting epoch 2727\n",
      "Train Loss: 0.02100293117540854\n",
      "Val Loss: 0.020994521953441477\n",
      "Starting epoch 2728\n",
      "Train Loss: 0.021073446781546983\n",
      "Val Loss: 0.02098968845826608\n",
      "Starting epoch 2729\n",
      "Train Loss: 0.02147525217798021\n",
      "Val Loss: 0.021063473489549425\n",
      "Starting epoch 2730\n",
      "Train Loss: 0.020989750270490295\n",
      "Val Loss: 0.020994951327641804\n",
      "Starting epoch 2731\n",
      "Train Loss: 0.0210315916273329\n",
      "Val Loss: 0.021484736491132667\n",
      "Starting epoch 2732\n",
      "Train Loss: 0.021110305631602252\n",
      "Val Loss: 0.021008957867269164\n",
      "Starting epoch 2733\n",
      "Train Loss: 0.021132938287876272\n",
      "Val Loss: 0.021460161164954857\n",
      "Starting epoch 2734\n",
      "Train Loss: 0.021151297622256808\n",
      "Val Loss: 0.021107918686336942\n",
      "Starting epoch 2735\n",
      "Train Loss: 0.021018154091305204\n",
      "Val Loss: 0.021501686286043237\n",
      "Starting epoch 2736\n",
      "Train Loss: 0.02103729049364726\n",
      "Val Loss: 0.021466902560657926\n",
      "Starting epoch 2737\n",
      "Train Loss: 0.02101074876608672\n",
      "Val Loss: 0.021128427651193406\n",
      "Starting epoch 2738\n",
      "Train Loss: 0.02145216420844749\n",
      "Val Loss: 0.02147181056163929\n",
      "Starting epoch 2739\n",
      "Train Loss: 0.021005239199709008\n",
      "Val Loss: 0.021440244383282132\n",
      "Starting epoch 2740\n",
      "Train Loss: 0.021109358028129296\n",
      "Val Loss: 0.021075746527424565\n",
      "Starting epoch 2741\n",
      "Train Loss: 0.021026808354589675\n",
      "Val Loss: 0.021102607250213623\n",
      "Starting epoch 2742\n",
      "Train Loss: 0.021006312083314965\n",
      "Val Loss: 0.021021659175554912\n",
      "Starting epoch 2743\n",
      "Train Loss: 0.021113641836025095\n",
      "Val Loss: 0.021010348642313922\n",
      "Starting epoch 2744\n",
      "Train Loss: 0.021002724214836403\n",
      "Val Loss: 0.02105045042656086\n",
      "Starting epoch 2745\n",
      "Train Loss: 0.021131538130618906\n",
      "Val Loss: 0.02101414623083892\n",
      "Starting epoch 2746\n",
      "Train Loss: 0.021041637217556988\n",
      "Val Loss: 0.021441752160037006\n",
      "Starting epoch 2747\n",
      "Train Loss: 0.021018421208416974\n",
      "Val Loss: 0.021014790292139405\n",
      "Starting epoch 2748\n",
      "Train Loss: 0.021145072800141794\n",
      "Val Loss: 0.020989154775937397\n",
      "Starting epoch 2749\n",
      "Train Loss: 0.02100831601354811\n",
      "Val Loss: 0.021016028744203073\n",
      "Starting epoch 2750\n",
      "Train Loss: 0.02099829801806697\n",
      "Val Loss: 0.020994441928686918\n",
      "Starting epoch 2751\n",
      "Train Loss: 0.021479416224691603\n",
      "Val Loss: 0.021014495580284683\n",
      "Starting epoch 2752\n",
      "Train Loss: 0.021570711776062294\n",
      "Val Loss: 0.02106862101289961\n",
      "Starting epoch 2753\n",
      "Train Loss: 0.02160090208053589\n",
      "Val Loss: 0.021096070055608398\n",
      "Starting epoch 2754\n",
      "Train Loss: 0.021021156951233192\n",
      "Val Loss: 0.02101587531743226\n",
      "Starting epoch 2755\n",
      "Train Loss: 0.0210531872731668\n",
      "Val Loss: 0.021507490564275672\n",
      "Starting epoch 2756\n",
      "Train Loss: 0.021039760775036283\n",
      "Val Loss: 0.021004845146779662\n",
      "Starting epoch 2757\n",
      "Train Loss: 0.021013429871311894\n",
      "Val Loss: 0.02104470740865778\n",
      "Starting epoch 2758\n",
      "Train Loss: 0.021053342907517043\n",
      "Val Loss: 0.021139248653694435\n",
      "Starting epoch 2759\n",
      "Train Loss: 0.021148465849735117\n",
      "Val Loss: 0.020988537757485\n",
      "Starting epoch 2760\n",
      "Train Loss: 0.020981288618511625\n",
      "Val Loss: 0.02099769976403978\n",
      "Starting epoch 2761\n",
      "Train Loss: 0.02143329989027094\n",
      "Val Loss: 0.02101606296168433\n",
      "Starting epoch 2762\n",
      "Train Loss: 0.021016596644013015\n",
      "Val Loss: 0.02098851457790092\n",
      "Starting epoch 2763\n",
      "Train Loss: 0.021488838173724985\n",
      "Val Loss: 0.0210255511381008\n",
      "Starting epoch 2764\n",
      "Train Loss: 0.021439239382743835\n",
      "Val Loss: 0.020985261709601792\n",
      "Starting epoch 2765\n",
      "Train Loss: 0.021032277080747817\n",
      "Val Loss: 0.020978863592501038\n",
      "Starting epoch 2766\n",
      "Train Loss: 0.021045463504614653\n",
      "Val Loss: 0.021065690451198153\n",
      "Starting epoch 2767\n",
      "Train Loss: 0.021065093300960683\n",
      "Val Loss: 0.021529548698001437\n",
      "Starting epoch 2768\n",
      "Train Loss: 0.021098298055154306\n",
      "Val Loss: 0.020987704948142723\n",
      "Starting epoch 2769\n",
      "Train Loss: 0.020991511366985464\n",
      "Val Loss: 0.021022134357028537\n",
      "Starting epoch 2770\n",
      "Train Loss: 0.021012929854569613\n",
      "Val Loss: 0.021018557526447153\n",
      "Starting epoch 2771\n",
      "Train Loss: 0.021099821284965233\n",
      "Val Loss: 0.02099764898971275\n",
      "Starting epoch 2772\n",
      "Train Loss: 0.021028783034395288\n",
      "Val Loss: 0.02099109689394633\n",
      "Starting epoch 2773\n",
      "Train Loss: 0.021023099069242126\n",
      "Val Loss: 0.02102270777578707\n",
      "Starting epoch 2774\n",
      "Train Loss: 0.021010956830448575\n",
      "Val Loss: 0.02100378606054518\n",
      "Starting epoch 2775\n",
      "Train Loss: 0.02102189814602887\n",
      "Val Loss: 0.021548027241671527\n",
      "Starting epoch 2776\n",
      "Train Loss: 0.02103546648113816\n",
      "Val Loss: 0.021006255790039344\n",
      "Starting epoch 2777\n",
      "Train Loss: 0.02098018593258328\n",
      "Val Loss: 0.020977685848871868\n",
      "Starting epoch 2778\n",
      "Train Loss: 0.021070161903346027\n",
      "Val Loss: 0.02109820423302827\n",
      "Starting epoch 2779\n",
      "Train Loss: 0.020986382608060485\n",
      "Val Loss: 0.021470948501869484\n",
      "Starting epoch 2780\n",
      "Train Loss: 0.0210178820071397\n",
      "Val Loss: 0.021023456697110778\n",
      "Starting epoch 2781\n",
      "Train Loss: 0.021005194496225427\n",
      "Val Loss: 0.021079718514725013\n",
      "Starting epoch 2782\n",
      "Train Loss: 0.02098310876775671\n",
      "Val Loss: 0.021014616997153672\n",
      "Starting epoch 2783\n",
      "Train Loss: 0.02106353474987878\n",
      "Val Loss: 0.020990181852270057\n",
      "Starting epoch 2784\n",
      "Train Loss: 0.02100734136722706\n",
      "Val Loss: 0.02100611616064001\n",
      "Starting epoch 2785\n",
      "Train Loss: 0.020994123485353258\n",
      "Val Loss: 0.02103426335034547\n",
      "Starting epoch 2786\n",
      "Train Loss: 0.02100450407575678\n",
      "Val Loss: 0.020987425689344055\n",
      "Starting epoch 2787\n",
      "Train Loss: 0.0211069506627542\n",
      "Val Loss: 0.020989192856682673\n",
      "Starting epoch 2788\n",
      "Train Loss: 0.02099985380967458\n",
      "Val Loss: 0.021001957632877207\n",
      "Starting epoch 2789\n",
      "Train Loss: 0.02106514628286715\n",
      "Val Loss: 0.021011832687589858\n",
      "Starting epoch 2790\n",
      "Train Loss: 0.021023008006590384\n",
      "Val Loss: 0.020992878410551283\n",
      "Starting epoch 2791\n",
      "Train Loss: 0.021113818442379986\n",
      "Val Loss: 0.02102249143300233\n",
      "Starting epoch 2792\n",
      "Train Loss: 0.021013892911098623\n",
      "Val Loss: 0.020987306480054504\n",
      "Starting epoch 2793\n",
      "Train Loss: 0.020980524244131864\n",
      "Val Loss: 0.021090128907450923\n",
      "Starting epoch 2794\n",
      "Train Loss: 0.021549378832181294\n",
      "Val Loss: 0.02097509194303442\n",
      "Starting epoch 2795\n",
      "Train Loss: 0.02147287847819152\n",
      "Val Loss: 0.02100592962017766\n",
      "Starting epoch 2796\n",
      "Train Loss: 0.020986563077679387\n",
      "Val Loss: 0.021445927796540438\n",
      "Starting epoch 2797\n",
      "Train Loss: 0.02107310019157551\n",
      "Val Loss: 0.021025996517252038\n",
      "Starting epoch 2798\n",
      "Train Loss: 0.020994440824897202\n",
      "Val Loss: 0.021002481932993287\n",
      "Starting epoch 2799\n",
      "Train Loss: 0.021040242027353356\n",
      "Val Loss: 0.021011300109050893\n",
      "Starting epoch 2800\n",
      "Train Loss: 0.020991796696627582\n",
      "Val Loss: 0.020976289002983657\n",
      "Starting epoch 2801\n",
      "Train Loss: 0.021046625243292913\n",
      "Val Loss: 0.020998684896363154\n",
      "Starting epoch 2802\n",
      "Train Loss: 0.02109141316678789\n",
      "Val Loss: 0.020970596759407607\n",
      "Starting epoch 2803\n",
      "Train Loss: 0.020979811747868855\n",
      "Val Loss: 0.02100611008979656\n",
      "Starting epoch 2804\n",
      "Train Loss: 0.021088471015294392\n",
      "Val Loss: 0.021030404501491122\n",
      "Starting epoch 2805\n",
      "Train Loss: 0.020981458602128206\n",
      "Val Loss: 0.020992499810677988\n",
      "Starting epoch 2806\n",
      "Train Loss: 0.020984250638220046\n",
      "Val Loss: 0.020991959505610995\n",
      "Starting epoch 2807\n",
      "Train Loss: 0.020996328305315087\n",
      "Val Loss: 0.020993453484994394\n",
      "Starting epoch 2808\n",
      "Train Loss: 0.021023771829075284\n",
      "Val Loss: 0.0210083551980831\n",
      "Starting epoch 2809\n",
      "Train Loss: 0.020978342051859254\n",
      "Val Loss: 0.021003789371914335\n",
      "Starting epoch 2810\n",
      "Train Loss: 0.0214294691880544\n",
      "Val Loss: 0.021063816768151743\n",
      "Starting epoch 2811\n",
      "Train Loss: 0.02142762475543552\n",
      "Val Loss: 0.02097374090441951\n",
      "Starting epoch 2812\n",
      "Train Loss: 0.021011710166931152\n",
      "Val Loss: 0.021436702322076867\n",
      "Starting epoch 2813\n",
      "Train Loss: 0.020995018658814608\n",
      "Val Loss: 0.020990890485269052\n",
      "Starting epoch 2814\n",
      "Train Loss: 0.021018251224800392\n",
      "Val Loss: 0.021421341984360305\n",
      "Starting epoch 2815\n",
      "Train Loss: 0.020996136797799006\n",
      "Val Loss: 0.02100560952115942\n",
      "Starting epoch 2816\n",
      "Train Loss: 0.02099692655934228\n",
      "Val Loss: 0.021171787822688068\n",
      "Starting epoch 2817\n",
      "Train Loss: 0.021041729935893306\n",
      "Val Loss: 0.021432437278606272\n",
      "Starting epoch 2818\n",
      "Train Loss: 0.020988153638663114\n",
      "Val Loss: 0.021109006471104093\n",
      "Starting epoch 2819\n",
      "Train Loss: 0.021098921696345013\n",
      "Val Loss: 0.021047970211064373\n",
      "Starting epoch 2820\n",
      "Train Loss: 0.020988183992880362\n",
      "Val Loss: 0.02097020270647826\n",
      "Starting epoch 2821\n",
      "Train Loss: 0.02100534626731166\n",
      "Val Loss: 0.0210660508385411\n",
      "Starting epoch 2822\n",
      "Train Loss: 0.021040990948677063\n",
      "Val Loss: 0.020968564682536654\n",
      "Starting epoch 2823\n",
      "Train Loss: 0.02105479770236545\n",
      "Val Loss: 0.020993942463839496\n",
      "Starting epoch 2824\n",
      "Train Loss: 0.020993943015734356\n",
      "Val Loss: 0.021208140585157607\n",
      "Starting epoch 2825\n",
      "Train Loss: 0.02101834339124185\n",
      "Val Loss: 0.02115656104352739\n",
      "Starting epoch 2826\n",
      "Train Loss: 0.021007702858359727\n",
      "Val Loss: 0.020979763181121262\n",
      "Starting epoch 2827\n",
      "Train Loss: 0.020999676099529973\n",
      "Val Loss: 0.02142801770457515\n",
      "Starting epoch 2828\n",
      "Train Loss: 0.021015561841152334\n",
      "Val Loss: 0.02101007048730497\n",
      "Starting epoch 2829\n",
      "Train Loss: 0.02097165694943181\n",
      "Val Loss: 0.020986250705189176\n",
      "Starting epoch 2830\n",
      "Train Loss: 0.021001623184592637\n",
      "Val Loss: 0.021010607481002808\n",
      "Starting epoch 2831\n",
      "Train Loss: 0.02100412326830405\n",
      "Val Loss: 0.020971948349917377\n",
      "Starting epoch 2832\n",
      "Train Loss: 0.02097319232092963\n",
      "Val Loss: 0.021138000267523306\n",
      "Starting epoch 2833\n",
      "Train Loss: 0.021033206471690425\n",
      "Val Loss: 0.020999915621898794\n",
      "Starting epoch 2834\n",
      "Train Loss: 0.020982975761095684\n",
      "Val Loss: 0.020978095906752127\n",
      "Starting epoch 2835\n",
      "Train Loss: 0.020981111460261874\n",
      "Val Loss: 0.020986306446569937\n",
      "Starting epoch 2836\n",
      "Train Loss: 0.021032482385635376\n",
      "Val Loss: 0.02106032548127351\n",
      "Starting epoch 2837\n",
      "Train Loss: 0.020974409800988657\n",
      "Val Loss: 0.020969698826471966\n",
      "Starting epoch 2838\n",
      "Train Loss: 0.020973698960410223\n",
      "Val Loss: 0.021020859479904175\n",
      "Starting epoch 2839\n",
      "Train Loss: 0.02111914974671823\n",
      "Val Loss: 0.02109012559608177\n",
      "Starting epoch 2840\n",
      "Train Loss: 0.02096849955894329\n",
      "Val Loss: 0.020977800091107685\n",
      "Starting epoch 2841\n",
      "Train Loss: 0.021074013577567205\n",
      "Val Loss: 0.020986683942653513\n",
      "Starting epoch 2842\n",
      "Train Loss: 0.020968836766702158\n",
      "Val Loss: 0.021074810513743648\n",
      "Starting epoch 2843\n",
      "Train Loss: 0.020998120859817223\n",
      "Val Loss: 0.02097244836665966\n",
      "Starting epoch 2844\n",
      "Train Loss: 0.021069714316615352\n",
      "Val Loss: 0.02099021882922561\n",
      "Starting epoch 2845\n",
      "Train Loss: 0.02100469227190371\n",
      "Val Loss: 0.020983442664146423\n",
      "Starting epoch 2846\n",
      "Train Loss: 0.021470474976080435\n",
      "Val Loss: 0.021023646548942284\n",
      "Starting epoch 2847\n",
      "Train Loss: 0.021449495796804077\n",
      "Val Loss: 0.02097041297841955\n",
      "Starting epoch 2848\n",
      "Train Loss: 0.020984779353494996\n",
      "Val Loss: 0.020989031151488976\n",
      "Starting epoch 2849\n",
      "Train Loss: 0.020966222440754925\n",
      "Val Loss: 0.02102366034631376\n",
      "Starting epoch 2850\n",
      "Train Loss: 0.020963118032172875\n",
      "Val Loss: 0.02097974772806521\n",
      "Starting epoch 2851\n",
      "Train Loss: 0.020988022287686665\n",
      "Val Loss: 0.02098958746150688\n",
      "Starting epoch 2852\n",
      "Train Loss: 0.021059262531775015\n",
      "Val Loss: 0.020977664324972365\n",
      "Starting epoch 2853\n",
      "Train Loss: 0.020994051187126724\n",
      "Val Loss: 0.021006131613696064\n",
      "Starting epoch 2854\n",
      "Train Loss: 0.02141817797113348\n",
      "Val Loss: 0.021016854378912184\n",
      "Starting epoch 2855\n",
      "Train Loss: 0.021604767552128545\n",
      "Val Loss: 0.020982261609148095\n",
      "Starting epoch 2856\n",
      "Train Loss: 0.021073072596832557\n",
      "Val Loss: 0.02102190476876718\n",
      "Starting epoch 2857\n",
      "Train Loss: 0.02101090771180612\n",
      "Val Loss: 0.020989462733268738\n",
      "Starting epoch 2858\n",
      "Train Loss: 0.020972697271241084\n",
      "Val Loss: 0.02098568390916895\n",
      "Starting epoch 2859\n",
      "Train Loss: 0.020969836248291865\n",
      "Val Loss: 0.020994861368779785\n",
      "Starting epoch 2860\n",
      "Train Loss: 0.02097901039653354\n",
      "Val Loss: 0.020994223378322744\n",
      "Starting epoch 2861\n",
      "Train Loss: 0.02097909704402641\n",
      "Val Loss: 0.021150673429171245\n",
      "Starting epoch 2862\n",
      "Train Loss: 0.021039848526318867\n",
      "Val Loss: 0.020967612663904827\n",
      "Starting epoch 2863\n",
      "Train Loss: 0.020963070569215\n",
      "Val Loss: 0.021003184495148836\n",
      "Starting epoch 2864\n",
      "Train Loss: 0.020982674426502652\n",
      "Val Loss: 0.02098310987154643\n",
      "Starting epoch 2865\n",
      "Train Loss: 0.0210056663663299\n",
      "Val Loss: 0.02095930388680211\n",
      "Starting epoch 2866\n",
      "Train Loss: 0.0209823841298068\n",
      "Val Loss: 0.020983500613106623\n",
      "Starting epoch 2867\n",
      "Train Loss: 0.020967346098687913\n",
      "Val Loss: 0.021006591894008494\n",
      "Starting epoch 2868\n",
      "Train Loss: 0.02098547860428139\n",
      "Val Loss: 0.02144178361804397\n",
      "Starting epoch 2869\n",
      "Train Loss: 0.02100959089067247\n",
      "Val Loss: 0.020965413914786443\n",
      "Starting epoch 2870\n",
      "Train Loss: 0.020981650109644288\n",
      "Val Loss: 0.021076321049972816\n",
      "Starting epoch 2871\n",
      "Train Loss: 0.020990472148965905\n",
      "Val Loss: 0.02107522443488792\n",
      "Starting epoch 2872\n",
      "Train Loss: 0.021440026936707674\n",
      "Val Loss: 0.020972333572528982\n",
      "Starting epoch 2873\n",
      "Train Loss: 0.021067241275752033\n",
      "Val Loss: 0.021035685583397194\n",
      "Starting epoch 2874\n",
      "Train Loss: 0.020987468185248197\n",
      "Val Loss: 0.020971776710616216\n",
      "Starting epoch 2875\n",
      "Train Loss: 0.020985780490769282\n",
      "Val Loss: 0.021499614472742432\n",
      "Starting epoch 2876\n",
      "Train Loss: 0.020991224933553626\n",
      "Val Loss: 0.02097085725378107\n",
      "Starting epoch 2877\n",
      "Train Loss: 0.02097403837574853\n",
      "Val Loss: 0.021126332106413664\n",
      "Starting epoch 2878\n",
      "Train Loss: 0.02099545575954296\n",
      "Val Loss: 0.020977374028276513\n",
      "Starting epoch 2879\n",
      "Train Loss: 0.02098464745062369\n",
      "Val Loss: 0.021111466818385653\n",
      "Starting epoch 2880\n",
      "Train Loss: 0.020991965576454445\n",
      "Val Loss: 0.02142540724189193\n",
      "Starting epoch 2881\n",
      "Train Loss: 0.020969558093282912\n",
      "Val Loss: 0.021072875018473023\n",
      "Starting epoch 2882\n",
      "Train Loss: 0.021000186602274578\n",
      "Val Loss: 0.020992062158054776\n",
      "Starting epoch 2883\n",
      "Train Loss: 0.021415554262973643\n",
      "Val Loss: 0.02097222484924175\n",
      "Starting epoch 2884\n",
      "Train Loss: 0.0209730405498434\n",
      "Val Loss: 0.021013641798937763\n",
      "Starting epoch 2885\n",
      "Train Loss: 0.020994255940119427\n",
      "Val Loss: 0.020964167184299894\n",
      "Starting epoch 2886\n",
      "Train Loss: 0.020971152517530654\n",
      "Val Loss: 0.020967669509075307\n",
      "Starting epoch 2887\n",
      "Train Loss: 0.020973031719525654\n",
      "Val Loss: 0.0214463715200071\n",
      "Starting epoch 2888\n",
      "Train Loss: 0.021098877544756287\n",
      "Val Loss: 0.020974196217678213\n",
      "Starting epoch 2889\n",
      "Train Loss: 0.021067306399345398\n",
      "Val Loss: 0.020986414617962308\n",
      "Starting epoch 2890\n",
      "Train Loss: 0.020976732174555462\n",
      "Val Loss: 0.02097697224881914\n",
      "Starting epoch 2891\n",
      "Train Loss: 0.02099290821287367\n",
      "Val Loss: 0.02096999243453697\n",
      "Starting epoch 2892\n",
      "Train Loss: 0.02150074420151887\n",
      "Val Loss: 0.02095749698303364\n",
      "Starting epoch 2893\n",
      "Train Loss: 0.021051297033274616\n",
      "Val Loss: 0.020969862739245098\n",
      "Starting epoch 2894\n",
      "Train Loss: 0.021000467516757822\n",
      "Val Loss: 0.020991317651889944\n",
      "Starting epoch 2895\n",
      "Train Loss: 0.02105823545544236\n",
      "Val Loss: 0.021547057562404208\n",
      "Starting epoch 2896\n",
      "Train Loss: 0.02148921677359828\n",
      "Val Loss: 0.021008268550590233\n",
      "Starting epoch 2897\n",
      "Train Loss: 0.020974449537418508\n",
      "Val Loss: 0.021076609139089233\n",
      "Starting epoch 2898\n",
      "Train Loss: 0.020983310209380254\n",
      "Val Loss: 0.020954563109963027\n",
      "Starting epoch 2899\n",
      "Train Loss: 0.021064137970959698\n",
      "Val Loss: 0.02141610339835838\n",
      "Starting epoch 2900\n",
      "Train Loss: 0.021005824760154442\n",
      "Val Loss: 0.020981242811238324\n",
      "Starting epoch 2901\n",
      "Train Loss: 0.020988701118363276\n",
      "Val Loss: 0.020966058527981793\n",
      "Starting epoch 2902\n",
      "Train Loss: 0.020995013691760874\n",
      "Val Loss: 0.02097012323361856\n",
      "Starting epoch 2903\n",
      "Train Loss: 0.021405114619820205\n",
      "Val Loss: 0.020953601709118596\n",
      "Starting epoch 2904\n",
      "Train Loss: 0.02095582198213648\n",
      "Val Loss: 0.02098068705311528\n",
      "Starting epoch 2905\n",
      "Train Loss: 0.021092599740734807\n",
      "Val Loss: 0.020979594301294396\n",
      "Starting epoch 2906\n",
      "Train Loss: 0.021062044081864535\n",
      "Val Loss: 0.021075502589896874\n",
      "Starting epoch 2907\n",
      "Train Loss: 0.020957632197274104\n",
      "Val Loss: 0.021413874846917612\n",
      "Starting epoch 2908\n",
      "Train Loss: 0.02144352650200879\n",
      "Val Loss: 0.02096040822841503\n",
      "Starting epoch 2909\n",
      "Train Loss: 0.021080303523275588\n",
      "Val Loss: 0.021118136467757048\n",
      "Starting epoch 2910\n",
      "Train Loss: 0.020973920270248695\n",
      "Val Loss: 0.020955858407197176\n",
      "Starting epoch 2911\n",
      "Train Loss: 0.02100447537722411\n",
      "Val Loss: 0.02095937839260808\n",
      "Starting epoch 2912\n",
      "Train Loss: 0.020987937847773235\n",
      "Val Loss: 0.02097933049555178\n",
      "Starting epoch 2913\n",
      "Train Loss: 0.020991641062277334\n",
      "Val Loss: 0.020953220901665865\n",
      "Starting epoch 2914\n",
      "Train Loss: 0.02096478309896257\n",
      "Val Loss: 0.021053201070538274\n",
      "Starting epoch 2915\n",
      "Train Loss: 0.0209910461196193\n",
      "Val Loss: 0.020963623015968887\n",
      "Starting epoch 2916\n",
      "Train Loss: 0.021095254906901607\n",
      "Val Loss: 0.02097003272286168\n",
      "Starting epoch 2917\n",
      "Train Loss: 0.021019680080590426\n",
      "Val Loss: 0.020984420069941768\n",
      "Starting epoch 2918\n",
      "Train Loss: 0.020956548275770964\n",
      "Val Loss: 0.020982737342516582\n",
      "Starting epoch 2919\n",
      "Train Loss: 0.020987012871989497\n",
      "Val Loss: 0.020962110272160283\n",
      "Starting epoch 2920\n",
      "Train Loss: 0.02106396633165854\n",
      "Val Loss: 0.021452139925073693\n",
      "Starting epoch 2921\n",
      "Train Loss: 0.021420602997144062\n",
      "Val Loss: 0.021420082008397137\n",
      "Starting epoch 2922\n",
      "Train Loss: 0.020956776208347745\n",
      "Val Loss: 0.02096652819050683\n",
      "Starting epoch 2923\n",
      "Train Loss: 0.02102550422703778\n",
      "Val Loss: 0.02108222246170044\n",
      "Starting epoch 2924\n",
      "Train Loss: 0.021026585940961486\n",
      "Val Loss: 0.0209576780045474\n",
      "Starting epoch 2925\n",
      "Train Loss: 0.02140872953114686\n",
      "Val Loss: 0.020962524193304556\n",
      "Starting epoch 2926\n",
      "Train Loss: 0.020963311747268395\n",
      "Val Loss: 0.020972644289334614\n",
      "Starting epoch 2927\n",
      "Train Loss: 0.020951129220150137\n",
      "Val Loss: 0.02096756464905209\n",
      "Starting epoch 2928\n",
      "Train Loss: 0.020960424233365943\n",
      "Val Loss: 0.021030108133951824\n",
      "Starting epoch 2929\n",
      "Train Loss: 0.02096020402731719\n",
      "Val Loss: 0.02097643028806757\n",
      "Starting epoch 2930\n",
      "Train Loss: 0.020985300342241924\n",
      "Val Loss: 0.02099673174045704\n",
      "Starting epoch 2931\n",
      "Train Loss: 0.021001354411796288\n",
      "Val Loss: 0.02097766156549807\n",
      "Starting epoch 2932\n",
      "Train Loss: 0.0214267130251284\n",
      "Val Loss: 0.020981151196691725\n",
      "Starting epoch 2933\n",
      "Train Loss: 0.021034161801691407\n",
      "Val Loss: 0.021428330077065363\n",
      "Starting epoch 2934\n",
      "Train Loss: 0.02095724145571391\n",
      "Val Loss: 0.02098707965126744\n",
      "Starting epoch 2935\n",
      "Train Loss: 0.020945812816973084\n",
      "Val Loss: 0.021402483737027203\n",
      "Starting epoch 2936\n",
      "Train Loss: 0.021005883812904358\n",
      "Val Loss: 0.02107678519354926\n",
      "Starting epoch 2937\n",
      "Train Loss: 0.020960699628900598\n",
      "Val Loss: 0.02142351700199975\n",
      "Starting epoch 2938\n",
      "Train Loss: 0.021147353229699312\n",
      "Val Loss: 0.02097806113737601\n",
      "Starting epoch 2939\n",
      "Train Loss: 0.0209927084269347\n",
      "Val Loss: 0.020969551470544603\n",
      "Starting epoch 2940\n",
      "Train Loss: 0.020948028674832097\n",
      "Val Loss: 0.020945391169300786\n",
      "Starting epoch 2941\n",
      "Train Loss: 0.020975059381237737\n",
      "Val Loss: 0.02095207296035908\n",
      "Starting epoch 2942\n",
      "Train Loss: 0.020951215315748145\n",
      "Val Loss: 0.020967402943858394\n",
      "Starting epoch 2943\n",
      "Train Loss: 0.02109184585235737\n",
      "Val Loss: 0.021086101178769714\n",
      "Starting epoch 2944\n",
      "Train Loss: 0.020965562374503526\n",
      "Val Loss: 0.02094772347697505\n",
      "Starting epoch 2945\n",
      "Train Loss: 0.02097159900047161\n",
      "Val Loss: 0.02094429345042617\n",
      "Starting epoch 2946\n",
      "Train Loss: 0.020944664323771442\n",
      "Val Loss: 0.02097081199840263\n",
      "Starting epoch 2947\n",
      "Train Loss: 0.020957655376858182\n",
      "Val Loss: 0.020989361184614676\n",
      "Starting epoch 2948\n",
      "Train Loss: 0.021006143755382962\n",
      "Val Loss: 0.020947265956136916\n",
      "Starting epoch 2949\n",
      "Train Loss: 0.020998644056143583\n",
      "Val Loss: 0.021026922596825495\n",
      "Starting epoch 2950\n",
      "Train Loss: 0.021107790646729647\n",
      "Val Loss: 0.020974665328308387\n",
      "Starting epoch 2951\n",
      "Train Loss: 0.020955209378842956\n",
      "Val Loss: 0.021018318004078336\n",
      "Starting epoch 2952\n",
      "Train Loss: 0.02105475244698701\n",
      "Val Loss: 0.021005818137416133\n",
      "Starting epoch 2953\n",
      "Train Loss: 0.021413359377119277\n",
      "Val Loss: 0.020983581189756042\n",
      "Starting epoch 2954\n",
      "Train Loss: 0.02099780296837842\n",
      "Val Loss: 0.021396093898349337\n",
      "Starting epoch 2955\n",
      "Train Loss: 0.021011200216081407\n",
      "Val Loss: 0.020968840629966172\n",
      "Starting epoch 2956\n",
      "Train Loss: 0.020942473301181087\n",
      "Val Loss: 0.02097333139843411\n",
      "Starting epoch 2957\n",
      "Train Loss: 0.02096228908609461\n",
      "Val Loss: 0.020980764870290405\n",
      "Starting epoch 2958\n",
      "Train Loss: 0.020946301795818186\n",
      "Val Loss: 0.021058276295661926\n",
      "Starting epoch 2959\n",
      "Train Loss: 0.0209860200131381\n",
      "Val Loss: 0.020974513005327294\n",
      "Starting epoch 2960\n",
      "Train Loss: 0.021017092245596426\n",
      "Val Loss: 0.02095237374305725\n",
      "Starting epoch 2961\n",
      "Train Loss: 0.021412808586049964\n",
      "Val Loss: 0.021406028005811904\n",
      "Starting epoch 2962\n",
      "Train Loss: 0.021019659108585782\n",
      "Val Loss: 0.020950792564286128\n",
      "Starting epoch 2963\n",
      "Train Loss: 0.021067633672996803\n",
      "Val Loss: 0.02096594704522027\n",
      "Starting epoch 2964\n",
      "Train Loss: 0.020970472031169467\n",
      "Val Loss: 0.02139610438435166\n",
      "Starting epoch 2965\n",
      "Train Loss: 0.020969732492058364\n",
      "Val Loss: 0.020971045449928002\n",
      "Starting epoch 2966\n",
      "Train Loss: 0.020991529027620952\n",
      "Val Loss: 0.02095692301238025\n",
      "Starting epoch 2967\n",
      "Train Loss: 0.020978895602402865\n",
      "Val Loss: 0.02105298031259466\n",
      "Starting epoch 2968\n",
      "Train Loss: 0.0209702601035436\n",
      "Val Loss: 0.02096680689741064\n",
      "Starting epoch 2969\n",
      "Train Loss: 0.021075132268446463\n",
      "Val Loss: 0.020949880833979004\n",
      "Starting epoch 2970\n",
      "Train Loss: 0.02098437371077361\n",
      "Val Loss: 0.02101742007114269\n",
      "Starting epoch 2971\n",
      "Train Loss: 0.02143618298901452\n",
      "Val Loss: 0.02106940028844056\n",
      "Starting epoch 2972\n",
      "Train Loss: 0.021408708559142217\n",
      "Val Loss: 0.021043053379765263\n",
      "Starting epoch 2973\n",
      "Train Loss: 0.020967497869774147\n",
      "Val Loss: 0.020955526718386897\n",
      "Starting epoch 2974\n",
      "Train Loss: 0.02097063042499401\n",
      "Val Loss: 0.0209452697524318\n",
      "Starting epoch 2975\n",
      "Train Loss: 0.021051273853690537\n",
      "Val Loss: 0.020972027822777076\n",
      "Starting epoch 2976\n",
      "Train Loss: 0.02102919750743442\n",
      "Val Loss: 0.020969548711070308\n",
      "Starting epoch 2977\n",
      "Train Loss: 0.020974226571895457\n",
      "Val Loss: 0.0209825673589\n",
      "Starting epoch 2978\n",
      "Train Loss: 0.020952806428626732\n",
      "Val Loss: 0.020963415503501892\n",
      "Starting epoch 2979\n",
      "Train Loss: 0.020987330211533442\n",
      "Val Loss: 0.02094987476313556\n",
      "Starting epoch 2980\n",
      "Train Loss: 0.020974919199943542\n",
      "Val Loss: 0.020979304556493408\n",
      "Starting epoch 2981\n",
      "Train Loss: 0.02145031260119544\n",
      "Val Loss: 0.02104587687386407\n",
      "Starting epoch 2982\n",
      "Train Loss: 0.020941119503091882\n",
      "Val Loss: 0.020958432444819697\n",
      "Starting epoch 2983\n",
      "Train Loss: 0.020966984607555247\n",
      "Val Loss: 0.020966903479010972\n",
      "Starting epoch 2984\n",
      "Train Loss: 0.02094223709018142\n",
      "Val Loss: 0.021007764670583937\n",
      "Starting epoch 2985\n",
      "Train Loss: 0.020959942429154006\n",
      "Val Loss: 0.02094165208163085\n",
      "Starting epoch 2986\n",
      "Train Loss: 0.021038790543874104\n",
      "Val Loss: 0.020984114320189866\n",
      "Starting epoch 2987\n",
      "Train Loss: 0.020985857204154686\n",
      "Val Loss: 0.020974594685766432\n",
      "Starting epoch 2988\n",
      "Train Loss: 0.020951579566355103\n",
      "Val Loss: 0.02093988436239737\n",
      "Starting epoch 2989\n",
      "Train Loss: 0.021414948834313288\n",
      "Val Loss: 0.020966165595584445\n",
      "Starting epoch 2990\n",
      "Train Loss: 0.020958000311145076\n",
      "Val Loss: 0.020974257478007564\n",
      "Starting epoch 2991\n",
      "Train Loss: 0.02095973602047673\n",
      "Val Loss: 0.02100361000608515\n",
      "Starting epoch 2992\n",
      "Train Loss: 0.02096886215386567\n",
      "Val Loss: 0.020945801227181045\n",
      "Starting epoch 2993\n",
      "Train Loss: 0.0209394798234657\n",
      "Val Loss: 0.020941517971180105\n",
      "Starting epoch 2994\n",
      "Train Loss: 0.02140032527623353\n",
      "Val Loss: 0.02094941669040256\n",
      "Starting epoch 2995\n",
      "Train Loss: 0.02103541405112655\n",
      "Val Loss: 0.02094287066547959\n",
      "Starting epoch 2996\n",
      "Train Loss: 0.021395429968833923\n",
      "Val Loss: 0.02104219573515433\n",
      "Starting epoch 2997\n",
      "Train Loss: 0.020969374864189712\n",
      "Val Loss: 0.020940777880174143\n",
      "Starting epoch 2998\n",
      "Train Loss: 0.020986676768020348\n",
      "Val Loss: 0.02099083971094202\n",
      "Starting epoch 2999\n",
      "Train Loss: 0.021415005679483765\n",
      "Val Loss: 0.02094677421781752\n",
      "Starting epoch 3000\n",
      "Train Loss: 0.020973253581258986\n",
      "Val Loss: 0.0214296645588345\n",
      "Starting epoch 3001\n",
      "Train Loss: 0.020977483303458604\n",
      "Val Loss: 0.021410545265233075\n",
      "Starting epoch 3002\n",
      "Train Loss: 0.020987897007553664\n",
      "Val Loss: 0.020961807833777532\n",
      "Starting epoch 3003\n",
      "Train Loss: 0.02095753064862004\n",
      "Val Loss: 0.020963885166026926\n",
      "Starting epoch 3004\n",
      "Train Loss: 0.021038099571510597\n",
      "Val Loss: 0.0210713396469752\n",
      "Starting epoch 3005\n",
      "Train Loss: 0.021047741174697876\n",
      "Val Loss: 0.020943238227455703\n",
      "Starting epoch 3006\n",
      "Train Loss: 0.02094697345186163\n",
      "Val Loss: 0.020963267043784813\n",
      "Starting epoch 3007\n",
      "Train Loss: 0.020946519794287504\n",
      "Val Loss: 0.020936394731203716\n",
      "Starting epoch 3008\n",
      "Train Loss: 0.020935863808349327\n",
      "Val Loss: 0.021026419268714056\n",
      "Starting epoch 3009\n",
      "Train Loss: 0.021059695769239356\n",
      "Val Loss: 0.020966546403037176\n",
      "Starting epoch 3010\n",
      "Train Loss: 0.021032192640834384\n",
      "Val Loss: 0.0209542711575826\n",
      "Starting epoch 3011\n",
      "Train Loss: 0.020948890182707045\n",
      "Val Loss: 0.02143559577288451\n",
      "Starting epoch 3012\n",
      "Train Loss: 0.021040915890976234\n",
      "Val Loss: 0.02097087049925769\n",
      "Starting epoch 3013\n",
      "Train Loss: 0.02093885894174929\n",
      "Val Loss: 0.02096930256596318\n",
      "Starting epoch 3014\n",
      "Train Loss: 0.021050153507126704\n",
      "Val Loss: 0.021144623005831684\n",
      "Starting epoch 3015\n",
      "Train Loss: 0.021040161450703938\n",
      "Val Loss: 0.020945629587879887\n",
      "Starting epoch 3016\n",
      "Train Loss: 0.02095930775006612\n",
      "Val Loss: 0.02094893267861119\n",
      "Starting epoch 3017\n",
      "Train Loss: 0.021032842772978323\n",
      "Val Loss: 0.02104679467501464\n",
      "Starting epoch 3018\n",
      "Train Loss: 0.020968381453443458\n",
      "Val Loss: 0.020986169576644897\n",
      "Starting epoch 3019\n",
      "Train Loss: 0.020976696853284484\n",
      "Val Loss: 0.020952814707049617\n",
      "Starting epoch 3020\n",
      "Train Loss: 0.021054751343197294\n",
      "Val Loss: 0.021102121582737676\n",
      "Starting epoch 3021\n",
      "Train Loss: 0.020975796712769404\n",
      "Val Loss: 0.021032014378794917\n",
      "Starting epoch 3022\n",
      "Train Loss: 0.021031028694576688\n",
      "Val Loss: 0.020991117314056115\n",
      "Starting epoch 3023\n",
      "Train Loss: 0.020963612529966567\n",
      "Val Loss: 0.02094253345772072\n",
      "Starting epoch 3024\n",
      "Train Loss: 0.02095734300436797\n",
      "Val Loss: 0.020978945272940176\n",
      "Starting epoch 3025\n",
      "Train Loss: 0.02093880871931712\n",
      "Val Loss: 0.020967049731148615\n",
      "Starting epoch 3026\n",
      "Train Loss: 0.02096794656029454\n",
      "Val Loss: 0.020971072492776095\n",
      "Starting epoch 3027\n",
      "Train Loss: 0.02101754093611682\n",
      "Val Loss: 0.020979838790716947\n",
      "Starting epoch 3028\n",
      "Train Loss: 0.02093181510766347\n",
      "Val Loss: 0.020947476779973065\n",
      "Starting epoch 3029\n",
      "Train Loss: 0.02095567241862968\n",
      "Val Loss: 0.020952758965668856\n",
      "Starting epoch 3030\n",
      "Train Loss: 0.020973363408335933\n",
      "Val Loss: 0.02095830550900212\n",
      "Starting epoch 3031\n",
      "Train Loss: 0.020937813652886286\n",
      "Val Loss: 0.020938110572320444\n",
      "Starting epoch 3032\n",
      "Train Loss: 0.02094133915724578\n",
      "Val Loss: 0.021530215938886006\n",
      "Starting epoch 3033\n",
      "Train Loss: 0.020955763481281423\n",
      "Val Loss: 0.020960217272793805\n",
      "Starting epoch 3034\n",
      "Train Loss: 0.02096468320599309\n",
      "Val Loss: 0.020956925771854543\n",
      "Starting epoch 3035\n",
      "Train Loss: 0.02100032733546363\n",
      "Val Loss: 0.02097150793781987\n",
      "Starting epoch 3036\n",
      "Train Loss: 0.02095562937083068\n",
      "Val Loss: 0.021045359196486296\n",
      "Starting epoch 3037\n",
      "Train Loss: 0.0209948746142564\n",
      "Val Loss: 0.020935352201815003\n",
      "Starting epoch 3038\n",
      "Train Loss: 0.02099395570931611\n",
      "Val Loss: 0.020963509877522785\n",
      "Starting epoch 3039\n",
      "Train Loss: 0.021397668454382155\n",
      "Val Loss: 0.02106500223830894\n",
      "Starting epoch 3040\n",
      "Train Loss: 0.02097056806087494\n",
      "Val Loss: 0.020934493453414353\n",
      "Starting epoch 3041\n",
      "Train Loss: 0.020952952680764376\n",
      "Val Loss: 0.020943864628120704\n",
      "Starting epoch 3042\n",
      "Train Loss: 0.020934641913131432\n",
      "Val Loss: 0.02095807316126647\n",
      "Starting epoch 3043\n",
      "Train Loss: 0.020998917795993662\n",
      "Val Loss: 0.020945040164170443\n",
      "Starting epoch 3044\n",
      "Train Loss: 0.021008414802727877\n",
      "Val Loss: 0.020956555450404132\n",
      "Starting epoch 3045\n",
      "Train Loss: 0.020942883359061346\n",
      "Val Loss: 0.020973362304546214\n",
      "Starting epoch 3046\n",
      "Train Loss: 0.020932092158882705\n",
      "Val Loss: 0.021028910522107726\n",
      "Starting epoch 3047\n",
      "Train Loss: 0.020962916590549326\n",
      "Val Loss: 0.020963316714322125\n",
      "Starting epoch 3048\n",
      "Train Loss: 0.021412944352185284\n",
      "Val Loss: 0.020941036718863028\n",
      "Starting epoch 3049\n",
      "Train Loss: 0.02094132646366402\n",
      "Val Loss: 0.02093713427031482\n",
      "Starting epoch 3050\n",
      "Train Loss: 0.02101020183828142\n",
      "Val Loss: 0.020946907224478544\n",
      "Starting epoch 3051\n",
      "Train Loss: 0.020931179876680726\n",
      "Val Loss: 0.020957481529977586\n",
      "Starting epoch 3052\n",
      "Train Loss: 0.0209853478051998\n",
      "Val Loss: 0.021029771478087815\n",
      "Starting epoch 3053\n",
      "Train Loss: 0.021003300944964092\n",
      "Val Loss: 0.02098524625654574\n",
      "Starting epoch 3054\n",
      "Train Loss: 0.020928532988936814\n",
      "Val Loss: 0.02140160125714761\n",
      "Starting epoch 3055\n",
      "Train Loss: 0.02095186213652293\n",
      "Val Loss: 0.020938458817976492\n",
      "Starting epoch 3056\n",
      "Train Loss: 0.02140102176754563\n",
      "Val Loss: 0.02095729167814608\n",
      "Starting epoch 3057\n",
      "Train Loss: 0.020957711118238943\n",
      "Val Loss: 0.02098445263173845\n",
      "Starting epoch 3058\n",
      "Train Loss: 0.020951100521617465\n",
      "Val Loss: 0.020930963533895987\n",
      "Starting epoch 3059\n",
      "Train Loss: 0.02094948512536508\n",
      "Val Loss: 0.0209904533845407\n",
      "Starting epoch 3060\n",
      "Train Loss: 0.020974796679284837\n",
      "Val Loss: 0.020926815492135507\n",
      "Starting epoch 3061\n",
      "Train Loss: 0.020937192771169875\n",
      "Val Loss: 0.021046759905638517\n",
      "Starting epoch 3062\n",
      "Train Loss: 0.02093789533332542\n",
      "Val Loss: 0.02096356561890355\n",
      "Starting epoch 3063\n",
      "Train Loss: 0.020963421022450482\n",
      "Val Loss: 0.02092886026258822\n",
      "Starting epoch 3064\n",
      "Train Loss: 0.02095256690625791\n",
      "Val Loss: 0.020930555131700303\n",
      "Starting epoch 3065\n",
      "Train Loss: 0.02105207299744641\n",
      "Val Loss: 0.0209507848377581\n",
      "Starting epoch 3066\n",
      "Train Loss: 0.0209722888690454\n",
      "Val Loss: 0.021071374968246178\n",
      "Starting epoch 3067\n",
      "Train Loss: 0.020947910569332266\n",
      "Val Loss: 0.0209569141820625\n",
      "Starting epoch 3068\n",
      "Train Loss: 0.020990517956239206\n",
      "Val Loss: 0.020947288583826135\n",
      "Starting epoch 3069\n",
      "Train Loss: 0.02095141565358197\n",
      "Val Loss: 0.02095090570273223\n",
      "Starting epoch 3070\n",
      "Train Loss: 0.020933385248537415\n",
      "Val Loss: 0.020925119519233704\n",
      "Starting epoch 3071\n",
      "Train Loss: 0.021499824744683725\n",
      "Val Loss: 0.020951734096915635\n",
      "Starting epoch 3072\n",
      "Train Loss: 0.020959761407640245\n",
      "Val Loss: 0.02094824446572198\n",
      "Starting epoch 3073\n",
      "Train Loss: 0.02098433397434376\n",
      "Val Loss: 0.020938064765047143\n",
      "Starting epoch 3074\n",
      "Train Loss: 0.021007515214107656\n",
      "Val Loss: 0.020931963015485694\n",
      "Starting epoch 3075\n",
      "Train Loss: 0.020969076840965835\n",
      "Val Loss: 0.02102026950429987\n",
      "Starting epoch 3076\n",
      "Train Loss: 0.02102789945072598\n",
      "Val Loss: 0.02093087688640312\n",
      "Starting epoch 3077\n",
      "Train Loss: 0.02138752352308344\n",
      "Val Loss: 0.020958064330948725\n",
      "Starting epoch 3078\n",
      "Train Loss: 0.020994891171102172\n",
      "Val Loss: 0.020955534444914922\n",
      "Starting epoch 3079\n",
      "Train Loss: 0.02140181925561693\n",
      "Val Loss: 0.021092544551248902\n",
      "Starting epoch 3080\n",
      "Train Loss: 0.020977303937629418\n",
      "Val Loss: 0.020923841330740187\n",
      "Starting epoch 3081\n",
      "Train Loss: 0.02092411948574914\n",
      "Val Loss: 0.020968777713952242\n",
      "Starting epoch 3082\n",
      "Train Loss: 0.021386858489778306\n",
      "Val Loss: 0.020925328687385277\n",
      "Starting epoch 3083\n",
      "Train Loss: 0.021396222489851492\n",
      "Val Loss: 0.020927650509057222\n",
      "Starting epoch 3084\n",
      "Train Loss: 0.020944523590582388\n",
      "Val Loss: 0.021378146829428495\n",
      "Starting epoch 3085\n",
      "Train Loss: 0.020933094951841567\n",
      "Val Loss: 0.020938554847681964\n",
      "Starting epoch 3086\n",
      "Train Loss: 0.020945921540260315\n",
      "Val Loss: 0.02102118013081727\n",
      "Starting epoch 3087\n",
      "Train Loss: 0.020930703591417382\n",
      "Val Loss: 0.0209691082989728\n",
      "Starting epoch 3088\n",
      "Train Loss: 0.02095864602813014\n",
      "Val Loss: 0.020941819857667993\n",
      "Starting epoch 3089\n",
      "Train Loss: 0.02103870831154011\n",
      "Val Loss: 0.020959287881851196\n",
      "Starting epoch 3090\n",
      "Train Loss: 0.020948190380025794\n",
      "Val Loss: 0.02092143065399594\n",
      "Starting epoch 3091\n",
      "Train Loss: 0.020991084200364572\n",
      "Val Loss: 0.0209556034317723\n",
      "Starting epoch 3092\n",
      "Train Loss: 0.020989043293175875\n",
      "Val Loss: 0.02093986228660301\n",
      "Starting epoch 3093\n",
      "Train Loss: 0.02103496591250102\n",
      "Val Loss: 0.0209987610578537\n",
      "Starting epoch 3094\n",
      "Train Loss: 0.020935939969839872\n",
      "Val Loss: 0.0209824084131806\n",
      "Starting epoch 3095\n",
      "Train Loss: 0.021029475662443373\n",
      "Val Loss: 0.020928906069861516\n",
      "Starting epoch 3096\n",
      "Train Loss: 0.02095214029153188\n",
      "Val Loss: 0.02137902820551837\n",
      "Starting epoch 3097\n",
      "Train Loss: 0.020926938012794213\n",
      "Val Loss: 0.020921197202470567\n",
      "Starting epoch 3098\n",
      "Train Loss: 0.021082042543976394\n",
      "Val Loss: 0.020920852820078533\n",
      "Starting epoch 3099\n",
      "Train Loss: 0.020932375280945388\n",
      "Val Loss: 0.02093048890431722\n",
      "Starting epoch 3100\n",
      "Train Loss: 0.020935261691058124\n",
      "Val Loss: 0.02094377632494326\n",
      "Starting epoch 3101\n",
      "Train Loss: 0.020956435137324862\n",
      "Val Loss: 0.020936729179488286\n",
      "Starting epoch 3102\n",
      "Train Loss: 0.021379460339192993\n",
      "Val Loss: 0.020980449738325895\n",
      "Starting epoch 3103\n",
      "Train Loss: 0.02103327711423238\n",
      "Val Loss: 0.02096692721048991\n",
      "Starting epoch 3104\n",
      "Train Loss: 0.02099526811529089\n",
      "Val Loss: 0.02092556103512093\n",
      "Starting epoch 3105\n",
      "Train Loss: 0.02094865341981252\n",
      "Val Loss: 0.020943771357889527\n",
      "Starting epoch 3106\n",
      "Train Loss: 0.02094979749785529\n",
      "Val Loss: 0.020925706183468853\n",
      "Starting epoch 3107\n",
      "Train Loss: 0.020944925370039762\n",
      "Val Loss: 0.020928786860571966\n",
      "Starting epoch 3108\n",
      "Train Loss: 0.020948307381735906\n",
      "Val Loss: 0.02092038702081751\n",
      "Starting epoch 3109\n",
      "Train Loss: 0.02091940023280956\n",
      "Val Loss: 0.020933900718335754\n",
      "Starting epoch 3110\n",
      "Train Loss: 0.0213952268715258\n",
      "Val Loss: 0.020921461008213186\n",
      "Starting epoch 3111\n",
      "Train Loss: 0.02092587230382142\n",
      "Val Loss: 0.020936564714820298\n",
      "Starting epoch 3112\n",
      "Train Loss: 0.020938216536133376\n",
      "Val Loss: 0.02095431751675076\n",
      "Starting epoch 3113\n",
      "Train Loss: 0.02102847507706395\n",
      "Val Loss: 0.021385025095056603\n",
      "Starting epoch 3114\n",
      "Train Loss: 0.020929220649931166\n",
      "Val Loss: 0.020953545967737835\n",
      "Starting epoch 3115\n",
      "Train Loss: 0.020927507568288733\n",
      "Val Loss: 0.02093668392410985\n",
      "Starting epoch 3116\n",
      "Train Loss: 0.020949449804094102\n",
      "Val Loss: 0.02094939351081848\n",
      "Starting epoch 3117\n",
      "Train Loss: 0.020926744849593552\n",
      "Val Loss: 0.02108435829480489\n",
      "Starting epoch 3118\n",
      "Train Loss: 0.021013396205725492\n",
      "Val Loss: 0.02093639141983456\n",
      "Starting epoch 3119\n",
      "Train Loss: 0.02096491555372874\n",
      "Val Loss: 0.020927818285094366\n",
      "Starting epoch 3120\n",
      "Train Loss: 0.020953196066397207\n",
      "Val Loss: 0.020939669675297208\n",
      "Starting epoch 3121\n",
      "Train Loss: 0.020933660644072073\n",
      "Val Loss: 0.020935253964530096\n",
      "Starting epoch 3122\n",
      "Train Loss: 0.020925290054745145\n",
      "Val Loss: 0.02142114495789563\n",
      "Starting epoch 3123\n",
      "Train Loss: 0.020934132514176546\n",
      "Val Loss: 0.02094161068951642\n",
      "Starting epoch 3124\n",
      "Train Loss: 0.020966536468929715\n",
      "Val Loss: 0.021384957763883803\n",
      "Starting epoch 3125\n",
      "Train Loss: 0.021386717756589253\n",
      "Val Loss: 0.020953150259123907\n",
      "Starting epoch 3126\n",
      "Train Loss: 0.020988135978027626\n",
      "Val Loss: 0.020921529443175706\n",
      "Starting epoch 3127\n",
      "Train Loss: 0.02094477304705867\n",
      "Val Loss: 0.02094790670606825\n",
      "Starting epoch 3128\n",
      "Train Loss: 0.02092357255794384\n",
      "Val Loss: 0.02093746871859939\n",
      "Starting epoch 3129\n",
      "Train Loss: 0.02145841000256715\n",
      "Val Loss: 0.02099919815858205\n",
      "Starting epoch 3130\n",
      "Train Loss: 0.020925345796125906\n",
      "Val Loss: 0.020934050833737408\n",
      "Starting epoch 3131\n",
      "Train Loss: 0.02103578492447182\n",
      "Val Loss: 0.020922132112361765\n",
      "Starting epoch 3132\n",
      "Train Loss: 0.021033285944550124\n",
      "Val Loss: 0.0209653134699221\n",
      "Starting epoch 3133\n",
      "Train Loss: 0.020940604585188406\n",
      "Val Loss: 0.02096052688580972\n",
      "Starting epoch 3134\n",
      "Train Loss: 0.02098664089485451\n",
      "Val Loss: 0.020965094367663067\n",
      "Starting epoch 3135\n",
      "Train Loss: 0.021011377926226014\n",
      "Val Loss: 0.02091584547802254\n",
      "Starting epoch 3136\n",
      "Train Loss: 0.020930695864889357\n",
      "Val Loss: 0.021468395988146465\n",
      "Starting epoch 3137\n",
      "Train Loss: 0.020921573042869568\n",
      "Val Loss: 0.02095801576420113\n",
      "Starting epoch 3138\n",
      "Train Loss: 0.02137444030355524\n",
      "Val Loss: 0.02137112010408331\n",
      "Starting epoch 3139\n",
      "Train Loss: 0.02091881853562814\n",
      "Val Loss: 0.020922372738520306\n",
      "Starting epoch 3140\n",
      "Train Loss: 0.020941129989094205\n",
      "Val Loss: 0.02093901292041496\n",
      "Starting epoch 3141\n",
      "Train Loss: 0.021408818386219167\n",
      "Val Loss: 0.02138609797866256\n",
      "Starting epoch 3142\n",
      "Train Loss: 0.02092152668370141\n",
      "Val Loss: 0.020936581823560927\n",
      "Starting epoch 3143\n",
      "Train Loss: 0.020945832133293152\n",
      "Val Loss: 0.020933353238635592\n",
      "Starting epoch 3144\n",
      "Train Loss: 0.020926548375023737\n",
      "Val Loss: 0.0209140463007821\n",
      "Starting epoch 3145\n",
      "Train Loss: 0.020939234230253432\n",
      "Val Loss: 0.020928307263939468\n",
      "Starting epoch 3146\n",
      "Train Loss: 0.0209318228341915\n",
      "Val Loss: 0.0209213368318699\n",
      "Starting epoch 3147\n",
      "Train Loss: 0.020928508153668157\n",
      "Val Loss: 0.020917428864373103\n",
      "Starting epoch 3148\n",
      "Train Loss: 0.020978853658393578\n",
      "Val Loss: 0.02092132634586758\n",
      "Starting epoch 3149\n",
      "Train Loss: 0.02144104849409174\n",
      "Val Loss: 0.02092658645576901\n",
      "Starting epoch 3150\n",
      "Train Loss: 0.0209343284368515\n",
      "Val Loss: 0.020920938363781682\n",
      "Starting epoch 3151\n",
      "Train Loss: 0.020944134504706773\n",
      "Val Loss: 0.020943689677450392\n",
      "Starting epoch 3152\n",
      "Train Loss: 0.020932451994330796\n",
      "Val Loss: 0.020921297095440054\n",
      "Starting epoch 3153\n",
      "Train Loss: 0.020936273314334727\n",
      "Val Loss: 0.021489925958492136\n",
      "Starting epoch 3154\n",
      "Train Loss: 0.020960945774007728\n",
      "Val Loss: 0.020950920051998563\n",
      "Starting epoch 3155\n",
      "Train Loss: 0.020937916305330064\n",
      "Val Loss: 0.020950676666365728\n",
      "Starting epoch 3156\n",
      "Train Loss: 0.02139661102383225\n",
      "Val Loss: 0.020929740534888372\n",
      "Starting epoch 3157\n",
      "Train Loss: 0.020943699059662996\n",
      "Val Loss: 0.020938709378242493\n",
      "Starting epoch 3158\n",
      "Train Loss: 0.020983246741471468\n",
      "Val Loss: 0.021034669544961717\n",
      "Starting epoch 3159\n",
      "Train Loss: 0.020927023004602502\n",
      "Val Loss: 0.02093516731703723\n",
      "Starting epoch 3160\n",
      "Train Loss: 0.020913968483606975\n",
      "Val Loss: 0.02092134842166194\n",
      "Starting epoch 3161\n",
      "Train Loss: 0.020934980776574876\n",
      "Val Loss: 0.021370228793885972\n",
      "Starting epoch 3162\n",
      "Train Loss: 0.02091718989389914\n",
      "Val Loss: 0.020947761557720327\n",
      "Starting epoch 3163\n",
      "Train Loss: 0.021047993390648452\n",
      "Val Loss: 0.020992696285247803\n",
      "Starting epoch 3164\n",
      "Train Loss: 0.021476706420933758\n",
      "Val Loss: 0.021023983204806293\n",
      "Starting epoch 3165\n",
      "Train Loss: 0.020950343321870873\n",
      "Val Loss: 0.02094536026318868\n",
      "Starting epoch 3166\n",
      "Train Loss: 0.020943840896641766\n",
      "Val Loss: 0.020919484672722994\n",
      "Starting epoch 3167\n",
      "Train Loss: 0.021029542993616174\n",
      "Val Loss: 0.021023751960860357\n",
      "Starting epoch 3168\n",
      "Train Loss: 0.020941840829672636\n",
      "Val Loss: 0.02138731877009074\n",
      "Starting epoch 3169\n",
      "Train Loss: 0.020922766239554795\n",
      "Val Loss: 0.02090971337424384\n",
      "Starting epoch 3170\n",
      "Train Loss: 0.020927004792072153\n",
      "Val Loss: 0.02091893940060227\n",
      "Starting epoch 3171\n",
      "Train Loss: 0.020991191819862084\n",
      "Val Loss: 0.020943204009974445\n",
      "Starting epoch 3172\n",
      "Train Loss: 0.020918234078972427\n",
      "Val Loss: 0.0210445926145271\n",
      "Starting epoch 3173\n",
      "Train Loss: 0.02092472877767351\n",
      "Val Loss: 0.02091438792369984\n",
      "Starting epoch 3174\n",
      "Train Loss: 0.021491270374368737\n",
      "Val Loss: 0.02137142088678148\n",
      "Starting epoch 3175\n",
      "Train Loss: 0.021050437181084243\n",
      "Val Loss: 0.02091505350889983\n",
      "Starting epoch 3176\n",
      "Train Loss: 0.020912331563455087\n",
      "Val Loss: 0.020978161582240352\n",
      "Starting epoch 3177\n",
      "Train Loss: 0.02102752857738071\n",
      "Val Loss: 0.020923864510324266\n",
      "Starting epoch 3178\n",
      "Train Loss: 0.020909843069535715\n",
      "Val Loss: 0.0210297918981976\n",
      "Starting epoch 3179\n",
      "Train Loss: 0.02102921020101618\n",
      "Val Loss: 0.020912863590099192\n",
      "Starting epoch 3180\n",
      "Train Loss: 0.020939740869734023\n",
      "Val Loss: 0.020917996764183044\n",
      "Starting epoch 3181\n",
      "Train Loss: 0.020973965525627136\n",
      "Val Loss: 0.020953396404231037\n",
      "Starting epoch 3182\n",
      "Train Loss: 0.02092049464031502\n",
      "Val Loss: 0.020926714495376305\n",
      "Starting epoch 3183\n",
      "Train Loss: 0.02148301292348791\n",
      "Val Loss: 0.020968135308336328\n",
      "Starting epoch 3184\n",
      "Train Loss: 0.02094651261965434\n",
      "Val Loss: 0.021006524562835693\n",
      "Starting epoch 3185\n",
      "Train Loss: 0.020910191315191763\n",
      "Val Loss: 0.020931818419032626\n",
      "Starting epoch 3186\n",
      "Train Loss: 0.02093028525511424\n",
      "Val Loss: 0.0209100897665377\n",
      "Starting epoch 3187\n",
      "Train Loss: 0.020938404732280307\n",
      "Val Loss: 0.020927779100559377\n",
      "Starting epoch 3188\n",
      "Train Loss: 0.020911249849531386\n",
      "Val Loss: 0.02091714298283612\n",
      "Starting epoch 3189\n",
      "Train Loss: 0.021371954569110164\n",
      "Val Loss: 0.020919250669302763\n",
      "Starting epoch 3190\n",
      "Train Loss: 0.02093381627842232\n",
      "Val Loss: 0.021369299402943364\n",
      "Starting epoch 3191\n",
      "Train Loss: 0.020938904749022588\n",
      "Val Loss: 0.02091635266939799\n",
      "Starting epoch 3192\n",
      "Train Loss: 0.020920109417703416\n",
      "Val Loss: 0.020906356749711214\n",
      "Starting epoch 3193\n",
      "Train Loss: 0.020974724932953163\n",
      "Val Loss: 0.020938982014302856\n",
      "Starting epoch 3194\n",
      "Train Loss: 0.021405147181616888\n",
      "Val Loss: 0.021022249151159217\n",
      "Starting epoch 3195\n",
      "Train Loss: 0.021027291814486187\n",
      "Val Loss: 0.020992722224306176\n",
      "Starting epoch 3196\n",
      "Train Loss: 0.020974676918100427\n",
      "Val Loss: 0.02091422732229586\n",
      "Starting epoch 3197\n",
      "Train Loss: 0.02091525274294394\n",
      "Val Loss: 0.02136862885068964\n",
      "Starting epoch 3198\n",
      "Train Loss: 0.020907713307274714\n",
      "Val Loss: 0.020907803266136733\n",
      "Starting epoch 3199\n",
      "Train Loss: 0.021379114853011236\n",
      "Val Loss: 0.020930319472595497\n",
      "Starting epoch 3200\n",
      "Train Loss: 0.020915305724850407\n",
      "Val Loss: 0.02097754842705197\n",
      "Starting epoch 3201\n",
      "Train Loss: 0.02094416265134458\n",
      "Val Loss: 0.020918724161607248\n",
      "Starting epoch 3202\n",
      "Train Loss: 0.02138598097695245\n",
      "Val Loss: 0.020920382605658636\n",
      "Starting epoch 3203\n",
      "Train Loss: 0.02096946923821061\n",
      "Val Loss: 0.020910059412320454\n",
      "Starting epoch 3204\n",
      "Train Loss: 0.020919448799557157\n",
      "Val Loss: 0.02090557802606512\n",
      "Starting epoch 3205\n",
      "Train Loss: 0.020925784000643977\n",
      "Val Loss: 0.020917938815222845\n",
      "Starting epoch 3206\n",
      "Train Loss: 0.02092647221353319\n",
      "Val Loss: 0.020933934383922152\n",
      "Starting epoch 3207\n",
      "Train Loss: 0.0209104777486236\n",
      "Val Loss: 0.020936449920689618\n",
      "Starting epoch 3208\n",
      "Train Loss: 0.021030295778203895\n",
      "Val Loss: 0.020920495744104737\n",
      "Starting epoch 3209\n",
      "Train Loss: 0.021022803253597684\n",
      "Val Loss: 0.020923202236493427\n",
      "Starting epoch 3210\n",
      "Train Loss: 0.02092893476839419\n",
      "Val Loss: 0.02097735360816673\n",
      "Starting epoch 3211\n",
      "Train Loss: 0.02095309286205857\n",
      "Val Loss: 0.020965836114353605\n",
      "Starting epoch 3212\n",
      "Train Loss: 0.02100973879849469\n",
      "Val Loss: 0.020984069064811425\n",
      "Starting epoch 3213\n",
      "Train Loss: 0.02137115156209027\n",
      "Val Loss: 0.02092133738376476\n",
      "Starting epoch 3214\n",
      "Train Loss: 0.020907418595419988\n",
      "Val Loss: 0.021388905467810453\n",
      "Starting epoch 3215\n",
      "Train Loss: 0.020922690629959106\n",
      "Val Loss: 0.020917306343714397\n",
      "Starting epoch 3216\n",
      "Train Loss: 0.021473086542553373\n",
      "Val Loss: 0.021374510946097196\n",
      "Starting epoch 3217\n",
      "Train Loss: 0.02136562709455137\n",
      "Val Loss: 0.02145863241619534\n",
      "Starting epoch 3218\n",
      "Train Loss: 0.020910326529432227\n",
      "Val Loss: 0.020911045096538686\n",
      "Starting epoch 3219\n",
      "Train Loss: 0.02090681040728534\n",
      "Val Loss: 0.020913307865460713\n",
      "Starting epoch 3220\n",
      "Train Loss: 0.020962913279180175\n",
      "Val Loss: 0.020919670661290485\n",
      "Starting epoch 3221\n",
      "Train Loss: 0.020954420169194538\n",
      "Val Loss: 0.02097467967757472\n",
      "Starting epoch 3222\n",
      "Train Loss: 0.020901894679775945\n",
      "Val Loss: 0.020908965004814997\n",
      "Starting epoch 3223\n",
      "Train Loss: 0.021394607645493967\n",
      "Val Loss: 0.02091137733724382\n",
      "Starting epoch 3224\n",
      "Train Loss: 0.020906521766274062\n",
      "Val Loss: 0.020910505343366553\n",
      "Starting epoch 3225\n",
      "Train Loss: 0.020916418344886216\n",
      "Val Loss: 0.02097823719183604\n",
      "Starting epoch 3226\n",
      "Train Loss: 0.020911947444633202\n",
      "Val Loss: 0.020901520495061523\n",
      "Starting epoch 3227\n",
      "Train Loss: 0.020909943514400058\n",
      "Val Loss: 0.020912949685697204\n",
      "Starting epoch 3228\n",
      "Train Loss: 0.02101660105917189\n",
      "Val Loss: 0.02090842856301202\n",
      "Starting epoch 3229\n",
      "Train Loss: 0.020939738110259728\n",
      "Val Loss: 0.020917205346955195\n",
      "Starting epoch 3230\n",
      "Train Loss: 0.020903520010135793\n",
      "Val Loss: 0.02093351549572415\n",
      "Starting epoch 3231\n",
      "Train Loss: 0.020916440972575435\n",
      "Val Loss: 0.020902947143272118\n",
      "Starting epoch 3232\n",
      "Train Loss: 0.020925562690805505\n",
      "Val Loss: 0.020909137747905874\n",
      "Starting epoch 3233\n",
      "Train Loss: 0.020918901871751855\n",
      "Val Loss: 0.02092459245964333\n",
      "Starting epoch 3234\n",
      "Train Loss: 0.02138096480457871\n",
      "Val Loss: 0.020913434249383432\n",
      "Starting epoch 3235\n",
      "Train Loss: 0.02100242950298168\n",
      "Val Loss: 0.020925583662810148\n",
      "Starting epoch 3236\n",
      "Train Loss: 0.021375085468645447\n",
      "Val Loss: 0.020917495643651043\n",
      "Starting epoch 3237\n",
      "Train Loss: 0.020931357034930476\n",
      "Val Loss: 0.020998046905906113\n",
      "Starting epoch 3238\n",
      "Train Loss: 0.020928364661004808\n",
      "Val Loss: 0.020903203774381568\n",
      "Starting epoch 3239\n",
      "Train Loss: 0.02091295023759206\n",
      "Val Loss: 0.020953062507841323\n",
      "Starting epoch 3240\n",
      "Train Loss: 0.02098619717138785\n",
      "Val Loss: 0.021362608229672467\n",
      "Starting epoch 3241\n",
      "Train Loss: 0.02090789101741932\n",
      "Val Loss: 0.0209113668512415\n",
      "Starting epoch 3242\n",
      "Train Loss: 0.020910404898502207\n",
      "Val Loss: 0.02090873431276392\n",
      "Starting epoch 3243\n",
      "Train Loss: 0.020937270588345\n",
      "Val Loss: 0.020968758949527034\n",
      "Starting epoch 3244\n",
      "Train Loss: 0.020968848908389057\n",
      "Val Loss: 0.020916099901552552\n",
      "Starting epoch 3245\n",
      "Train Loss: 0.021002701035252324\n",
      "Val Loss: 0.021022575872915762\n",
      "Starting epoch 3246\n",
      "Train Loss: 0.020917159539681894\n",
      "Val Loss: 0.020914674357131676\n",
      "Starting epoch 3247\n",
      "Train Loss: 0.020910399379553617\n",
      "Val Loss: 0.02090507635363826\n",
      "Starting epoch 3248\n",
      "Train Loss: 0.020902921204213745\n",
      "Val Loss: 0.020912983903178462\n",
      "Starting epoch 3249\n",
      "Train Loss: 0.020925814906756084\n",
      "Val Loss: 0.02092790769206153\n",
      "Starting epoch 3250\n",
      "Train Loss: 0.02090665973998882\n",
      "Val Loss: 0.020943345846953215\n",
      "Starting epoch 3251\n",
      "Train Loss: 0.020974668087782682\n",
      "Val Loss: 0.021052787149394\n",
      "Starting epoch 3252\n",
      "Train Loss: 0.020994422612366854\n",
      "Val Loss: 0.02090603554690326\n",
      "Starting epoch 3253\n",
      "Train Loss: 0.020942509174346924\n",
      "Val Loss: 0.020916469671108103\n",
      "Starting epoch 3254\n",
      "Train Loss: 0.02090621049757357\n",
      "Val Loss: 0.0209075262149175\n",
      "Starting epoch 3255\n",
      "Train Loss: 0.021378040865615563\n",
      "Val Loss: 0.020901232957839966\n",
      "Starting epoch 3256\n",
      "Train Loss: 0.020923520127932232\n",
      "Val Loss: 0.020925713909996882\n",
      "Starting epoch 3257\n",
      "Train Loss: 0.02144811992292051\n",
      "Val Loss: 0.0209042661719852\n",
      "Starting epoch 3258\n",
      "Train Loss: 0.020900710313408462\n",
      "Val Loss: 0.020946404448261968\n",
      "Starting epoch 3259\n",
      "Train Loss: 0.020920024977789983\n",
      "Val Loss: 0.02091330952114529\n",
      "Starting epoch 3260\n",
      "Train Loss: 0.02091908068568618\n",
      "Val Loss: 0.02094098925590515\n",
      "Starting epoch 3261\n",
      "Train Loss: 0.020994462348796702\n",
      "Val Loss: 0.020924539477736863\n",
      "Starting epoch 3262\n",
      "Train Loss: 0.020997675480665983\n",
      "Val Loss: 0.020900294736579613\n",
      "Starting epoch 3263\n",
      "Train Loss: 0.020927877337844285\n",
      "Val Loss: 0.02143631985893956\n",
      "Starting epoch 3264\n",
      "Train Loss: 0.02092619350662938\n",
      "Val Loss: 0.02100897773548409\n",
      "Starting epoch 3265\n",
      "Train Loss: 0.020900041968734177\n",
      "Val Loss: 0.020991923632445158\n",
      "Starting epoch 3266\n",
      "Train Loss: 0.020940173555303504\n",
      "Val Loss: 0.020909718341297574\n",
      "Starting epoch 3267\n",
      "Train Loss: 0.020914759348939965\n",
      "Val Loss: 0.02103470265865326\n",
      "Starting epoch 3268\n",
      "Train Loss: 0.021006868945227727\n",
      "Val Loss: 0.0209140463007821\n",
      "Starting epoch 3269\n",
      "Train Loss: 0.02091067643077285\n",
      "Val Loss: 0.020914952512140626\n",
      "Starting epoch 3270\n",
      "Train Loss: 0.02143977306507252\n",
      "Val Loss: 0.02138028100684837\n",
      "Starting epoch 3271\n",
      "Train Loss: 0.020968215884985746\n",
      "Val Loss: 0.020931350412192167\n",
      "Starting epoch 3272\n",
      "Train Loss: 0.02090111154097098\n",
      "Val Loss: 0.020930314505541767\n",
      "Starting epoch 3273\n",
      "Train Loss: 0.020933603247006733\n",
      "Val Loss: 0.020910497616838525\n",
      "Starting epoch 3274\n",
      "Train Loss: 0.020914458566241793\n",
      "Val Loss: 0.02095849922409764\n",
      "Starting epoch 3275\n",
      "Train Loss: 0.020977138369171706\n",
      "Val Loss: 0.020934442679087322\n",
      "Starting epoch 3276\n",
      "Train Loss: 0.02092201621444137\n",
      "Val Loss: 0.021475555720152677\n",
      "Starting epoch 3277\n",
      "Train Loss: 0.02094337178601159\n",
      "Val Loss: 0.020936412943734065\n",
      "Starting epoch 3278\n",
      "Train Loss: 0.020903781608298973\n",
      "Val Loss: 0.02093634616445612\n",
      "Starting epoch 3279\n",
      "Train Loss: 0.0210076035172851\n",
      "Val Loss: 0.021361145156401175\n",
      "Starting epoch 3280\n",
      "Train Loss: 0.020910880631870694\n",
      "Val Loss: 0.021008367891664857\n",
      "Starting epoch 3281\n",
      "Train Loss: 0.021011331015162997\n",
      "Val Loss: 0.02100374025327188\n",
      "Starting epoch 3282\n",
      "Train Loss: 0.020901347751970643\n",
      "Val Loss: 0.020923858991375676\n",
      "Starting epoch 3283\n",
      "Train Loss: 0.02091391881306966\n",
      "Val Loss: 0.020918859927742568\n",
      "Starting epoch 3284\n",
      "Train Loss: 0.02092851643209104\n",
      "Val Loss: 0.020998034764219214\n",
      "Starting epoch 3285\n",
      "Train Loss: 0.02098243987118756\n",
      "Val Loss: 0.02089689506424798\n",
      "Starting epoch 3286\n",
      "Train Loss: 0.021353801091512043\n",
      "Val Loss: 0.020929143384650902\n",
      "Starting epoch 3287\n",
      "Train Loss: 0.020926883927098027\n",
      "Val Loss: 0.02090602892416495\n",
      "Starting epoch 3288\n",
      "Train Loss: 0.020920156328766433\n",
      "Val Loss: 0.020952154088903358\n",
      "Starting epoch 3289\n",
      "Train Loss: 0.020905209912194148\n",
      "Val Loss: 0.021353622277577717\n",
      "Starting epoch 3290\n",
      "Train Loss: 0.020900346062801504\n",
      "Val Loss: 0.020978013674418133\n",
      "Starting epoch 3291\n",
      "Train Loss: 0.020914914983290213\n",
      "Val Loss: 0.02097857881475378\n",
      "Starting epoch 3292\n",
      "Train Loss: 0.021358933713701036\n",
      "Val Loss: 0.021421822684782522\n",
      "Starting epoch 3293\n",
      "Train Loss: 0.021375230616993375\n",
      "Val Loss: 0.020917826780566463\n",
      "Starting epoch 3294\n",
      "Train Loss: 0.020899985675458557\n",
      "Val Loss: 0.021382425670270568\n",
      "Starting epoch 3295\n",
      "Train Loss: 0.020911889495673002\n",
      "Val Loss: 0.02089815890347516\n",
      "Starting epoch 3296\n",
      "Train Loss: 0.021373390047638503\n",
      "Val Loss: 0.020930850947344745\n",
      "Starting epoch 3297\n",
      "Train Loss: 0.020906262375690318\n",
      "Val Loss: 0.020934097744800425\n",
      "Starting epoch 3298\n",
      "Train Loss: 0.020901876467245596\n",
      "Val Loss: 0.020899860395325556\n",
      "Starting epoch 3299\n",
      "Train Loss: 0.020894092542153818\n",
      "Val Loss: 0.020977202388975356\n",
      "Starting epoch 3300\n",
      "Train Loss: 0.02097436123424106\n",
      "Val Loss: 0.020911288482171518\n",
      "Starting epoch 3301\n",
      "Train Loss: 0.02095528498843864\n",
      "Val Loss: 0.020923225967972366\n",
      "Starting epoch 3302\n",
      "Train Loss: 0.02093824302708661\n",
      "Val Loss: 0.020897626324936195\n",
      "Starting epoch 3303\n",
      "Train Loss: 0.02089341812663608\n",
      "Val Loss: 0.02090536168328038\n",
      "Starting epoch 3304\n",
      "Train Loss: 0.02091209480056056\n",
      "Val Loss: 0.021003864429615163\n",
      "Starting epoch 3305\n",
      "Train Loss: 0.020900244514147442\n",
      "Val Loss: 0.020898326679512306\n",
      "Starting epoch 3306\n",
      "Train Loss: 0.021026703494566458\n",
      "Val Loss: 0.02091016979129226\n",
      "Starting epoch 3307\n",
      "Train Loss: 0.02092189148620323\n",
      "Val Loss: 0.020892247005745216\n",
      "Starting epoch 3308\n",
      "Train Loss: 0.020937597310101544\n",
      "Val Loss: 0.021398271675463074\n",
      "Starting epoch 3309\n",
      "Train Loss: 0.020926368457299692\n",
      "Val Loss: 0.020921785522390296\n",
      "Starting epoch 3310\n",
      "Train Loss: 0.020960313302499277\n",
      "Val Loss: 0.021357972312856605\n",
      "Starting epoch 3311\n",
      "Train Loss: 0.021012810093385202\n",
      "Val Loss: 0.020973578095436096\n",
      "Starting epoch 3312\n",
      "Train Loss: 0.020910200145509508\n",
      "Val Loss: 0.020907423010578862\n",
      "Starting epoch 3313\n",
      "Train Loss: 0.02090461000248238\n",
      "Val Loss: 0.02091083096133338\n",
      "Starting epoch 3314\n",
      "Train Loss: 0.020987515648206074\n",
      "Val Loss: 0.020916991211749888\n",
      "Starting epoch 3315\n",
      "Train Loss: 0.021378534811514395\n",
      "Val Loss: 0.020897946423954435\n",
      "Starting epoch 3316\n",
      "Train Loss: 0.020899517116723238\n",
      "Val Loss: 0.020947716854236745\n",
      "Starting epoch 3317\n",
      "Train Loss: 0.02135756832581979\n",
      "Val Loss: 0.02144757354701007\n",
      "Starting epoch 3318\n",
      "Train Loss: 0.02135424315929413\n",
      "Val Loss: 0.020916413377832482\n",
      "Starting epoch 3319\n",
      "Train Loss: 0.020896488317736873\n",
      "Val Loss: 0.020893632261841384\n",
      "Starting epoch 3320\n",
      "Train Loss: 0.02090342894748405\n",
      "Val Loss: 0.020968554748429194\n",
      "Starting epoch 3321\n",
      "Train Loss: 0.020899700345816435\n",
      "Val Loss: 0.02090887118268896\n",
      "Starting epoch 3322\n",
      "Train Loss: 0.02137640615304311\n",
      "Val Loss: 0.02089972076592622\n",
      "Starting epoch 3323\n",
      "Train Loss: 0.020891647647928308\n",
      "Val Loss: 0.020972246373141254\n",
      "Starting epoch 3324\n",
      "Train Loss: 0.02097418462788617\n",
      "Val Loss: 0.020912520311496877\n",
      "Starting epoch 3325\n",
      "Train Loss: 0.0213727542647609\n",
      "Val Loss: 0.020912116324460064\n",
      "Starting epoch 3326\n",
      "Train Loss: 0.020895101957850985\n",
      "Val Loss: 0.020990449521276686\n",
      "Starting epoch 3327\n",
      "Train Loss: 0.020923208307336877\n",
      "Val Loss: 0.020969936141261348\n",
      "Starting epoch 3328\n",
      "Train Loss: 0.020907787261185824\n",
      "Val Loss: 0.020962389530958952\n",
      "Starting epoch 3329\n",
      "Train Loss: 0.02099476092391544\n",
      "Val Loss: 0.020889210480230826\n",
      "Starting epoch 3330\n",
      "Train Loss: 0.020894623465008207\n",
      "Val Loss: 0.021000370383262634\n",
      "Starting epoch 3331\n",
      "Train Loss: 0.02089873508170799\n",
      "Val Loss: 0.02094375921620263\n",
      "Starting epoch 3332\n",
      "Train Loss: 0.020896787996645325\n",
      "Val Loss: 0.021010556706675777\n",
      "Starting epoch 3333\n",
      "Train Loss: 0.020894165392275208\n",
      "Val Loss: 0.020895876266338206\n",
      "Starting epoch 3334\n",
      "Train Loss: 0.020912904982213622\n",
      "Val Loss: 0.021437288986312017\n",
      "Starting epoch 3335\n",
      "Train Loss: 0.02091135581334432\n",
      "Val Loss: 0.020911722823425575\n",
      "Starting epoch 3336\n",
      "Train Loss: 0.020895753193784644\n",
      "Val Loss: 0.020920294302481192\n",
      "Starting epoch 3337\n",
      "Train Loss: 0.02090880881856989\n",
      "Val Loss: 0.020954730334105314\n",
      "Starting epoch 3338\n",
      "Train Loss: 0.020902955421695003\n",
      "Val Loss: 0.021368393191584834\n",
      "Starting epoch 3339\n",
      "Train Loss: 0.020896976744687115\n",
      "Val Loss: 0.020890623331069946\n",
      "Starting epoch 3340\n",
      "Train Loss: 0.02090661393271552\n",
      "Val Loss: 0.02090745226100639\n",
      "Starting epoch 3341\n",
      "Train Loss: 0.020898161662949458\n",
      "Val Loss: 0.020888031080917076\n",
      "Starting epoch 3342\n",
      "Train Loss: 0.02088849467259866\n",
      "Val Loss: 0.02098728385236528\n",
      "Starting epoch 3343\n",
      "Train Loss: 0.020914253261354234\n",
      "Val Loss: 0.02091243863105774\n",
      "Starting epoch 3344\n",
      "Train Loss: 0.021382966527232417\n",
      "Val Loss: 0.02089355499656112\n",
      "Starting epoch 3345\n",
      "Train Loss: 0.020909495927669382\n",
      "Val Loss: 0.020985508958498638\n",
      "Starting epoch 3346\n",
      "Train Loss: 0.02096410702776026\n",
      "Val Loss: 0.02091061461854864\n",
      "Starting epoch 3347\n",
      "Train Loss: 0.02089406770688516\n",
      "Val Loss: 0.020900089983586913\n",
      "Starting epoch 3348\n",
      "Train Loss: 0.02090033557679918\n",
      "Val Loss: 0.02089621016272792\n",
      "Starting epoch 3349\n",
      "Train Loss: 0.021018962617273682\n",
      "Val Loss: 0.02089272494669314\n",
      "Starting epoch 3350\n",
      "Train Loss: 0.0208990353125113\n",
      "Val Loss: 0.021465768968617474\n",
      "Starting epoch 3351\n",
      "Train Loss: 0.02090235937524725\n",
      "Val Loss: 0.020888537720397667\n",
      "Starting epoch 3352\n",
      "Train Loss: 0.020894741570508038\n",
      "Val Loss: 0.0209151280147058\n",
      "Starting epoch 3353\n",
      "Train Loss: 0.020934281525788485\n",
      "Val Loss: 0.020950356567347492\n",
      "Starting epoch 3354\n",
      "Train Loss: 0.020893170877739235\n",
      "Val Loss: 0.02092353116582941\n",
      "Starting epoch 3355\n",
      "Train Loss: 0.02088876951623846\n",
      "Val Loss: 0.02139578428533342\n",
      "Starting epoch 3356\n",
      "Train Loss: 0.020899077808415448\n",
      "Val Loss: 0.020906634352825307\n",
      "Starting epoch 3357\n",
      "Train Loss: 0.021349548741623207\n",
      "Val Loss: 0.02089392531801153\n",
      "Starting epoch 3358\n",
      "Train Loss: 0.021436875617062603\n",
      "Val Loss: 0.020915304621060688\n",
      "Starting epoch 3359\n",
      "Train Loss: 0.02090252991075869\n",
      "Val Loss: 0.020899302981517934\n",
      "Starting epoch 3360\n",
      "Train Loss: 0.020895768094945838\n",
      "Val Loss: 0.020984816330450552\n",
      "Starting epoch 3361\n",
      "Train Loss: 0.020973389899289166\n",
      "Val Loss: 0.02134864584163383\n",
      "Starting epoch 3362\n",
      "Train Loss: 0.020898845460679796\n",
      "Val Loss: 0.020933181599334435\n",
      "Starting epoch 3363\n",
      "Train Loss: 0.0209258618178191\n",
      "Val Loss: 0.020977882875336543\n",
      "Starting epoch 3364\n",
      "Train Loss: 0.020927837049519574\n",
      "Val Loss: 0.021359161646277817\n",
      "Starting epoch 3365\n",
      "Train Loss: 0.020909278481094924\n",
      "Val Loss: 0.02091442655633997\n",
      "Starting epoch 3366\n",
      "Train Loss: 0.02091273389480732\n",
      "Val Loss: 0.020902930586426345\n",
      "Starting epoch 3367\n",
      "Train Loss: 0.020990602948047495\n",
      "Val Loss: 0.020894691348075867\n",
      "Starting epoch 3368\n",
      "Train Loss: 0.02139025209126649\n",
      "Val Loss: 0.02090634847128833\n",
      "Starting epoch 3369\n",
      "Train Loss: 0.02098887496524387\n",
      "Val Loss: 0.02136114184503202\n",
      "Starting epoch 3370\n",
      "Train Loss: 0.020907644320417335\n",
      "Val Loss: 0.02090456419520908\n",
      "Starting epoch 3371\n",
      "Train Loss: 0.020904048725410743\n",
      "Val Loss: 0.020957208893917226\n",
      "Starting epoch 3372\n",
      "Train Loss: 0.020921329657236736\n",
      "Val Loss: 0.02089304283813194\n",
      "Starting epoch 3373\n",
      "Train Loss: 0.02089389165242513\n",
      "Val Loss: 0.0209009172739806\n",
      "Starting epoch 3374\n",
      "Train Loss: 0.020892168084780376\n",
      "Val Loss: 0.02097528510623508\n",
      "Starting epoch 3375\n",
      "Train Loss: 0.021005355649524264\n",
      "Val Loss: 0.02090614206261105\n",
      "Starting epoch 3376\n",
      "Train Loss: 0.020957441793547735\n",
      "Val Loss: 0.020897793549078482\n",
      "Starting epoch 3377\n",
      "Train Loss: 0.020898305707507663\n",
      "Val Loss: 0.02136608240781007\n",
      "Starting epoch 3378\n",
      "Train Loss: 0.02090594779562067\n",
      "Val Loss: 0.02090648975637224\n",
      "Starting epoch 3379\n",
      "Train Loss: 0.02090517900608204\n",
      "Val Loss: 0.020886174506611295\n",
      "Starting epoch 3380\n",
      "Train Loss: 0.02090634019286544\n",
      "Val Loss: 0.020911848103558575\n",
      "Starting epoch 3381\n",
      "Train Loss: 0.020904250167034292\n",
      "Val Loss: 0.020889557622097158\n",
      "Starting epoch 3382\n",
      "Train Loss: 0.020886214243041143\n",
      "Val Loss: 0.0209025486751839\n",
      "Starting epoch 3383\n",
      "Train Loss: 0.020887129836612277\n",
      "Val Loss: 0.020892675276155823\n",
      "Starting epoch 3384\n",
      "Train Loss: 0.020984034847330163\n",
      "Val Loss: 0.020954420169194538\n",
      "Starting epoch 3385\n",
      "Train Loss: 0.020947256573924312\n",
      "Val Loss: 0.020908862352371216\n",
      "Starting epoch 3386\n",
      "Train Loss: 0.02088435380547135\n",
      "Val Loss: 0.020957483185662165\n",
      "Starting epoch 3387\n",
      "Train Loss: 0.020939294386793067\n",
      "Val Loss: 0.020905514006261474\n",
      "Starting epoch 3388\n",
      "Train Loss: 0.020885412339810974\n",
      "Val Loss: 0.020900351029855234\n",
      "Starting epoch 3389\n",
      "Train Loss: 0.02090228486944128\n",
      "Val Loss: 0.020900305774476793\n",
      "Starting epoch 3390\n",
      "Train Loss: 0.02094682499214455\n",
      "Val Loss: 0.020900076186215436\n",
      "Starting epoch 3391\n",
      "Train Loss: 0.02090503661720841\n",
      "Val Loss: 0.020884840576737014\n",
      "Starting epoch 3392\n",
      "Train Loss: 0.020890638784126\n",
      "Val Loss: 0.02088612649175856\n",
      "Starting epoch 3393\n",
      "Train Loss: 0.020921428446416503\n",
      "Val Loss: 0.020905820307908236\n",
      "Starting epoch 3394\n",
      "Train Loss: 0.020887690009894194\n",
      "Val Loss: 0.02088784067719071\n",
      "Starting epoch 3395\n",
      "Train Loss: 0.020886430033931026\n",
      "Val Loss: 0.021352836931193317\n",
      "Starting epoch 3396\n",
      "Train Loss: 0.021347656294151588\n",
      "Val Loss: 0.020915050197530677\n",
      "Starting epoch 3397\n",
      "Train Loss: 0.02088843948311276\n",
      "Val Loss: 0.021352946758270264\n",
      "Starting epoch 3398\n",
      "Train Loss: 0.02088639912781892\n",
      "Val Loss: 0.020900439333032678\n",
      "Starting epoch 3399\n",
      "Train Loss: 0.02093060425034276\n",
      "Val Loss: 0.020965734565699543\n",
      "Starting epoch 3400\n",
      "Train Loss: 0.020995385668895864\n",
      "Val Loss: 0.02091153904243752\n",
      "Starting epoch 3401\n",
      "Train Loss: 0.020933939350975886\n",
      "Val Loss: 0.020974238713582356\n",
      "Starting epoch 3402\n",
      "Train Loss: 0.020904782745573256\n",
      "Val Loss: 0.021344678269492254\n",
      "Starting epoch 3403\n",
      "Train Loss: 0.02097928413638362\n",
      "Val Loss: 0.020886967579523723\n",
      "Starting epoch 3404\n",
      "Train Loss: 0.02089879082308875\n",
      "Val Loss: 0.020934280973893625\n",
      "Starting epoch 3405\n",
      "Train Loss: 0.021466247461460256\n",
      "Val Loss: 0.021348750701657048\n",
      "Starting epoch 3406\n",
      "Train Loss: 0.02097840220839889\n",
      "Val Loss: 0.020890297161208257\n",
      "Starting epoch 3407\n",
      "Train Loss: 0.020896701901047317\n",
      "Val Loss: 0.021426860932950622\n",
      "Starting epoch 3408\n",
      "Train Loss: 0.02097226017051273\n",
      "Val Loss: 0.020901471376419067\n",
      "Starting epoch 3409\n",
      "Train Loss: 0.020896901686986286\n",
      "Val Loss: 0.020899654538543137\n",
      "Starting epoch 3410\n",
      "Train Loss: 0.02088920220180794\n",
      "Val Loss: 0.0214186774359809\n",
      "Starting epoch 3411\n",
      "Train Loss: 0.02089949724850831\n",
      "Val Loss: 0.020922858405996253\n",
      "Starting epoch 3412\n",
      "Train Loss: 0.020892570968027466\n",
      "Val Loss: 0.020888299853713425\n",
      "Starting epoch 3413\n",
      "Train Loss: 0.02090355422761705\n",
      "Val Loss: 0.02088644990214595\n",
      "Starting epoch 3414\n",
      "Train Loss: 0.02141854056605586\n",
      "Val Loss: 0.02096068803910856\n",
      "Starting epoch 3415\n",
      "Train Loss: 0.02088725953190415\n",
      "Val Loss: 0.020963373559492605\n",
      "Starting epoch 3416\n",
      "Train Loss: 0.020960438030737417\n",
      "Val Loss: 0.020882209693944012\n",
      "Starting epoch 3417\n",
      "Train Loss: 0.02134361421620404\n",
      "Val Loss: 0.02088578321315624\n",
      "Starting epoch 3418\n",
      "Train Loss: 0.02096803762294628\n",
      "Val Loss: 0.020924182401763067\n",
      "Starting epoch 3419\n",
      "Train Loss: 0.020881455805566575\n",
      "Val Loss: 0.021346556919592398\n",
      "Starting epoch 3420\n",
      "Train Loss: 0.020937688372753286\n",
      "Val Loss: 0.02090364749784823\n",
      "Starting epoch 3421\n",
      "Train Loss: 0.02089341260768749\n",
      "Val Loss: 0.020931871952833952\n",
      "Starting epoch 3422\n",
      "Train Loss: 0.02102350029680464\n",
      "Val Loss: 0.02088225218984816\n",
      "Starting epoch 3423\n",
      "Train Loss: 0.020885884761810303\n",
      "Val Loss: 0.02089313941973227\n",
      "Starting epoch 3424\n",
      "Train Loss: 0.02098452161859583\n",
      "Val Loss: 0.021413815242272836\n",
      "Starting epoch 3425\n",
      "Train Loss: 0.020879680911699932\n",
      "Val Loss: 0.020921966543904057\n",
      "Starting epoch 3426\n",
      "Train Loss: 0.0209666578857987\n",
      "Val Loss: 0.020889571971363492\n",
      "Starting epoch 3427\n",
      "Train Loss: 0.020918760586667945\n",
      "Val Loss: 0.020954803184226708\n",
      "Starting epoch 3428\n",
      "Train Loss: 0.0208942625257704\n",
      "Val Loss: 0.020897069463023433\n",
      "Starting epoch 3429\n",
      "Train Loss: 0.020892092475184688\n",
      "Val Loss: 0.02088096296345746\n",
      "Starting epoch 3430\n",
      "Train Loss: 0.020886937225306476\n",
      "Val Loss: 0.0208921206218225\n",
      "Starting epoch 3431\n",
      "Train Loss: 0.020911100286024588\n",
      "Val Loss: 0.020887316928969488\n",
      "Starting epoch 3432\n",
      "Train Loss: 0.020886469770360877\n",
      "Val Loss: 0.021361307965384588\n",
      "Starting epoch 3433\n",
      "Train Loss: 0.02088315177846838\n",
      "Val Loss: 0.02136379259603995\n",
      "Starting epoch 3434\n",
      "Train Loss: 0.021356649972774363\n",
      "Val Loss: 0.020944342569068627\n",
      "Starting epoch 3435\n",
      "Train Loss: 0.02096210088994768\n",
      "Val Loss: 0.020887592876399005\n",
      "Starting epoch 3436\n",
      "Train Loss: 0.02096500164932675\n",
      "Val Loss: 0.020886133666391724\n",
      "Starting epoch 3437\n",
      "Train Loss: 0.020883866482310824\n",
      "Val Loss: 0.020891901519563463\n",
      "Starting epoch 3438\n",
      "Train Loss: 0.020971514560558176\n",
      "Val Loss: 0.020877734378532128\n",
      "Starting epoch 3439\n",
      "Train Loss: 0.020893578728040058\n",
      "Val Loss: 0.020901072356435988\n",
      "Starting epoch 3440\n",
      "Train Loss: 0.02090370379112385\n",
      "Val Loss: 0.020962612496482\n",
      "Starting epoch 3441\n",
      "Train Loss: 0.020930127413184556\n",
      "Val Loss: 0.02095311493785293\n",
      "Starting epoch 3442\n",
      "Train Loss: 0.020892173603728966\n",
      "Val Loss: 0.020886861615710788\n",
      "Starting epoch 3443\n",
      "Train Loss: 0.021031100992803222\n",
      "Val Loss: 0.020981487852555734\n",
      "Starting epoch 3444\n",
      "Train Loss: 0.020876887771818373\n",
      "Val Loss: 0.020888424030056706\n",
      "Starting epoch 3445\n",
      "Train Loss: 0.020877279065273428\n",
      "Val Loss: 0.020895724495251972\n",
      "Starting epoch 3446\n",
      "Train Loss: 0.020975694612220482\n",
      "Val Loss: 0.020896321093594586\n",
      "Starting epoch 3447\n",
      "Train Loss: 0.020882935987578496\n",
      "Val Loss: 0.02087964834990325\n",
      "Starting epoch 3448\n",
      "Train Loss: 0.020908336948465417\n",
      "Val Loss: 0.020875609583324857\n",
      "Starting epoch 3449\n",
      "Train Loss: 0.020963402258025274\n",
      "Val Loss: 0.02090504765510559\n",
      "Starting epoch 3450\n",
      "Train Loss: 0.020884681631017615\n",
      "Val Loss: 0.020885000626246136\n",
      "Starting epoch 3451\n",
      "Train Loss: 0.020939504106839497\n",
      "Val Loss: 0.02090122964647081\n",
      "Starting epoch 3452\n",
      "Train Loss: 0.020899661161281443\n",
      "Val Loss: 0.020895576035534894\n",
      "Starting epoch 3453\n",
      "Train Loss: 0.020969049246222886\n",
      "Val Loss: 0.020898321160563716\n",
      "Starting epoch 3454\n",
      "Train Loss: 0.020991878928961576\n",
      "Val Loss: 0.021341088745329116\n",
      "Starting epoch 3455\n",
      "Train Loss: 0.021374436992186087\n",
      "Val Loss: 0.020962247693980182\n",
      "Starting epoch 3456\n",
      "Train Loss: 0.020905021164152358\n",
      "Val Loss: 0.02089114431981687\n",
      "Starting epoch 3457\n",
      "Train Loss: 0.021390025814374287\n",
      "Val Loss: 0.02088254083085943\n",
      "Starting epoch 3458\n",
      "Train Loss: 0.02095692246048539\n",
      "Val Loss: 0.02088890031532005\n",
      "Starting epoch 3459\n",
      "Train Loss: 0.0213608686570768\n",
      "Val Loss: 0.02089749883722376\n",
      "Starting epoch 3460\n",
      "Train Loss: 0.020881181513821637\n",
      "Val Loss: 0.020950906254627085\n",
      "Starting epoch 3461\n",
      "Train Loss: 0.02134788312293865\n",
      "Val Loss: 0.020907690127690632\n",
      "Starting epoch 3462\n",
      "Train Loss: 0.020961041803713196\n",
      "Val Loss: 0.020905140925336768\n",
      "Starting epoch 3463\n",
      "Train Loss: 0.02087713998776895\n",
      "Val Loss: 0.02090134444060149\n",
      "Starting epoch 3464\n",
      "Train Loss: 0.020912093144875986\n",
      "Val Loss: 0.02088629537158542\n",
      "Starting epoch 3465\n",
      "Train Loss: 0.02088076538509793\n",
      "Val Loss: 0.020945009809953195\n",
      "Starting epoch 3466\n",
      "Train Loss: 0.020978480025574012\n",
      "Val Loss: 0.020948080552948847\n",
      "Starting epoch 3467\n",
      "Train Loss: 0.020921551518970065\n",
      "Val Loss: 0.020951232976383634\n",
      "Starting epoch 3468\n",
      "Train Loss: 0.021435239800700435\n",
      "Val Loss: 0.02090304648434674\n",
      "Starting epoch 3469\n",
      "Train Loss: 0.020920565282856976\n",
      "Val Loss: 0.020903525529084383\n",
      "Starting epoch 3470\n",
      "Train Loss: 0.020883530930236534\n",
      "Val Loss: 0.020890990893046062\n",
      "Starting epoch 3471\n",
      "Train Loss: 0.02096887484744743\n",
      "Val Loss: 0.02134562752864979\n",
      "Starting epoch 3472\n",
      "Train Loss: 0.02089388558158168\n",
      "Val Loss: 0.020888994137446087\n",
      "Starting epoch 3473\n",
      "Train Loss: 0.02088165393582097\n",
      "Val Loss: 0.020882038054642855\n",
      "Starting epoch 3474\n",
      "Train Loss: 0.02133781490502534\n",
      "Val Loss: 0.020879912155645865\n",
      "Starting epoch 3475\n",
      "Train Loss: 0.020895062773315994\n",
      "Val Loss: 0.020878377887937758\n",
      "Starting epoch 3476\n",
      "Train Loss: 0.020875229327766982\n",
      "Val Loss: 0.020908423595958285\n",
      "Starting epoch 3477\n",
      "Train Loss: 0.020909662048021953\n",
      "Val Loss: 0.020882481226214656\n",
      "Starting epoch 3478\n",
      "Train Loss: 0.020890533372207924\n",
      "Val Loss: 0.02087777908201571\n",
      "Starting epoch 3479\n",
      "Train Loss: 0.02134757019855358\n",
      "Val Loss: 0.020897421020048636\n",
      "Starting epoch 3480\n",
      "Train Loss: 0.020910265269102873\n",
      "Val Loss: 0.020907188455263775\n",
      "Starting epoch 3481\n",
      "Train Loss: 0.021378696516708092\n",
      "Val Loss: 0.02142514067667502\n",
      "Starting epoch 3482\n",
      "Train Loss: 0.020905993602893972\n",
      "Val Loss: 0.02097241911623213\n",
      "Starting epoch 3483\n",
      "Train Loss: 0.020875477680453548\n",
      "Val Loss: 0.020987100623272085\n",
      "Starting epoch 3484\n",
      "Train Loss: 0.02087420445901376\n",
      "Val Loss: 0.020953305341579295\n",
      "Starting epoch 3485\n",
      "Train Loss: 0.020882879694302876\n",
      "Val Loss: 0.02089903144924729\n",
      "Starting epoch 3486\n",
      "Train Loss: 0.02097051618275819\n",
      "Val Loss: 0.020886310272746615\n",
      "Starting epoch 3487\n",
      "Train Loss: 0.020894174774487812\n",
      "Val Loss: 0.020872051517168682\n",
      "Starting epoch 3488\n",
      "Train Loss: 0.020872493033055908\n",
      "Val Loss: 0.020876301107583223\n",
      "Starting epoch 3489\n",
      "Train Loss: 0.02096246624434436\n",
      "Val Loss: 0.02135118897314425\n",
      "Starting epoch 3490\n",
      "Train Loss: 0.020940188456464698\n",
      "Val Loss: 0.020899996161460876\n",
      "Starting epoch 3491\n",
      "Train Loss: 0.020899523187566688\n",
      "Val Loss: 0.02088559004995558\n",
      "Starting epoch 3492\n",
      "Train Loss: 0.020902312464184232\n",
      "Val Loss: 0.02087485348736798\n",
      "Starting epoch 3493\n",
      "Train Loss: 0.020880480607350666\n",
      "Val Loss: 0.020875188487547415\n",
      "Starting epoch 3494\n",
      "Train Loss: 0.021357553424658598\n",
      "Val Loss: 0.020892657615520335\n",
      "Starting epoch 3495\n",
      "Train Loss: 0.020905661914083693\n",
      "Val Loss: 0.021038683476271452\n",
      "Starting epoch 3496\n",
      "Train Loss: 0.02087765987272616\n",
      "Val Loss: 0.020917804152877244\n",
      "Starting epoch 3497\n",
      "Train Loss: 0.02095903566590062\n",
      "Val Loss: 0.020888010108912433\n",
      "Starting epoch 3498\n",
      "Train Loss: 0.020880710195612023\n",
      "Val Loss: 0.02087989780637953\n",
      "Starting epoch 3499\n",
      "Train Loss: 0.02089297992211801\n",
      "Val Loss: 0.020880106974531104\n",
      "Starting epoch 3500\n",
      "Train Loss: 0.020941452847586736\n",
      "Val Loss: 0.020877907121623004\n",
      "Starting epoch 3501\n",
      "Train Loss: 0.020886990207212942\n",
      "Val Loss: 0.020919490743566443\n",
      "Starting epoch 3502\n",
      "Train Loss: 0.02088941302564409\n",
      "Val Loss: 0.020870506211563392\n",
      "Starting epoch 3503\n",
      "Train Loss: 0.021336592457912588\n",
      "Val Loss: 0.020892349106294138\n",
      "Starting epoch 3504\n",
      "Train Loss: 0.020882140707086633\n",
      "Val Loss: 0.020892242038691486\n",
      "Starting epoch 3505\n",
      "Train Loss: 0.02097840772734748\n",
      "Val Loss: 0.020874252473866498\n",
      "Starting epoch 3506\n",
      "Train Loss: 0.02135080595811208\n",
      "Val Loss: 0.02087647274688438\n",
      "Starting epoch 3507\n",
      "Train Loss: 0.02087173804088875\n",
      "Val Loss: 0.02088710610513334\n",
      "Starting epoch 3508\n",
      "Train Loss: 0.02088015940454271\n",
      "Val Loss: 0.020870790437415795\n",
      "Starting epoch 3509\n",
      "Train Loss: 0.020940285589959886\n",
      "Val Loss: 0.021396687185322796\n",
      "Starting epoch 3510\n",
      "Train Loss: 0.020893796174614516\n",
      "Val Loss: 0.020875363990112587\n",
      "Starting epoch 3511\n",
      "Train Loss: 0.020880413828072725\n",
      "Val Loss: 0.020953117697327224\n",
      "Starting epoch 3512\n",
      "Train Loss: 0.02089909822852523\n",
      "Val Loss: 0.0209035266328741\n",
      "Starting epoch 3513\n",
      "Train Loss: 0.021360546350479126\n",
      "Val Loss: 0.020890032251675923\n",
      "Starting epoch 3514\n",
      "Train Loss: 0.02087407917888076\n",
      "Val Loss: 0.0209002908733156\n",
      "Starting epoch 3515\n",
      "Train Loss: 0.020884299167880305\n",
      "Val Loss: 0.020875770736623694\n",
      "Starting epoch 3516\n",
      "Train Loss: 0.02099623724266335\n",
      "Val Loss: 0.020892921421262953\n",
      "Starting epoch 3517\n",
      "Train Loss: 0.020872497448214778\n",
      "Val Loss: 0.020893392187577707\n",
      "Starting epoch 3518\n",
      "Train Loss: 0.020945801779075904\n",
      "Val Loss: 0.02089495736139792\n",
      "Starting epoch 3519\n",
      "Train Loss: 0.020887468148160865\n",
      "Val Loss: 0.020893114584463614\n",
      "Starting epoch 3520\n",
      "Train Loss: 0.020895872403074195\n",
      "Val Loss: 0.020966788132985432\n",
      "Starting epoch 3521\n",
      "Train Loss: 0.02133863667647044\n",
      "Val Loss: 0.020893154320893465\n",
      "Starting epoch 3522\n",
      "Train Loss: 0.02088275827743389\n",
      "Val Loss: 0.020881294652267738\n",
      "Starting epoch 3523\n",
      "Train Loss: 0.020874895431377268\n",
      "Val Loss: 0.020868333953398245\n",
      "Starting epoch 3524\n",
      "Train Loss: 0.020884959786026565\n",
      "Val Loss: 0.020884462528758578\n",
      "Starting epoch 3525\n",
      "Train Loss: 0.0208822273545795\n",
      "Val Loss: 0.020894589247526945\n",
      "Starting epoch 3526\n",
      "Train Loss: 0.02088695047078309\n",
      "Val Loss: 0.02087711736007973\n",
      "Starting epoch 3527\n",
      "Train Loss: 0.020870821895422758\n",
      "Val Loss: 0.020871416286185936\n",
      "Starting epoch 3528\n",
      "Train Loss: 0.020894996545932912\n",
      "Val Loss: 0.02087332308292389\n",
      "Starting epoch 3529\n",
      "Train Loss: 0.020879938094704238\n",
      "Val Loss: 0.020889757408036128\n",
      "Starting epoch 3530\n",
      "Train Loss: 0.020888084614718402\n",
      "Val Loss: 0.02087047364976671\n",
      "Starting epoch 3531\n",
      "Train Loss: 0.020896465138152794\n",
      "Val Loss: 0.020873068107499018\n",
      "Starting epoch 3532\n",
      "Train Loss: 0.020870358303741173\n",
      "Val Loss: 0.020871781088687754\n",
      "Starting epoch 3533\n",
      "Train Loss: 0.02087543132128539\n",
      "Val Loss: 0.020928356934476783\n",
      "Starting epoch 3534\n",
      "Train Loss: 0.020911986629168194\n",
      "Val Loss: 0.020878788497712877\n",
      "Starting epoch 3535\n",
      "Train Loss: 0.020944478335203947\n",
      "Val Loss: 0.02087145381503635\n",
      "Starting epoch 3536\n",
      "Train Loss: 0.020870951590714632\n",
      "Val Loss: 0.02088532789989754\n",
      "Starting epoch 3537\n",
      "Train Loss: 0.020962570000577857\n",
      "Val Loss: 0.02086771583115613\n",
      "Starting epoch 3538\n",
      "Train Loss: 0.020877617928716872\n",
      "Val Loss: 0.02086860603756375\n",
      "Starting epoch 3539\n",
      "Train Loss: 0.021424478402844182\n",
      "Val Loss: 0.020946097594720346\n",
      "Starting epoch 3540\n",
      "Train Loss: 0.020955164123464515\n",
      "Val Loss: 0.02086653146478865\n",
      "Starting epoch 3541\n",
      "Train Loss: 0.020943227741453383\n",
      "Val Loss: 0.020881975138628925\n",
      "Starting epoch 3542\n",
      "Train Loss: 0.020907921371636568\n",
      "Val Loss: 0.02089827369760584\n",
      "Starting epoch 3543\n",
      "Train Loss: 0.02087419894006517\n",
      "Val Loss: 0.02086977826224433\n",
      "Starting epoch 3544\n",
      "Train Loss: 0.02093454698721568\n",
      "Val Loss: 0.020894885615066246\n",
      "Starting epoch 3545\n",
      "Train Loss: 0.02095173464881049\n",
      "Val Loss: 0.02142274545298682\n",
      "Starting epoch 3546\n",
      "Train Loss: 0.020884499505714135\n",
      "Val Loss: 0.020954025012475473\n",
      "Starting epoch 3547\n",
      "Train Loss: 0.020907898743947346\n",
      "Val Loss: 0.020890797177950542\n",
      "Starting epoch 3548\n",
      "Train Loss: 0.02095178211176837\n",
      "Val Loss: 0.020964704177997732\n",
      "Starting epoch 3549\n",
      "Train Loss: 0.02090795890048698\n",
      "Val Loss: 0.020881860896393104\n",
      "Starting epoch 3550\n",
      "Train Loss: 0.020903087324566312\n",
      "Val Loss: 0.02094611249588154\n",
      "Starting epoch 3551\n",
      "Train Loss: 0.020866253861674556\n",
      "Val Loss: 0.020935283766852483\n",
      "Starting epoch 3552\n",
      "Train Loss: 0.020873827514825045\n",
      "Val Loss: 0.02089709981724068\n",
      "Starting epoch 3553\n",
      "Train Loss: 0.020890542202525668\n",
      "Val Loss: 0.020876402656237285\n",
      "Starting epoch 3554\n",
      "Train Loss: 0.02088875295939269\n",
      "Val Loss: 0.020951481880965055\n",
      "Starting epoch 3555\n",
      "Train Loss: 0.02088580694463518\n",
      "Val Loss: 0.020867183804512024\n",
      "Starting epoch 3556\n",
      "Train Loss: 0.02090835902425978\n",
      "Val Loss: 0.0208738186845073\n",
      "Starting epoch 3557\n",
      "Train Loss: 0.020897579413873178\n",
      "Val Loss: 0.02091863033948121\n",
      "Starting epoch 3558\n",
      "Train Loss: 0.020945692503893817\n",
      "Val Loss: 0.020870563056733873\n",
      "Starting epoch 3559\n",
      "Train Loss: 0.021338532368342083\n",
      "Val Loss: 0.020941985978020564\n",
      "Starting epoch 3560\n",
      "Train Loss: 0.020884173335852445\n",
      "Val Loss: 0.020936668471053795\n",
      "Starting epoch 3561\n",
      "Train Loss: 0.020886160709239817\n",
      "Val Loss: 0.020868380864461262\n",
      "Starting epoch 3562\n",
      "Train Loss: 0.020931364209563645\n",
      "Val Loss: 0.02096117812174338\n",
      "Starting epoch 3563\n",
      "Train Loss: 0.020870214811077824\n",
      "Val Loss: 0.020957345763842266\n",
      "Starting epoch 3564\n",
      "Train Loss: 0.020882442593574524\n",
      "Val Loss: 0.02087130535531927\n",
      "Starting epoch 3565\n",
      "Train Loss: 0.020868533187442355\n",
      "Val Loss: 0.02087733535854905\n",
      "Starting epoch 3566\n",
      "Train Loss: 0.020922805975984643\n",
      "Val Loss: 0.02136185489318989\n",
      "Starting epoch 3567\n",
      "Train Loss: 0.020869298113716975\n",
      "Val Loss: 0.021391776976761995\n",
      "Starting epoch 3568\n",
      "Train Loss: 0.02088308389540072\n",
      "Val Loss: 0.02086533385294455\n",
      "Starting epoch 3569\n",
      "Train Loss: 0.020869551985352126\n",
      "Val Loss: 0.020953682285768015\n",
      "Starting epoch 3570\n",
      "Train Loss: 0.021335915834815415\n",
      "Val Loss: 0.020883854892518785\n",
      "Starting epoch 3571\n",
      "Train Loss: 0.02086576101956544\n",
      "Val Loss: 0.0208790037367079\n",
      "Starting epoch 3572\n",
      "Train Loss: 0.020869033204184637\n",
      "Val Loss: 0.020887717052742286\n",
      "Starting epoch 3573\n",
      "Train Loss: 0.021350035512888874\n",
      "Val Loss: 0.02133095430003272\n",
      "Starting epoch 3574\n",
      "Train Loss: 0.0208636075258255\n",
      "Val Loss: 0.020862934765992342\n",
      "Starting epoch 3575\n",
      "Train Loss: 0.02089006260589317\n",
      "Val Loss: 0.02086704362321783\n",
      "Starting epoch 3576\n",
      "Train Loss: 0.020864242756808246\n",
      "Val Loss: 0.021340802311897278\n",
      "Starting epoch 3577\n",
      "Train Loss: 0.020873548807921232\n",
      "Val Loss: 0.020899889093858225\n",
      "Starting epoch 3578\n",
      "Train Loss: 0.020870248476664226\n",
      "Val Loss: 0.02088074165361899\n",
      "Starting epoch 3579\n",
      "Train Loss: 0.02087667749987708\n",
      "Val Loss: 0.02089508319342578\n",
      "Starting epoch 3580\n",
      "Train Loss: 0.020869757842134545\n",
      "Val Loss: 0.020872118296446623\n",
      "Starting epoch 3581\n",
      "Train Loss: 0.020871532736001192\n",
      "Val Loss: 0.02086483273241255\n",
      "Starting epoch 3582\n",
      "Train Loss: 0.020880366917009705\n",
      "Val Loss: 0.02086735709949776\n",
      "Starting epoch 3583\n",
      "Train Loss: 0.020884112627417954\n",
      "Val Loss: 0.02086904258639724\n",
      "Starting epoch 3584\n",
      "Train Loss: 0.02140683266851637\n",
      "Val Loss: 0.02087420445901376\n",
      "Starting epoch 3585\n",
      "Train Loss: 0.02094244405075356\n",
      "Val Loss: 0.020953340110955416\n",
      "Starting epoch 3586\n",
      "Train Loss: 0.020941297213236492\n",
      "Val Loss: 0.02088025157098417\n",
      "Starting epoch 3587\n",
      "Train Loss: 0.020867990122901067\n",
      "Val Loss: 0.020885905181920086\n",
      "Starting epoch 3588\n",
      "Train Loss: 0.02134072725419645\n",
      "Val Loss: 0.02088016547538616\n",
      "Starting epoch 3589\n",
      "Train Loss: 0.020874955036022044\n",
      "Val Loss: 0.02086276533427062\n",
      "Starting epoch 3590\n",
      "Train Loss: 0.02086723016368018\n",
      "Val Loss: 0.020870783262782626\n",
      "Starting epoch 3591\n",
      "Train Loss: 0.020864932073487177\n",
      "Val Loss: 0.020895590936696087\n",
      "Starting epoch 3592\n",
      "Train Loss: 0.02086401923939034\n",
      "Val Loss: 0.02090978346489094\n",
      "Starting epoch 3593\n",
      "Train Loss: 0.020873340743559378\n",
      "Val Loss: 0.0208964165714052\n",
      "Starting epoch 3594\n",
      "Train Loss: 0.020896400566454285\n",
      "Val Loss: 0.020918857720163133\n",
      "Starting epoch 3595\n",
      "Train Loss: 0.02088170360635828\n",
      "Val Loss: 0.020861758678047744\n",
      "Starting epoch 3596\n",
      "Train Loss: 0.02086728866453524\n",
      "Val Loss: 0.020875581988581905\n",
      "Starting epoch 3597\n",
      "Train Loss: 0.020871531080316613\n",
      "Val Loss: 0.02086756350817504\n",
      "Starting epoch 3598\n",
      "Train Loss: 0.020874253025761357\n",
      "Val Loss: 0.021327864240717004\n",
      "Starting epoch 3599\n",
      "Train Loss: 0.02086703148153093\n",
      "Val Loss: 0.020864604247940913\n",
      "Starting epoch 3600\n",
      "Train Loss: 0.021331135321546485\n",
      "Val Loss: 0.020962258179982502\n",
      "Starting epoch 3601\n",
      "Train Loss: 0.02087536895716632\n",
      "Val Loss: 0.02086843936531632\n",
      "Starting epoch 3602\n",
      "Train Loss: 0.021328076720237732\n",
      "Val Loss: 0.02094247661255024\n",
      "Starting epoch 3603\n",
      "Train Loss: 0.0208795048572399\n",
      "Val Loss: 0.0213445038707168\n",
      "Starting epoch 3604\n",
      "Train Loss: 0.021326034157364455\n",
      "Val Loss: 0.020968198224350258\n",
      "Starting epoch 3605\n",
      "Train Loss: 0.020865450302759807\n",
      "Val Loss: 0.02132608989874522\n",
      "Starting epoch 3606\n",
      "Train Loss: 0.02086804641617669\n",
      "Val Loss: 0.020877075416070444\n",
      "Starting epoch 3607\n",
      "Train Loss: 0.02089037663406796\n",
      "Val Loss: 0.020864574445618525\n",
      "Starting epoch 3608\n",
      "Train Loss: 0.020963265939995094\n",
      "Val Loss: 0.020860829287105136\n",
      "Starting epoch 3609\n",
      "Train Loss: 0.020871603930438007\n",
      "Val Loss: 0.02087745236025916\n",
      "Starting epoch 3610\n",
      "Train Loss: 0.02087862292925517\n",
      "Val Loss: 0.020935010027002404\n",
      "Starting epoch 3611\n",
      "Train Loss: 0.020879535211457148\n",
      "Val Loss: 0.020939051001160232\n",
      "Starting epoch 3612\n",
      "Train Loss: 0.020860163701905146\n",
      "Val Loss: 0.021341313366536743\n",
      "Starting epoch 3613\n",
      "Train Loss: 0.02086761373060721\n",
      "Val Loss: 0.020872881015141804\n",
      "Starting epoch 3614\n",
      "Train Loss: 0.02086238894197676\n",
      "Val Loss: 0.020872978148636995\n",
      "Starting epoch 3615\n",
      "Train Loss: 0.02086253684979898\n",
      "Val Loss: 0.02093694552227303\n",
      "Starting epoch 3616\n",
      "Train Loss: 0.020861641676337632\n",
      "Val Loss: 0.020866999471629108\n",
      "Starting epoch 3617\n",
      "Train Loss: 0.020885376466645136\n",
      "Val Loss: 0.020863172632676584\n",
      "Starting epoch 3618\n",
      "Train Loss: 0.02086812588903639\n",
      "Val Loss: 0.020861390012281912\n",
      "Starting epoch 3619\n",
      "Train Loss: 0.020884699843547964\n",
      "Val Loss: 0.02086288399166531\n",
      "Starting epoch 3620\n",
      "Train Loss: 0.020872446673887747\n",
      "Val Loss: 0.021337053290119878\n",
      "Starting epoch 3621\n",
      "Train Loss: 0.020862484971682232\n",
      "Val Loss: 0.020971463786231145\n",
      "Starting epoch 3622\n",
      "Train Loss: 0.020890503569885536\n",
      "Val Loss: 0.02093887163533105\n",
      "Starting epoch 3623\n",
      "Train Loss: 0.020873643733836985\n",
      "Val Loss: 0.020878962896488332\n",
      "Starting epoch 3624\n",
      "Train Loss: 0.02087340255578359\n",
      "Val Loss: 0.02134165498945448\n",
      "Starting epoch 3625\n",
      "Train Loss: 0.02094876214309975\n",
      "Val Loss: 0.0213435932441994\n",
      "Starting epoch 3626\n",
      "Train Loss: 0.020925699008835688\n",
      "Val Loss: 0.021338473867487023\n",
      "Starting epoch 3627\n",
      "Train Loss: 0.020879826611942716\n",
      "Val Loss: 0.02093911943612275\n",
      "Starting epoch 3628\n",
      "Train Loss: 0.02086331722912965\n",
      "Val Loss: 0.021348107744146277\n",
      "Starting epoch 3629\n",
      "Train Loss: 0.021339190778908907\n",
      "Val Loss: 0.020943777980627836\n",
      "Starting epoch 3630\n",
      "Train Loss: 0.020866165558497112\n",
      "Val Loss: 0.020930618599609093\n",
      "Starting epoch 3631\n",
      "Train Loss: 0.020865826695053664\n",
      "Val Loss: 0.020870432257652283\n",
      "Starting epoch 3632\n",
      "Train Loss: 0.020992952916357253\n",
      "Val Loss: 0.02086044020122952\n",
      "Starting epoch 3633\n",
      "Train Loss: 0.021338046700866135\n",
      "Val Loss: 0.020865973499086168\n",
      "Starting epoch 3634\n",
      "Train Loss: 0.020882708606896578\n",
      "Val Loss: 0.02086833119392395\n",
      "Starting epoch 3635\n",
      "Train Loss: 0.020871267274573998\n",
      "Val Loss: 0.02086639901002248\n",
      "Starting epoch 3636\n",
      "Train Loss: 0.020878175342524494\n",
      "Val Loss: 0.020892692384896456\n",
      "Starting epoch 3637\n",
      "Train Loss: 0.020874550497090374\n",
      "Val Loss: 0.02088858794282984\n",
      "Starting epoch 3638\n",
      "Train Loss: 0.020860744847191706\n",
      "Val Loss: 0.021327674388885498\n",
      "Starting epoch 3639\n",
      "Train Loss: 0.021413439953768695\n",
      "Val Loss: 0.02088697033899802\n",
      "Starting epoch 3640\n",
      "Train Loss: 0.0208694863098639\n",
      "Val Loss: 0.020862614115079243\n",
      "Starting epoch 3641\n",
      "Train Loss: 0.020927461761015433\n",
      "Val Loss: 0.020921864995249995\n",
      "Starting epoch 3642\n",
      "Train Loss: 0.020886857752446777\n",
      "Val Loss: 0.020865406703065942\n",
      "Starting epoch 3643\n",
      "Train Loss: 0.020856929046136362\n",
      "Val Loss: 0.020864971809917025\n",
      "Starting epoch 3644\n",
      "Train Loss: 0.020866664471449674\n",
      "Val Loss: 0.02093157724097923\n",
      "Starting epoch 3645\n",
      "Train Loss: 0.020874221567754394\n",
      "Val Loss: 0.020872294902801514\n",
      "Starting epoch 3646\n",
      "Train Loss: 0.02087155646748013\n",
      "Val Loss: 0.020889693940127338\n",
      "Starting epoch 3647\n",
      "Train Loss: 0.02087352176507314\n",
      "Val Loss: 0.02091702542923115\n",
      "Starting epoch 3648\n",
      "Train Loss: 0.02086542491559629\n",
      "Val Loss: 0.020868335609082824\n",
      "Starting epoch 3649\n",
      "Train Loss: 0.020857500257315458\n",
      "Val Loss: 0.020875551634364657\n",
      "Starting epoch 3650\n",
      "Train Loss: 0.02088009096958019\n",
      "Val Loss: 0.020877802261599788\n",
      "Starting epoch 3651\n",
      "Train Loss: 0.02088384606220104\n",
      "Val Loss: 0.020879774733825966\n",
      "Starting epoch 3652\n",
      "Train Loss: 0.020875733759668138\n",
      "Val Loss: 0.020859771856555232\n",
      "Starting epoch 3653\n",
      "Train Loss: 0.020868356581087464\n",
      "Val Loss: 0.020865439816757484\n",
      "Starting epoch 3654\n",
      "Train Loss: 0.020869133649048983\n",
      "Val Loss: 0.020864291875450698\n",
      "Starting epoch 3655\n",
      "Train Loss: 0.020860955671027855\n",
      "Val Loss: 0.020885514440359892\n",
      "Starting epoch 3656\n",
      "Train Loss: 0.020937552054723103\n",
      "Val Loss: 0.020880471777032922\n",
      "Starting epoch 3657\n",
      "Train Loss: 0.021341896167507878\n",
      "Val Loss: 0.020865918861495122\n",
      "Starting epoch 3658\n",
      "Train Loss: 0.02087189974608245\n",
      "Val Loss: 0.020868672264946833\n",
      "Starting epoch 3659\n",
      "Train Loss: 0.020862096437701472\n",
      "Val Loss: 0.020868031515015498\n",
      "Starting epoch 3660\n",
      "Train Loss: 0.020861179740340623\n",
      "Val Loss: 0.021327608713397273\n",
      "Starting epoch 3661\n",
      "Train Loss: 0.020868060213548166\n",
      "Val Loss: 0.020951660143004522\n",
      "Starting epoch 3662\n",
      "Train Loss: 0.02092728681034512\n",
      "Val Loss: 0.02133693739219948\n",
      "Starting epoch 3663\n",
      "Train Loss: 0.021343272593286302\n",
      "Val Loss: 0.02085959745777978\n",
      "Starting epoch 3664\n",
      "Train Loss: 0.020860762507827195\n",
      "Val Loss: 0.020860404879958543\n",
      "Starting epoch 3665\n",
      "Train Loss: 0.020863114683716384\n",
      "Val Loss: 0.02090781761540307\n",
      "Starting epoch 3666\n",
      "Train Loss: 0.020856704424928735\n",
      "Val Loss: 0.020876191280506277\n",
      "Starting epoch 3667\n",
      "Train Loss: 0.02095120593353554\n",
      "Val Loss: 0.020858985958275972\n",
      "Starting epoch 3668\n",
      "Train Loss: 0.021380676715462295\n",
      "Val Loss: 0.020878261438122502\n",
      "Starting epoch 3669\n",
      "Train Loss: 0.0213254502526036\n",
      "Val Loss: 0.020855240799762583\n",
      "Starting epoch 3670\n",
      "Train Loss: 0.020873934582427697\n",
      "Val Loss: 0.02086574556650939\n",
      "Starting epoch 3671\n",
      "Train Loss: 0.021321225497457717\n",
      "Val Loss: 0.02085708964754034\n",
      "Starting epoch 3672\n",
      "Train Loss: 0.021337146560351055\n",
      "Val Loss: 0.020920993553267583\n",
      "Starting epoch 3673\n",
      "Train Loss: 0.020875667532285053\n",
      "Val Loss: 0.021343226234118145\n",
      "Starting epoch 3674\n",
      "Train Loss: 0.020878902188053838\n",
      "Val Loss: 0.02087621666766979\n",
      "Starting epoch 3675\n",
      "Train Loss: 0.02092904183599684\n",
      "Val Loss: 0.020876360712228\n",
      "Starting epoch 3676\n",
      "Train Loss: 0.02086088447659104\n",
      "Val Loss: 0.020902212019319886\n",
      "Starting epoch 3677\n",
      "Train Loss: 0.020858917523313453\n",
      "Val Loss: 0.021327943161681847\n",
      "Starting epoch 3678\n",
      "Train Loss: 0.02134542222376223\n",
      "Val Loss: 0.02086632008905764\n",
      "Starting epoch 3679\n",
      "Train Loss: 0.020855229209970544\n",
      "Val Loss: 0.021322375094449078\n",
      "Starting epoch 3680\n",
      "Train Loss: 0.020859442375324392\n",
      "Val Loss: 0.020923237557764405\n",
      "Starting epoch 3681\n",
      "Train Loss: 0.0209408700466156\n",
      "Val Loss: 0.020939345161120098\n",
      "Starting epoch 3682\n",
      "Train Loss: 0.02086624613514653\n",
      "Val Loss: 0.020882887420830904\n",
      "Starting epoch 3683\n",
      "Train Loss: 0.020921199410050002\n",
      "Val Loss: 0.020859649887791386\n",
      "Starting epoch 3684\n",
      "Train Loss: 0.020864552921719022\n",
      "Val Loss: 0.020877244847792166\n",
      "Starting epoch 3685\n",
      "Train Loss: 0.02089941722375375\n",
      "Val Loss: 0.02085447863296226\n",
      "Starting epoch 3686\n",
      "Train Loss: 0.02094246557465306\n",
      "Val Loss: 0.020865071150991652\n",
      "Starting epoch 3687\n",
      "Train Loss: 0.020871469268092403\n",
      "Val Loss: 0.020876275168524847\n",
      "Starting epoch 3688\n",
      "Train Loss: 0.020859452861326712\n",
      "Val Loss: 0.02087066184591364\n",
      "Starting epoch 3689\n",
      "Train Loss: 0.020875301625993516\n",
      "Val Loss: 0.020872227019733854\n",
      "Starting epoch 3690\n",
      "Train Loss: 0.02091657066786731\n",
      "Val Loss: 0.020858225999055086\n",
      "Starting epoch 3691\n",
      "Train Loss: 0.020908456157754968\n",
      "Val Loss: 0.020859535093660706\n",
      "Starting epoch 3692\n",
      "Train Loss: 0.02093325168998153\n",
      "Val Loss: 0.020907934617113183\n",
      "Starting epoch 3693\n",
      "Train Loss: 0.020904704376503273\n",
      "Val Loss: 0.020925568761648954\n",
      "Starting epoch 3694\n",
      "Train Loss: 0.020915179892822548\n",
      "Val Loss: 0.020939754115210638\n",
      "Starting epoch 3695\n",
      "Train Loss: 0.020954194444197195\n",
      "Val Loss: 0.02086310033445005\n",
      "Starting epoch 3696\n",
      "Train Loss: 0.020873372201566345\n",
      "Val Loss: 0.020857735916420265\n",
      "Starting epoch 3697\n",
      "Train Loss: 0.02085791638603917\n",
      "Val Loss: 0.02133172584904565\n",
      "Starting epoch 3698\n",
      "Train Loss: 0.020858868404670997\n",
      "Val Loss: 0.020868374241722956\n",
      "Starting epoch 3699\n",
      "Train Loss: 0.020869409044583637\n",
      "Val Loss: 0.0208645209118172\n",
      "Starting epoch 3700\n",
      "Train Loss: 0.020853149670141714\n",
      "Val Loss: 0.02086576101956544\n",
      "Starting epoch 3701\n",
      "Train Loss: 0.020857991995634855\n",
      "Val Loss: 0.02085817246525376\n",
      "Starting epoch 3702\n",
      "Train Loss: 0.021332466491946468\n",
      "Val Loss: 0.02094153066476186\n",
      "Starting epoch 3703\n",
      "Train Loss: 0.02085642351044549\n",
      "Val Loss: 0.020919265570463957\n",
      "Starting epoch 3704\n",
      "Train Loss: 0.020857771789586102\n",
      "Val Loss: 0.020854943880328426\n",
      "Starting epoch 3705\n",
      "Train Loss: 0.02085908364366602\n",
      "Val Loss: 0.02091411418384976\n",
      "Starting epoch 3706\n",
      "Train Loss: 0.020852425032191806\n",
      "Val Loss: 0.020939795507325068\n",
      "Starting epoch 3707\n",
      "Train Loss: 0.02132009080162755\n",
      "Val Loss: 0.02087073745550933\n",
      "Starting epoch 3708\n",
      "Train Loss: 0.0208707297289813\n",
      "Val Loss: 0.02085745996899075\n",
      "Starting epoch 3709\n",
      "Train Loss: 0.020853050329067088\n",
      "Val Loss: 0.02089051847104673\n",
      "Starting epoch 3710\n",
      "Train Loss: 0.020862398324189364\n",
      "Val Loss: 0.020872055932327552\n",
      "Starting epoch 3711\n",
      "Train Loss: 0.020853000658529776\n",
      "Val Loss: 0.020875490374035306\n",
      "Starting epoch 3712\n",
      "Train Loss: 0.02085801848658809\n",
      "Val Loss: 0.02091468263555456\n",
      "Starting epoch 3713\n",
      "Train Loss: 0.020854099481194106\n",
      "Val Loss: 0.02085435445661898\n",
      "Starting epoch 3714\n",
      "Train Loss: 0.020945769217279222\n",
      "Val Loss: 0.020923700597551134\n",
      "Starting epoch 3715\n",
      "Train Loss: 0.0208841887889085\n",
      "Val Loss: 0.020858857918668677\n",
      "Starting epoch 3716\n",
      "Train Loss: 0.0208559842021377\n",
      "Val Loss: 0.02087540317464758\n",
      "Starting epoch 3717\n",
      "Train Loss: 0.020914042989412945\n",
      "Val Loss: 0.020857531163427565\n",
      "Starting epoch 3718\n",
      "Train Loss: 0.02133101335278264\n",
      "Val Loss: 0.02086845150700322\n",
      "Starting epoch 3719\n",
      "Train Loss: 0.020927647197688068\n",
      "Val Loss: 0.020925006380787602\n",
      "Starting epoch 3720\n",
      "Train Loss: 0.020864185911637766\n",
      "Val Loss: 0.020905482548254507\n",
      "Starting epoch 3721\n",
      "Train Loss: 0.02088542558528759\n",
      "Val Loss: 0.021365687251091003\n",
      "Starting epoch 3722\n",
      "Train Loss: 0.020858043873751606\n",
      "Val Loss: 0.020856865578227572\n",
      "Starting epoch 3723\n",
      "Train Loss: 0.02092126342985365\n",
      "Val Loss: 0.021337658166885376\n",
      "Starting epoch 3724\n",
      "Train Loss: 0.020857018453103525\n",
      "Val Loss: 0.02086806297302246\n",
      "Starting epoch 3725\n",
      "Train Loss: 0.02088615905355524\n",
      "Val Loss: 0.020936668471053795\n",
      "Starting epoch 3726\n",
      "Train Loss: 0.020946742759810552\n",
      "Val Loss: 0.020854444415481004\n",
      "Starting epoch 3727\n",
      "Train Loss: 0.02085972218601792\n",
      "Val Loss: 0.020872151410138165\n",
      "Starting epoch 3728\n",
      "Train Loss: 0.0208821721650936\n",
      "Val Loss: 0.020865067287727638\n",
      "Starting epoch 3729\n",
      "Train Loss: 0.02133436114699752\n",
      "Val Loss: 0.020866796374320984\n",
      "Starting epoch 3730\n",
      "Train Loss: 0.020878782426869427\n",
      "Val Loss: 0.020858295537807322\n",
      "Starting epoch 3731\n",
      "Train Loss: 0.020867731284212182\n",
      "Val Loss: 0.02087796562247806\n",
      "Starting epoch 3732\n",
      "Train Loss: 0.020914947545086895\n",
      "Val Loss: 0.020860443512598675\n",
      "Starting epoch 3733\n",
      "Train Loss: 0.020850594948839257\n",
      "Val Loss: 0.020927693556856225\n",
      "Starting epoch 3734\n",
      "Train Loss: 0.02086001358650349\n",
      "Val Loss: 0.020861555028844764\n",
      "Starting epoch 3735\n",
      "Train Loss: 0.020862871849978412\n",
      "Val Loss: 0.02086641170360424\n",
      "Starting epoch 3736\n",
      "Train Loss: 0.020873285554073476\n",
      "Val Loss: 0.020903964285497314\n",
      "Starting epoch 3737\n",
      "Train Loss: 0.020866214125244704\n",
      "Val Loss: 0.020917272678127995\n",
      "Starting epoch 3738\n",
      "Train Loss: 0.020867208087885822\n",
      "Val Loss: 0.020862950219048396\n",
      "Starting epoch 3739\n",
      "Train Loss: 0.020870702686133207\n",
      "Val Loss: 0.020905661914083693\n",
      "Starting epoch 3740\n",
      "Train Loss: 0.020861563859162508\n",
      "Val Loss: 0.020904109433845238\n",
      "Starting epoch 3741\n",
      "Train Loss: 0.021332910767307988\n",
      "Val Loss: 0.02092001062852365\n",
      "Starting epoch 3742\n",
      "Train Loss: 0.02137347779892109\n",
      "Val Loss: 0.020858818182238826\n",
      "Starting epoch 3743\n",
      "Train Loss: 0.020857507431948627\n",
      "Val Loss: 0.02084969425642932\n",
      "Starting epoch 3744\n",
      "Train Loss: 0.020857512399002357\n",
      "Val Loss: 0.021321005291408963\n",
      "Starting epoch 3745\n",
      "Train Loss: 0.020926572658397532\n",
      "Val Loss: 0.02088062906706775\n",
      "Starting epoch 3746\n",
      "Train Loss: 0.020851686044975563\n",
      "Val Loss: 0.02085290242124487\n",
      "Starting epoch 3747\n",
      "Train Loss: 0.020851685493080703\n",
      "Val Loss: 0.020849320071714895\n",
      "Starting epoch 3748\n",
      "Train Loss: 0.021327267090479534\n",
      "Val Loss: 0.020852857717761287\n",
      "Starting epoch 3749\n",
      "Train Loss: 0.02086892558468713\n",
      "Val Loss: 0.020929265905309608\n",
      "Starting epoch 3750\n",
      "Train Loss: 0.02086741394466824\n",
      "Val Loss: 0.02085327936543359\n",
      "Starting epoch 3751\n",
      "Train Loss: 0.020852555831273396\n",
      "Val Loss: 0.02088012077190258\n",
      "Starting epoch 3752\n",
      "Train Loss: 0.02092792535269702\n",
      "Val Loss: 0.02133023131776739\n",
      "Starting epoch 3753\n",
      "Train Loss: 0.020917815190774423\n",
      "Val Loss: 0.020847742204312927\n",
      "Starting epoch 3754\n",
      "Train Loss: 0.020851120904639916\n",
      "Val Loss: 0.020871330742482787\n",
      "Starting epoch 3755\n",
      "Train Loss: 0.020850316241935448\n",
      "Val Loss: 0.020858680760418927\n",
      "Starting epoch 3756\n",
      "Train Loss: 0.020853405197461445\n",
      "Val Loss: 0.020901325676176283\n",
      "Starting epoch 3757\n",
      "Train Loss: 0.020863512599909748\n",
      "Val Loss: 0.02085507247183058\n",
      "Starting epoch 3758\n",
      "Train Loss: 0.02086541829285798\n",
      "Val Loss: 0.021325098695578398\n",
      "Starting epoch 3759\n",
      "Train Loss: 0.020847604230598168\n",
      "Val Loss: 0.02092039805871469\n",
      "Starting epoch 3760\n",
      "Train Loss: 0.02087073690361447\n",
      "Val Loss: 0.020862870194293833\n",
      "Starting epoch 3761\n",
      "Train Loss: 0.02134918835428026\n",
      "Val Loss: 0.02086045013533698\n",
      "Starting epoch 3762\n",
      "Train Loss: 0.02085262261055134\n",
      "Val Loss: 0.02092686516267282\n",
      "Starting epoch 3763\n",
      "Train Loss: 0.020906087425020006\n",
      "Val Loss: 0.020848905598675763\n",
      "Starting epoch 3764\n",
      "Train Loss: 0.020858761337068345\n",
      "Val Loss: 0.020852644134450843\n",
      "Starting epoch 3765\n",
      "Train Loss: 0.021329443211908692\n",
      "Val Loss: 0.02085321479373508\n",
      "Starting epoch 3766\n",
      "Train Loss: 0.020861817178902804\n",
      "Val Loss: 0.02085604711815163\n",
      "Starting epoch 3767\n",
      "Train Loss: 0.021321569327954894\n",
      "Val Loss: 0.021320329772101507\n",
      "Starting epoch 3768\n",
      "Train Loss: 0.020917710330751207\n",
      "Val Loss: 0.02084673665187977\n",
      "Starting epoch 3769\n",
      "Train Loss: 0.020868732421486465\n",
      "Val Loss: 0.02133586671617296\n",
      "Starting epoch 3770\n",
      "Train Loss: 0.02084866110925321\n",
      "Val Loss: 0.021319962210125394\n",
      "Starting epoch 3771\n",
      "Train Loss: 0.020917763312657673\n",
      "Val Loss: 0.020853189958466425\n",
      "Starting epoch 3772\n",
      "Train Loss: 0.020848419379304955\n",
      "Val Loss: 0.020856032768885296\n",
      "Starting epoch 3773\n",
      "Train Loss: 0.02136457352726548\n",
      "Val Loss: 0.02086722519662645\n",
      "Starting epoch 3774\n",
      "Train Loss: 0.020848064510910598\n",
      "Val Loss: 0.02087467246585422\n",
      "Starting epoch 3775\n",
      "Train Loss: 0.02084863351451026\n",
      "Val Loss: 0.02086931025540387\n",
      "Starting epoch 3776\n",
      "Train Loss: 0.021323743793699477\n",
      "Val Loss: 0.02093081341849433\n",
      "Starting epoch 3777\n",
      "Train Loss: 0.02093278975398452\n",
      "Val Loss: 0.020849538070184213\n",
      "Starting epoch 3778\n",
      "Train Loss: 0.02132130828168657\n",
      "Val Loss: 0.020855496327082317\n",
      "Starting epoch 3779\n",
      "Train Loss: 0.02092541754245758\n",
      "Val Loss: 0.02084926598601871\n",
      "Starting epoch 3780\n",
      "Train Loss: 0.020872552085805823\n",
      "Val Loss: 0.020853104966658133\n",
      "Starting epoch 3781\n",
      "Train Loss: 0.020862591487390024\n",
      "Val Loss: 0.020919071303473577\n",
      "Starting epoch 3782\n",
      "Train Loss: 0.02084615550659321\n",
      "Val Loss: 0.020877256437584205\n",
      "Starting epoch 3783\n",
      "Train Loss: 0.020867980740688467\n",
      "Val Loss: 0.02085160270885185\n",
      "Starting epoch 3784\n",
      "Train Loss: 0.020847410515502648\n",
      "Val Loss: 0.0208810082188359\n",
      "Starting epoch 3785\n",
      "Train Loss: 0.020862295119850723\n",
      "Val Loss: 0.020910892773557593\n",
      "Starting epoch 3786\n",
      "Train Loss: 0.02092956061716433\n",
      "Val Loss: 0.020844982730017766\n",
      "Starting epoch 3787\n",
      "Train Loss: 0.02088062796327803\n",
      "Val Loss: 0.020867378071502404\n",
      "Starting epoch 3788\n",
      "Train Loss: 0.021318645940886602\n",
      "Val Loss: 0.020898721836231374\n",
      "Starting epoch 3789\n",
      "Train Loss: 0.02091441496654793\n",
      "Val Loss: 0.02131435164698848\n",
      "Starting epoch 3790\n",
      "Train Loss: 0.020948535314312688\n",
      "Val Loss: 0.021329823467466567\n",
      "Starting epoch 3791\n",
      "Train Loss: 0.020856210479029903\n",
      "Val Loss: 0.020848572254180908\n",
      "Starting epoch 3792\n",
      "Train Loss: 0.020852592256334092\n",
      "Val Loss: 0.02084470788637797\n",
      "Starting epoch 3793\n",
      "Train Loss: 0.020846775836414762\n",
      "Val Loss: 0.02088227868080139\n",
      "Starting epoch 3794\n",
      "Train Loss: 0.020918285957089177\n",
      "Val Loss: 0.02093297905392117\n",
      "Starting epoch 3795\n",
      "Train Loss: 0.02084798558994576\n",
      "Val Loss: 0.021316851178805035\n",
      "Starting epoch 3796\n",
      "Train Loss: 0.02090966867076026\n",
      "Val Loss: 0.02084764175944858\n",
      "Starting epoch 3797\n",
      "Train Loss: 0.02092227394934054\n",
      "Val Loss: 0.020851735163618018\n",
      "Starting epoch 3798\n",
      "Train Loss: 0.02084673775566949\n",
      "Val Loss: 0.020917911220479896\n",
      "Starting epoch 3799\n",
      "Train Loss: 0.02085092829333411\n",
      "Val Loss: 0.020936580719771208\n",
      "Starting epoch 3800\n",
      "Train Loss: 0.020847432591297007\n",
      "Val Loss: 0.020908479889233906\n",
      "Starting epoch 3801\n",
      "Train Loss: 0.020847509304682415\n",
      "Val Loss: 0.020907193422317505\n",
      "Starting epoch 3802\n",
      "Train Loss: 0.02087978963498716\n",
      "Val Loss: 0.020898699208542152\n",
      "Starting epoch 3803\n",
      "Train Loss: 0.020848121907975938\n",
      "Val Loss: 0.020863010375588027\n",
      "Starting epoch 3804\n",
      "Train Loss: 0.021335722119719895\n",
      "Val Loss: 0.020844078726238675\n",
      "Starting epoch 3805\n",
      "Train Loss: 0.020849451422691345\n",
      "Val Loss: 0.020864273111025494\n",
      "Starting epoch 3806\n",
      "Train Loss: 0.020854321894822298\n",
      "Val Loss: 0.020856406953599717\n",
      "Starting epoch 3807\n",
      "Train Loss: 0.02132981022198995\n",
      "Val Loss: 0.020894976677717985\n",
      "Starting epoch 3808\n",
      "Train Loss: 0.02085476065123523\n",
      "Val Loss: 0.02133327501791495\n",
      "Starting epoch 3809\n",
      "Train Loss: 0.020845566634778625\n",
      "Val Loss: 0.02085070312023163\n",
      "Starting epoch 3810\n",
      "Train Loss: 0.020847521446369314\n",
      "Val Loss: 0.020856768996627244\n",
      "Starting epoch 3811\n",
      "Train Loss: 0.020862101404755203\n",
      "Val Loss: 0.020844920917793556\n",
      "Starting epoch 3812\n",
      "Train Loss: 0.02084688455970199\n",
      "Val Loss: 0.020857662514404015\n",
      "Starting epoch 3813\n",
      "Train Loss: 0.021327071167804575\n",
      "Val Loss: 0.0213310933775372\n",
      "Starting epoch 3814\n",
      "Train Loss: 0.020858988717750267\n",
      "Val Loss: 0.020916399028566148\n",
      "Starting epoch 3815\n",
      "Train Loss: 0.020844116255089088\n",
      "Val Loss: 0.02097309132417043\n",
      "Starting epoch 3816\n",
      "Train Loss: 0.020862288497112417\n",
      "Val Loss: 0.02084777255853017\n",
      "Starting epoch 3817\n",
      "Train Loss: 0.020931781442077073\n",
      "Val Loss: 0.020860580934418574\n",
      "Starting epoch 3818\n",
      "Train Loss: 0.020862017516736633\n",
      "Val Loss: 0.020843098560969036\n",
      "Starting epoch 3819\n",
      "Train Loss: 0.02132390273941888\n",
      "Val Loss: 0.02085773922778942\n",
      "Starting epoch 3820\n",
      "Train Loss: 0.02085050940513611\n",
      "Val Loss: 0.0208481655076698\n",
      "Starting epoch 3821\n",
      "Train Loss: 0.020845231082704332\n",
      "Val Loss: 0.02086123327414195\n",
      "Starting epoch 3822\n",
      "Train Loss: 0.020860748710455717\n",
      "Val Loss: 0.020849155607046903\n",
      "Starting epoch 3823\n",
      "Train Loss: 0.02090276888123265\n",
      "Val Loss: 0.020854903040108858\n",
      "Starting epoch 3824\n",
      "Train Loss: 0.020860609632951242\n",
      "Val Loss: 0.020844545629289415\n",
      "Starting epoch 3825\n",
      "Train Loss: 0.021310507699295326\n",
      "Val Loss: 0.02085274899447406\n",
      "Starting epoch 3826\n",
      "Train Loss: 0.020927232724648935\n",
      "Val Loss: 0.020853425065676372\n",
      "Starting epoch 3827\n",
      "Train Loss: 0.020843532902223093\n",
      "Val Loss: 0.020846108043635334\n",
      "Starting epoch 3828\n",
      "Train Loss: 0.0208616825165572\n",
      "Val Loss: 0.020857643198083947\n",
      "Starting epoch 3829\n",
      "Train Loss: 0.021334389845530193\n",
      "Val Loss: 0.020851109314847877\n",
      "Starting epoch 3830\n",
      "Train Loss: 0.020909752558778832\n",
      "Val Loss: 0.020842363437016804\n",
      "Starting epoch 3831\n",
      "Train Loss: 0.020856567555003695\n",
      "Val Loss: 0.020858329755288584\n",
      "Starting epoch 3832\n",
      "Train Loss: 0.020841514622723614\n",
      "Val Loss: 0.021324036297974764\n",
      "Starting epoch 3833\n",
      "Train Loss: 0.021316223674350314\n",
      "Val Loss: 0.021326129635175068\n",
      "Starting epoch 3834\n",
      "Train Loss: 0.020907581956298264\n",
      "Val Loss: 0.02087659692322766\n",
      "Starting epoch 3835\n",
      "Train Loss: 0.020847394510551735\n",
      "Val Loss: 0.020847738341048912\n",
      "Starting epoch 3836\n",
      "Train Loss: 0.02086143747523979\n",
      "Val Loss: 0.020936055315865412\n",
      "Starting epoch 3837\n",
      "Train Loss: 0.020857912522775156\n",
      "Val Loss: 0.020845165407216107\n",
      "Starting epoch 3838\n",
      "Train Loss: 0.020844483265170344\n",
      "Val Loss: 0.02092522934631065\n",
      "Starting epoch 3839\n",
      "Train Loss: 0.020912579916141653\n",
      "Val Loss: 0.02092582925602242\n",
      "Starting epoch 3840\n",
      "Train Loss: 0.020856603980064392\n",
      "Val Loss: 0.020842567638114647\n",
      "Starting epoch 3841\n",
      "Train Loss: 0.020842740933100384\n",
      "Val Loss: 0.02084213881580918\n",
      "Starting epoch 3842\n",
      "Train Loss: 0.02085014405073943\n",
      "Val Loss: 0.020883120320461416\n",
      "Starting epoch 3843\n",
      "Train Loss: 0.020856655858181142\n",
      "Val Loss: 0.020842300521002874\n",
      "Starting epoch 3844\n",
      "Train Loss: 0.020863439197893494\n",
      "Val Loss: 0.020923202236493427\n",
      "Starting epoch 3845\n",
      "Train Loss: 0.02084498107433319\n",
      "Val Loss: 0.020847371330967656\n",
      "Starting epoch 3846\n",
      "Train Loss: 0.020932536986139085\n",
      "Val Loss: 0.02084131759625894\n",
      "Starting epoch 3847\n",
      "Train Loss: 0.020844233256799204\n",
      "Val Loss: 0.02086948851744334\n",
      "Starting epoch 3848\n",
      "Train Loss: 0.02085171088024422\n",
      "Val Loss: 0.020870164036750793\n",
      "Starting epoch 3849\n",
      "Train Loss: 0.021320001394660386\n",
      "Val Loss: 0.020905468198988173\n",
      "Starting epoch 3850\n",
      "Train Loss: 0.02092459742669706\n",
      "Val Loss: 0.02084694250866219\n",
      "Starting epoch 3851\n",
      "Train Loss: 0.02084324481310668\n",
      "Val Loss: 0.020863559510972764\n",
      "Starting epoch 3852\n",
      "Train Loss: 0.02087278608922605\n",
      "Val Loss: 0.020865063976358483\n",
      "Starting epoch 3853\n",
      "Train Loss: 0.02091258046803651\n",
      "Val Loss: 0.02085486164799443\n",
      "Starting epoch 3854\n",
      "Train Loss: 0.020860580934418574\n",
      "Val Loss: 0.021316207669399404\n",
      "Starting epoch 3855\n",
      "Train Loss: 0.02130830453501807\n",
      "Val Loss: 0.020852744027420326\n",
      "Starting epoch 3856\n",
      "Train Loss: 0.020847614164705628\n",
      "Val Loss: 0.020854346178196096\n",
      "Starting epoch 3857\n",
      "Train Loss: 0.020845742689238653\n",
      "Val Loss: 0.020844278512177645\n",
      "Starting epoch 3858\n",
      "Train Loss: 0.020850757757822674\n",
      "Val Loss: 0.020855872719376174\n",
      "Starting epoch 3859\n",
      "Train Loss: 0.021318463815583125\n",
      "Val Loss: 0.021320303281148274\n",
      "Starting epoch 3860\n",
      "Train Loss: 0.02084506165098261\n",
      "Val Loss: 0.020850460838388513\n",
      "Starting epoch 3861\n",
      "Train Loss: 0.021336202268247253\n",
      "Val Loss: 0.02090834136362429\n",
      "Starting epoch 3862\n",
      "Train Loss: 0.0208423540548042\n",
      "Val Loss: 0.021313134718824317\n",
      "Starting epoch 3863\n",
      "Train Loss: 0.020906109500814368\n",
      "Val Loss: 0.020845370712103666\n",
      "Starting epoch 3864\n",
      "Train Loss: 0.020860353553736652\n",
      "Val Loss: 0.020848214074417396\n",
      "Starting epoch 3865\n",
      "Train Loss: 0.02085402828675729\n",
      "Val Loss: 0.020860030143349258\n",
      "Starting epoch 3866\n",
      "Train Loss: 0.020853242388478032\n",
      "Val Loss: 0.02084621787071228\n",
      "Starting epoch 3867\n",
      "Train Loss: 0.020840703337280837\n",
      "Val Loss: 0.0209097260678256\n",
      "Starting epoch 3868\n",
      "Train Loss: 0.020839815890347516\n",
      "Val Loss: 0.02084887358877394\n",
      "Starting epoch 3869\n",
      "Train Loss: 0.02085305529612082\n",
      "Val Loss: 0.020849280887179904\n",
      "Starting epoch 3870\n",
      "Train Loss: 0.02085268497467041\n",
      "Val Loss: 0.020874419146113925\n",
      "Starting epoch 3871\n",
      "Train Loss: 0.020852181094664114\n",
      "Val Loss: 0.020858898758888245\n",
      "Starting epoch 3872\n",
      "Train Loss: 0.020844601922565036\n",
      "Val Loss: 0.021326403926920007\n",
      "Starting epoch 3873\n",
      "Train Loss: 0.02086531122525533\n",
      "Val Loss: 0.020874152029002155\n",
      "Starting epoch 3874\n",
      "Train Loss: 0.020847875210973952\n",
      "Val Loss: 0.02085015343295203\n",
      "Starting epoch 3875\n",
      "Train Loss: 0.020906857870243215\n",
      "Val Loss: 0.021373251522028888\n",
      "Starting epoch 3876\n",
      "Train Loss: 0.020859111238408973\n",
      "Val Loss: 0.020845051716875146\n",
      "Starting epoch 3877\n",
      "Train Loss: 0.020869810272146155\n",
      "Val Loss: 0.020850500574818364\n",
      "Starting epoch 3878\n",
      "Train Loss: 0.020839560363027785\n",
      "Val Loss: 0.02089951104587979\n",
      "Starting epoch 3879\n",
      "Train Loss: 0.020916441524470294\n",
      "Val Loss: 0.020902737975120544\n",
      "Starting epoch 3880\n",
      "Train Loss: 0.02089976657319952\n",
      "Val Loss: 0.02091419420860432\n",
      "Starting epoch 3881\n",
      "Train Loss: 0.020861611874015244\n",
      "Val Loss: 0.020841770150043345\n",
      "Starting epoch 3882\n",
      "Train Loss: 0.020852015526206406\n",
      "Val Loss: 0.02084257702032725\n",
      "Starting epoch 3883\n",
      "Train Loss: 0.020919581806218182\n",
      "Val Loss: 0.0209081095677835\n",
      "Starting epoch 3884\n",
      "Train Loss: 0.020856687316188106\n",
      "Val Loss: 0.02085172302193112\n",
      "Starting epoch 3885\n",
      "Train Loss: 0.020851816292162293\n",
      "Val Loss: 0.021320452292760212\n",
      "Starting epoch 3886\n",
      "Train Loss: 0.02091749178038703\n",
      "Val Loss: 0.02084878694128107\n",
      "Starting epoch 3887\n",
      "Train Loss: 0.020849609816515888\n",
      "Val Loss: 0.020838102808705083\n",
      "Starting epoch 3888\n",
      "Train Loss: 0.02085118547633842\n",
      "Val Loss: 0.02084563175837199\n",
      "Starting epoch 3889\n",
      "Train Loss: 0.020890667482658668\n",
      "Val Loss: 0.021309089329507615\n",
      "Starting epoch 3890\n",
      "Train Loss: 0.020838680642622488\n",
      "Val Loss: 0.020928888961120887\n",
      "Starting epoch 3891\n",
      "Train Loss: 0.020838854489503084\n",
      "Val Loss: 0.020853314686704566\n",
      "Starting epoch 3892\n",
      "Train Loss: 0.020839205494633428\n",
      "Val Loss: 0.020849420516579238\n",
      "Starting epoch 3893\n",
      "Train Loss: 0.020862620185922692\n",
      "Val Loss: 0.02084070775243971\n",
      "Starting epoch 3894\n",
      "Train Loss: 0.020857537234271015\n",
      "Val Loss: 0.020837591202170762\n",
      "Starting epoch 3895\n",
      "Train Loss: 0.020902960388748733\n",
      "Val Loss: 0.020863464033162152\n",
      "Starting epoch 3896\n",
      "Train Loss: 0.020843383338716295\n",
      "Val Loss: 0.020847983382366323\n",
      "Starting epoch 3897\n",
      "Train Loss: 0.020842540043371695\n",
      "Val Loss: 0.02090952683378149\n",
      "Starting epoch 3898\n",
      "Train Loss: 0.020852856613971568\n",
      "Val Loss: 0.021316667949711834\n",
      "Starting epoch 3899\n",
      "Train Loss: 0.02085270208341104\n",
      "Val Loss: 0.020894880096117657\n",
      "Starting epoch 3900\n",
      "Train Loss: 0.020856009037406358\n",
      "Val Loss: 0.02084338665008545\n",
      "Starting epoch 3901\n",
      "Train Loss: 0.0209276400230549\n",
      "Val Loss: 0.020981065652988577\n",
      "Starting epoch 3902\n",
      "Train Loss: 0.020848864758456195\n",
      "Val Loss: 0.020951082860981976\n",
      "Starting epoch 3903\n",
      "Train Loss: 0.020839725931485493\n",
      "Val Loss: 0.020835948211175424\n",
      "Starting epoch 3904\n",
      "Train Loss: 0.02083667395291505\n",
      "Val Loss: 0.020857798832434195\n",
      "Starting epoch 3905\n",
      "Train Loss: 0.02088526608767333\n",
      "Val Loss: 0.020867182700722305\n",
      "Starting epoch 3906\n",
      "Train Loss: 0.021307151626657556\n",
      "Val Loss: 0.02085597813129425\n",
      "Starting epoch 3907\n",
      "Train Loss: 0.020836935551078233\n",
      "Val Loss: 0.02090907703947138\n",
      "Starting epoch 3908\n",
      "Train Loss: 0.020843407622090093\n",
      "Val Loss: 0.020919785455421166\n",
      "Starting epoch 3909\n",
      "Train Loss: 0.020843986559797217\n",
      "Val Loss: 0.021310440920017385\n",
      "Starting epoch 3910\n",
      "Train Loss: 0.021319830307254085\n",
      "Val Loss: 0.020847450251932496\n",
      "Starting epoch 3911\n",
      "Train Loss: 0.021307034073052584\n",
      "Val Loss: 0.020838882084246033\n",
      "Starting epoch 3912\n",
      "Train Loss: 0.02083669602870941\n",
      "Val Loss: 0.020909107945583486\n",
      "Starting epoch 3913\n",
      "Train Loss: 0.020916550247757522\n",
      "Val Loss: 0.020860598595054063\n",
      "Starting epoch 3914\n",
      "Train Loss: 0.02083481627481955\n",
      "Val Loss: 0.02085074230476662\n",
      "Starting epoch 3915\n",
      "Train Loss: 0.020839911920052988\n",
      "Val Loss: 0.020844707334483112\n",
      "Starting epoch 3916\n",
      "Train Loss: 0.02084919755105619\n",
      "Val Loss: 0.021370935771200392\n",
      "Starting epoch 3917\n",
      "Train Loss: 0.020854807562298246\n",
      "Val Loss: 0.02085907260576884\n",
      "Starting epoch 3918\n",
      "Train Loss: 0.020848040227536804\n",
      "Val Loss: 0.020855320824517146\n",
      "Starting epoch 3919\n",
      "Train Loss: 0.02084098756313324\n",
      "Val Loss: 0.021307950218518574\n",
      "Starting epoch 3920\n",
      "Train Loss: 0.02090219767005355\n",
      "Val Loss: 0.020906219879786175\n",
      "Starting epoch 3921\n",
      "Train Loss: 0.020834836694929335\n",
      "Val Loss: 0.020835166728055035\n",
      "Starting epoch 3922\n",
      "Train Loss: 0.020838346194337914\n",
      "Val Loss: 0.020849381883939106\n",
      "Starting epoch 3923\n",
      "Train Loss: 0.02083820711683344\n",
      "Val Loss: 0.02085497037128166\n",
      "Starting epoch 3924\n",
      "Train Loss: 0.02084616820017497\n",
      "Val Loss: 0.02084952923986647\n",
      "Starting epoch 3925\n",
      "Train Loss: 0.02083833957159961\n",
      "Val Loss: 0.020839578023663274\n",
      "Starting epoch 3926\n",
      "Train Loss: 0.020851167263808073\n",
      "Val Loss: 0.02084691215444494\n",
      "Starting epoch 3927\n",
      "Train Loss: 0.021319106221199036\n",
      "Val Loss: 0.020855774482091267\n",
      "Starting epoch 3928\n",
      "Train Loss: 0.020842039474734553\n",
      "Val Loss: 0.02088600121162556\n",
      "Starting epoch 3929\n",
      "Train Loss: 0.020840967143023456\n",
      "Val Loss: 0.020847970136889705\n",
      "Starting epoch 3930\n",
      "Train Loss: 0.020839022265540227\n",
      "Val Loss: 0.020837793195689167\n",
      "Starting epoch 3931\n",
      "Train Loss: 0.021317389828187448\n",
      "Val Loss: 0.020852401852607727\n",
      "Starting epoch 3932\n",
      "Train Loss: 0.020847757657368977\n",
      "Val Loss: 0.0208471754082927\n",
      "Starting epoch 3933\n",
      "Train Loss: 0.021380289837166114\n",
      "Val Loss: 0.020845502614974976\n",
      "Starting epoch 3934\n",
      "Train Loss: 0.02089251136338269\n",
      "Val Loss: 0.02088881366782718\n",
      "Starting epoch 3935\n",
      "Train Loss: 0.021309676545637625\n",
      "Val Loss: 0.020893833703464933\n",
      "Starting epoch 3936\n",
      "Train Loss: 0.020847007632255554\n",
      "Val Loss: 0.02135481712994752\n",
      "Starting epoch 3937\n",
      "Train Loss: 0.020844891115471168\n",
      "Val Loss: 0.020840215462225455\n",
      "Starting epoch 3938\n",
      "Train Loss: 0.020854089547086646\n",
      "Val Loss: 0.020840107842727943\n",
      "Starting epoch 3939\n",
      "Train Loss: 0.02095637884404924\n",
      "Val Loss: 0.020835823482937284\n",
      "Starting epoch 3940\n",
      "Train Loss: 0.02085018985801273\n",
      "Val Loss: 0.02131382789876726\n",
      "Starting epoch 3941\n",
      "Train Loss: 0.02084958056608836\n",
      "Val Loss: 0.020837123195330303\n",
      "Starting epoch 3942\n",
      "Train Loss: 0.02083793779214223\n",
      "Val Loss: 0.020841031162827102\n",
      "Starting epoch 3943\n",
      "Train Loss: 0.021320383305902833\n",
      "Val Loss: 0.020833463028625206\n",
      "Starting epoch 3944\n",
      "Train Loss: 0.020892577038870916\n",
      "Val Loss: 0.020835657914479572\n",
      "Starting epoch 3945\n",
      "Train Loss: 0.020854272776179843\n",
      "Val Loss: 0.02084705068005456\n",
      "Starting epoch 3946\n",
      "Train Loss: 0.020834482378429837\n",
      "Val Loss: 0.020916798048549227\n",
      "Starting epoch 3947\n",
      "Train Loss: 0.020842408692395245\n",
      "Val Loss: 0.020845527450243633\n",
      "Starting epoch 3948\n",
      "Train Loss: 0.02091205175276156\n",
      "Val Loss: 0.020858157012197707\n",
      "Starting epoch 3949\n",
      "Train Loss: 0.02088043480007737\n",
      "Val Loss: 0.021304481559329562\n",
      "Starting epoch 3950\n",
      "Train Loss: 0.02087931776488269\n",
      "Val Loss: 0.020884668385540997\n",
      "Starting epoch 3951\n",
      "Train Loss: 0.02084151241514418\n",
      "Val Loss: 0.021325162715382047\n",
      "Starting epoch 3952\n",
      "Train Loss: 0.02084389439335576\n",
      "Val Loss: 0.020850192065592164\n",
      "Starting epoch 3953\n",
      "Train Loss: 0.020840616137893113\n",
      "Val Loss: 0.020854278295128433\n",
      "Starting epoch 3954\n",
      "Train Loss: 0.020836813030419527\n",
      "Val Loss: 0.02086492379506429\n",
      "Starting epoch 3955\n",
      "Train Loss: 0.02132055660088857\n",
      "Val Loss: 0.020834994536859018\n",
      "Starting epoch 3956\n",
      "Train Loss: 0.02090241732420745\n",
      "Val Loss: 0.02084454342170998\n",
      "Starting epoch 3957\n",
      "Train Loss: 0.020905027786890667\n",
      "Val Loss: 0.020832055696734676\n",
      "Starting epoch 3958\n",
      "Train Loss: 0.021361429934148437\n",
      "Val Loss: 0.020837153549547547\n",
      "Starting epoch 3959\n",
      "Train Loss: 0.02090019208413583\n",
      "Val Loss: 0.020881405583134404\n",
      "Starting epoch 3960\n",
      "Train Loss: 0.02083392662030679\n",
      "Val Loss: 0.020839666326840717\n",
      "Starting epoch 3961\n",
      "Train Loss: 0.02083459386119136\n",
      "Val Loss: 0.020893604667098435\n",
      "Starting epoch 3962\n",
      "Train Loss: 0.020838415181195294\n",
      "Val Loss: 0.02089919205065127\n",
      "Starting epoch 3963\n",
      "Train Loss: 0.020835920064537612\n",
      "Val Loss: 0.020832210779190063\n",
      "Starting epoch 3964\n",
      "Train Loss: 0.02083579644008919\n",
      "Val Loss: 0.020841194523705378\n",
      "Starting epoch 3965\n",
      "Train Loss: 0.0208322587940428\n",
      "Val Loss: 0.020835197082272282\n",
      "Starting epoch 3966\n",
      "Train Loss: 0.020859685209062364\n",
      "Val Loss: 0.02084131262920521\n",
      "Starting epoch 3967\n",
      "Train Loss: 0.020845501511185256\n",
      "Val Loss: 0.020850950369128474\n",
      "Starting epoch 3968\n",
      "Train Loss: 0.020842157580234385\n",
      "Val Loss: 0.02089471673523938\n",
      "Starting epoch 3969\n",
      "Train Loss: 0.02090317176447974\n",
      "Val Loss: 0.02083452708191342\n",
      "Starting epoch 3970\n",
      "Train Loss: 0.020920205999303748\n",
      "Val Loss: 0.020833387419029518\n",
      "Starting epoch 3971\n",
      "Train Loss: 0.020894897204858286\n",
      "Val Loss: 0.020892133315404255\n",
      "Starting epoch 3972\n",
      "Train Loss: 0.020831940902604\n",
      "Val Loss: 0.0213366421284499\n",
      "Starting epoch 3973\n",
      "Train Loss: 0.02084203064441681\n",
      "Val Loss: 0.021303033387219464\n",
      "Starting epoch 3974\n",
      "Train Loss: 0.020885969753618592\n",
      "Val Loss: 0.02083964921810009\n",
      "Starting epoch 3975\n",
      "Train Loss: 0.02090097908620481\n",
      "Val Loss: 0.020842079763059265\n",
      "Starting epoch 3976\n",
      "Train Loss: 0.021303352382447984\n",
      "Val Loss: 0.020852864340499596\n",
      "Starting epoch 3977\n",
      "Train Loss: 0.02083344371230514\n",
      "Val Loss: 0.020897132930932222\n",
      "Starting epoch 3978\n",
      "Train Loss: 0.02084113547095546\n",
      "Val Loss: 0.021300010107181692\n",
      "Starting epoch 3979\n",
      "Train Loss: 0.020838186696723656\n",
      "Val Loss: 0.021358840995364718\n",
      "Starting epoch 3980\n",
      "Train Loss: 0.020848698638103628\n",
      "Val Loss: 0.021367600118672406\n",
      "Starting epoch 3981\n",
      "Train Loss: 0.02083108877694165\n",
      "Val Loss: 0.02083845160625599\n",
      "Starting epoch 3982\n",
      "Train Loss: 0.020835338919251052\n",
      "Val Loss: 0.020836352198212234\n",
      "Starting epoch 3983\n",
      "Train Loss: 0.02083375718858507\n",
      "Val Loss: 0.021312884710453176\n",
      "Starting epoch 3984\n",
      "Train Loss: 0.02084401305075045\n",
      "Val Loss: 0.02083261697380631\n",
      "Starting epoch 3985\n",
      "Train Loss: 0.020901989605691697\n",
      "Val Loss: 0.021313994571014686\n",
      "Starting epoch 3986\n",
      "Train Loss: 0.02088749408721924\n",
      "Val Loss: 0.020942789536935312\n",
      "Starting epoch 3987\n",
      "Train Loss: 0.020909212253711843\n",
      "Val Loss: 0.020850818466257165\n",
      "Starting epoch 3988\n",
      "Train Loss: 0.020840773427927936\n",
      "Val Loss: 0.020832732871726708\n",
      "Starting epoch 3989\n",
      "Train Loss: 0.02084376249048445\n",
      "Val Loss: 0.020832419395446777\n",
      "Starting epoch 3990\n",
      "Train Loss: 0.020852094447171246\n",
      "Val Loss: 0.020850814051098294\n",
      "Starting epoch 3991\n",
      "Train Loss: 0.02133102439067982\n",
      "Val Loss: 0.020869643599898728\n",
      "Starting epoch 3992\n",
      "Train Loss: 0.020858150941354257\n",
      "Val Loss: 0.02083638862327293\n",
      "Starting epoch 3993\n",
      "Train Loss: 0.020846289617043955\n",
      "Val Loss: 0.020939590754332365\n",
      "Starting epoch 3994\n",
      "Train Loss: 0.020882536967595417\n",
      "Val Loss: 0.020834398490411264\n",
      "Starting epoch 3995\n",
      "Train Loss: 0.020892038389488502\n",
      "Val Loss: 0.020829621840406348\n",
      "Starting epoch 3996\n",
      "Train Loss: 0.020848980104481732\n",
      "Val Loss: 0.020847451907617075\n",
      "Starting epoch 3997\n",
      "Train Loss: 0.020874895431377268\n",
      "Val Loss: 0.020836396901695815\n",
      "Starting epoch 3998\n",
      "Train Loss: 0.020831707451078627\n",
      "Val Loss: 0.02132643207355782\n",
      "Starting epoch 3999\n",
      "Train Loss: 0.02085251443915897\n",
      "Val Loss: 0.020836074595098144\n",
      "Starting epoch 4000\n",
      "Train Loss: 0.020846116322058218\n",
      "Val Loss: 0.021333939499325223\n",
      "Starting epoch 4001\n",
      "Train Loss: 0.020879159371058147\n",
      "Val Loss: 0.02083846374794289\n",
      "Starting epoch 4002\n",
      "Train Loss: 0.020842090800956444\n",
      "Val Loss: 0.020861440786608943\n",
      "Starting epoch 4003\n",
      "Train Loss: 0.020833376933027198\n",
      "Val Loss: 0.021309026965388545\n",
      "Starting epoch 4004\n",
      "Train Loss: 0.020833678819515086\n",
      "Val Loss: 0.020869919547328242\n",
      "Starting epoch 4005\n",
      "Train Loss: 0.020834168902149907\n",
      "Val Loss: 0.02091330952114529\n",
      "Starting epoch 4006\n",
      "Train Loss: 0.020830285218026903\n",
      "Val Loss: 0.020854199926058452\n",
      "Starting epoch 4007\n",
      "Train Loss: 0.020832817863534997\n",
      "Val Loss: 0.020841901501019795\n",
      "Starting epoch 4008\n",
      "Train Loss: 0.0208348438695625\n",
      "Val Loss: 0.02084128889772627\n",
      "Starting epoch 4009\n",
      "Train Loss: 0.0208857258160909\n",
      "Val Loss: 0.021307959048836318\n",
      "Starting epoch 4010\n",
      "Train Loss: 0.020850567905991164\n",
      "Val Loss: 0.020831897854804993\n",
      "Starting epoch 4011\n",
      "Train Loss: 0.021303989269115305\n",
      "Val Loss: 0.020837798714637756\n",
      "Starting epoch 4012\n",
      "Train Loss: 0.02083798967025898\n",
      "Val Loss: 0.020845298413877136\n",
      "Starting epoch 4013\n",
      "Train Loss: 0.020834098259607952\n",
      "Val Loss: 0.02083097067144182\n",
      "Starting epoch 4014\n",
      "Train Loss: 0.020879388407424645\n",
      "Val Loss: 0.020833114782969158\n",
      "Starting epoch 4015\n",
      "Train Loss: 0.020828114063651475\n",
      "Val Loss: 0.020903734697235957\n",
      "Starting epoch 4016\n",
      "Train Loss: 0.02088760722566534\n",
      "Val Loss: 0.0213106495362741\n",
      "Starting epoch 4017\n",
      "Train Loss: 0.021302732052626432\n",
      "Val Loss: 0.020838819720126963\n",
      "Starting epoch 4018\n",
      "Train Loss: 0.02083555084687692\n",
      "Val Loss: 0.02083800236384074\n",
      "Starting epoch 4019\n",
      "Train Loss: 0.020900704242565012\n",
      "Val Loss: 0.020831059526514123\n",
      "Starting epoch 4020\n",
      "Train Loss: 0.02084745577088109\n",
      "Val Loss: 0.02085590859254201\n",
      "Starting epoch 4021\n",
      "Train Loss: 0.02083693610297309\n",
      "Val Loss: 0.02087759033397392\n",
      "Starting epoch 4022\n",
      "Train Loss: 0.020833697032045434\n",
      "Val Loss: 0.020830698587276316\n",
      "Starting epoch 4023\n",
      "Train Loss: 0.02083535050904309\n",
      "Val Loss: 0.020837674538294475\n",
      "Starting epoch 4024\n",
      "Train Loss: 0.020908987632504216\n",
      "Val Loss: 0.020833279799532006\n",
      "Starting epoch 4025\n",
      "Train Loss: 0.02084268022466589\n",
      "Val Loss: 0.021352586370927316\n",
      "Starting epoch 4026\n",
      "Train Loss: 0.020886409613821242\n",
      "Val Loss: 0.020847401685184903\n",
      "Starting epoch 4027\n",
      "Train Loss: 0.020836408491487855\n",
      "Val Loss: 0.020832661125395033\n",
      "Starting epoch 4028\n",
      "Train Loss: 0.020900596071172645\n",
      "Val Loss: 0.020852700427726464\n",
      "Starting epoch 4029\n",
      "Train Loss: 0.02086024096718541\n",
      "Val Loss: 0.020847684255352727\n",
      "Starting epoch 4030\n",
      "Train Loss: 0.020839578575558133\n",
      "Val Loss: 0.020831344856156245\n",
      "Starting epoch 4031\n",
      "Train Loss: 0.020827883923495258\n",
      "Val Loss: 0.02134855091571808\n",
      "Starting epoch 4032\n",
      "Train Loss: 0.020833207501305476\n",
      "Val Loss: 0.020838316943910386\n",
      "Starting epoch 4033\n",
      "Train Loss: 0.02082752739941632\n",
      "Val Loss: 0.02130262664070836\n",
      "Starting epoch 4034\n",
      "Train Loss: 0.021307509806421068\n",
      "Val Loss: 0.020843383890611154\n",
      "Starting epoch 4035\n",
      "Train Loss: 0.02090396594118189\n",
      "Val Loss: 0.021310945351918537\n",
      "Starting epoch 4036\n",
      "Train Loss: 0.02083938154909346\n",
      "Val Loss: 0.020832540812315763\n",
      "Starting epoch 4037\n",
      "Train Loss: 0.020851446522606745\n",
      "Val Loss: 0.020883358739040517\n",
      "Starting epoch 4038\n",
      "Train Loss: 0.020833805755332665\n",
      "Val Loss: 0.02084098866692296\n",
      "Starting epoch 4039\n",
      "Train Loss: 0.020890881617863972\n",
      "Val Loss: 0.020826460586653814\n",
      "Starting epoch 4040\n",
      "Train Loss: 0.02130908049918987\n",
      "Val Loss: 0.02090805106692844\n",
      "Starting epoch 4041\n",
      "Train Loss: 0.02083683234673959\n",
      "Val Loss: 0.020835997329817876\n",
      "Starting epoch 4042\n",
      "Train Loss: 0.0208948431191621\n",
      "Val Loss: 0.0208972477250629\n",
      "Starting epoch 4043\n",
      "Train Loss: 0.02090745943563956\n",
      "Val Loss: 0.02089517370418266\n",
      "Starting epoch 4044\n",
      "Train Loss: 0.02130547938523469\n",
      "Val Loss: 0.020845451840647945\n",
      "Starting epoch 4045\n",
      "Train Loss: 0.020882503853903875\n",
      "Val Loss: 0.020830921000904508\n",
      "Starting epoch 4046\n",
      "Train Loss: 0.020835590031411912\n",
      "Val Loss: 0.020828649401664734\n",
      "Starting epoch 4047\n",
      "Train Loss: 0.02083587094589516\n",
      "Val Loss: 0.020851195962340745\n",
      "Starting epoch 4048\n",
      "Train Loss: 0.020829794583497225\n",
      "Val Loss: 0.02084583706325955\n",
      "Starting epoch 4049\n",
      "Train Loss: 0.020843200661517954\n",
      "Val Loss: 0.020825897653897602\n",
      "Starting epoch 4050\n",
      "Train Loss: 0.02082798381646474\n",
      "Val Loss: 0.02129990303957904\n",
      "Starting epoch 4051\n",
      "Train Loss: 0.020837347264643067\n",
      "Val Loss: 0.020904041550777578\n",
      "Starting epoch 4052\n",
      "Train Loss: 0.020878208456216036\n",
      "Val Loss: 0.020832111438115437\n",
      "Starting epoch 4053\n",
      "Train Loss: 0.020835782090822857\n",
      "Val Loss: 0.02129860884613461\n",
      "Starting epoch 4054\n",
      "Train Loss: 0.02083638972706265\n",
      "Val Loss: 0.02086524886113626\n",
      "Starting epoch 4055\n",
      "Train Loss: 0.020826650438485323\n",
      "Val Loss: 0.021313090567235595\n",
      "Starting epoch 4056\n",
      "Train Loss: 0.02084349537337268\n",
      "Val Loss: 0.020839069728498107\n",
      "Starting epoch 4057\n",
      "Train Loss: 0.021297030978732638\n",
      "Val Loss: 0.020828260867683974\n",
      "Starting epoch 4058\n",
      "Train Loss: 0.0208274832478276\n",
      "Val Loss: 0.020893005861176386\n",
      "Starting epoch 4059\n",
      "Train Loss: 0.02089000134556382\n",
      "Val Loss: 0.020850937123651856\n",
      "Starting epoch 4060\n",
      "Train Loss: 0.020835137477627507\n",
      "Val Loss: 0.02082584301630656\n",
      "Starting epoch 4061\n",
      "Train Loss: 0.02089639835887485\n",
      "Val Loss: 0.02083392662030679\n",
      "Starting epoch 4062\n",
      "Train Loss: 0.02083065719516189\n",
      "Val Loss: 0.020834740665223863\n",
      "Starting epoch 4063\n",
      "Train Loss: 0.020877285688011733\n",
      "Val Loss: 0.020850883037955674\n",
      "Starting epoch 4064\n",
      "Train Loss: 0.020828518602583144\n",
      "Val Loss: 0.02083961334493425\n",
      "Starting epoch 4065\n",
      "Train Loss: 0.020875041131620056\n",
      "Val Loss: 0.020847093727853563\n",
      "Starting epoch 4066\n",
      "Train Loss: 0.02083089119858212\n",
      "Val Loss: 0.0208273336843208\n",
      "Starting epoch 4067\n",
      "Train Loss: 0.02082869852030719\n",
      "Val Loss: 0.020830999921869348\n",
      "Starting epoch 4068\n",
      "Train Loss: 0.02083879874812232\n",
      "Val Loss: 0.02084193847797535\n",
      "Starting epoch 4069\n",
      "Train Loss: 0.020847200795456215\n",
      "Val Loss: 0.021365303684163978\n",
      "Starting epoch 4070\n",
      "Train Loss: 0.020832677130345947\n",
      "Val Loss: 0.020884824571786104\n",
      "Starting epoch 4071\n",
      "Train Loss: 0.020828724459365563\n",
      "Val Loss: 0.020839841277511033\n",
      "Starting epoch 4072\n",
      "Train Loss: 0.02085922713632937\n",
      "Val Loss: 0.020827269664517156\n",
      "Starting epoch 4073\n",
      "Train Loss: 0.020835596102255362\n",
      "Val Loss: 0.02082734803358714\n",
      "Starting epoch 4074\n",
      "Train Loss: 0.02083458447897876\n",
      "Val Loss: 0.020830737219916448\n",
      "Starting epoch 4075\n",
      "Train Loss: 0.02084324370931696\n",
      "Val Loss: 0.02084650264845954\n",
      "Starting epoch 4076\n",
      "Train Loss: 0.020901438814622385\n",
      "Val Loss: 0.020870041516092088\n",
      "Starting epoch 4077\n",
      "Train Loss: 0.020825759680182847\n",
      "Val Loss: 0.02085715863439772\n",
      "Starting epoch 4078\n",
      "Train Loss: 0.0208856463432312\n",
      "Val Loss: 0.020827117893430922\n",
      "Starting epoch 4079\n",
      "Train Loss: 0.02082922226852841\n",
      "Val Loss: 0.020848299618120545\n",
      "Starting epoch 4080\n",
      "Train Loss: 0.02130992545021905\n",
      "Val Loss: 0.021309636257312917\n",
      "Starting epoch 4081\n",
      "Train Loss: 0.02129438077961957\n",
      "Val Loss: 0.02089063271328255\n",
      "Starting epoch 4082\n",
      "Train Loss: 0.02129738253575784\n",
      "Val Loss: 0.021293986174795363\n",
      "Starting epoch 4083\n",
      "Train Loss: 0.02088143593735165\n",
      "Val Loss: 0.02130697888356668\n",
      "Starting epoch 4084\n",
      "Train Loss: 0.021373049528510484\n",
      "Val Loss: 0.02087881609245583\n",
      "Starting epoch 4085\n",
      "Train Loss: 0.020877742656955012\n",
      "Val Loss: 0.020824198921521504\n",
      "Starting epoch 4086\n",
      "Train Loss: 0.020830706865699204\n",
      "Val Loss: 0.020826525158352323\n",
      "Starting epoch 4087\n",
      "Train Loss: 0.02083331843217214\n",
      "Val Loss: 0.020843383338716295\n",
      "Starting epoch 4088\n",
      "Train Loss: 0.020829577136922767\n",
      "Val Loss: 0.02087641700550362\n",
      "Starting epoch 4089\n",
      "Train Loss: 0.020843598577711318\n",
      "Val Loss: 0.020825150388258475\n",
      "Starting epoch 4090\n",
      "Train Loss: 0.0208252160637467\n",
      "Val Loss: 0.020830563373035856\n",
      "Starting epoch 4091\n",
      "Train Loss: 0.020823766787846882\n",
      "Val Loss: 0.020839206598423147\n",
      "Starting epoch 4092\n",
      "Train Loss: 0.02083438966009352\n",
      "Val Loss: 0.020824232587107906\n",
      "Starting epoch 4093\n",
      "Train Loss: 0.021296980756300467\n",
      "Val Loss: 0.020847501578154386\n",
      "Starting epoch 4094\n",
      "Train Loss: 0.020851070682207744\n",
      "Val Loss: 0.020883560180664062\n",
      "Starting epoch 4095\n",
      "Train Loss: 0.020828787375379493\n",
      "Val Loss: 0.02083537589620661\n",
      "Starting epoch 4096\n",
      "Train Loss: 0.020842965554308007\n",
      "Val Loss: 0.020823132108758996\n",
      "Starting epoch 4097\n",
      "Train Loss: 0.02083962107146228\n",
      "Val Loss: 0.0208741150520466\n",
      "Starting epoch 4098\n",
      "Train Loss: 0.02082631709399047\n",
      "Val Loss: 0.020838637042928626\n",
      "Starting epoch 4099\n",
      "Train Loss: 0.020837394175706087\n",
      "Val Loss: 0.02082499861717224\n",
      "Starting epoch 4100\n",
      "Train Loss: 0.02082921619768496\n",
      "Val Loss: 0.020879319972462125\n",
      "Starting epoch 4101\n",
      "Train Loss: 0.020824319234600774\n",
      "Val Loss: 0.0208357329721804\n",
      "Starting epoch 4102\n",
      "Train Loss: 0.020877043958063477\n",
      "Val Loss: 0.020834199808262014\n",
      "Starting epoch 4103\n",
      "Train Loss: 0.02083153360419803\n",
      "Val Loss: 0.02086708943049113\n",
      "Starting epoch 4104\n",
      "Train Loss: 0.020835761118818213\n",
      "Val Loss: 0.02082318122740145\n",
      "Starting epoch 4105\n",
      "Train Loss: 0.020845002598232694\n",
      "Val Loss: 0.020832299634262367\n",
      "Starting epoch 4106\n",
      "Train Loss: 0.02082617194564254\n",
      "Val Loss: 0.020896965706789936\n",
      "Starting epoch 4107\n",
      "Train Loss: 0.020847406652238634\n",
      "Val Loss: 0.020831863085428875\n",
      "Starting epoch 4108\n",
      "Train Loss: 0.02082888450887468\n",
      "Val Loss: 0.02082540425989363\n",
      "Starting epoch 4109\n",
      "Train Loss: 0.02132093796023616\n",
      "Val Loss: 0.02137614621056451\n",
      "Starting epoch 4110\n",
      "Train Loss: 0.020837832932119018\n",
      "Val Loss: 0.02088215340066839\n",
      "Starting epoch 4111\n",
      "Train Loss: 0.020824791656600103\n",
      "Val Loss: 0.02082409350960343\n",
      "Starting epoch 4112\n",
      "Train Loss: 0.020893888892950834\n",
      "Val Loss: 0.020837023854255676\n",
      "Starting epoch 4113\n",
      "Train Loss: 0.0208270858835291\n",
      "Val Loss: 0.02083044526753602\n",
      "Starting epoch 4114\n",
      "Train Loss: 0.02088217161319874\n",
      "Val Loss: 0.020843285101431387\n",
      "Starting epoch 4115\n",
      "Train Loss: 0.02088108934738018\n",
      "Val Loss: 0.02088380632577119\n",
      "Starting epoch 4116\n",
      "Train Loss: 0.020822374909012405\n",
      "Val Loss: 0.02082467465488999\n",
      "Starting epoch 4117\n",
      "Train Loss: 0.020826012448028283\n",
      "Val Loss: 0.020863429815680894\n",
      "Starting epoch 4118\n",
      "Train Loss: 0.020825992579813355\n",
      "Val Loss: 0.020842937959565058\n",
      "Starting epoch 4119\n",
      "Train Loss: 0.020892366215034767\n",
      "Val Loss: 0.02130844306062769\n",
      "Starting epoch 4120\n",
      "Train Loss: 0.02082219609507808\n",
      "Val Loss: 0.02082197478523961\n",
      "Starting epoch 4121\n",
      "Train Loss: 0.020838578542073567\n",
      "Val Loss: 0.020841336360684148\n",
      "Starting epoch 4122\n",
      "Train Loss: 0.020841469367345173\n",
      "Val Loss: 0.020823236416887353\n",
      "Starting epoch 4123\n",
      "Train Loss: 0.020824226516264456\n",
      "Val Loss: 0.020841241986663255\n",
      "Starting epoch 4124\n",
      "Train Loss: 0.020824069226229633\n",
      "Val Loss: 0.020821795419410424\n",
      "Starting epoch 4125\n",
      "Train Loss: 0.020830082672613638\n",
      "Val Loss: 0.02088357287424582\n",
      "Starting epoch 4126\n",
      "Train Loss: 0.02082972945990386\n",
      "Val Loss: 0.0208852826445191\n",
      "Starting epoch 4127\n",
      "Train Loss: 0.020832750532362197\n",
      "Val Loss: 0.020821120451997827\n",
      "Starting epoch 4128\n",
      "Train Loss: 0.02082106802198622\n",
      "Val Loss: 0.020829180324519123\n",
      "Starting epoch 4129\n",
      "Train Loss: 0.020821155221373948\n",
      "Val Loss: 0.02083083380151678\n",
      "Starting epoch 4130\n",
      "Train Loss: 0.021318223189424584\n",
      "Val Loss: 0.020821804249728168\n",
      "Starting epoch 4131\n",
      "Train Loss: 0.02086687253581153\n",
      "Val Loss: 0.020825487044122484\n",
      "Starting epoch 4132\n",
      "Train Loss: 0.020823617224340087\n",
      "Val Loss: 0.020829560028182134\n",
      "Starting epoch 4133\n",
      "Train Loss: 0.020878144988307246\n",
      "Val Loss: 0.021311444264871103\n",
      "Starting epoch 4134\n",
      "Train Loss: 0.020823378253866126\n",
      "Val Loss: 0.020852835090072068\n",
      "Starting epoch 4135\n",
      "Train Loss: 0.020822083508526837\n",
      "Val Loss: 0.020821275534453215\n",
      "Starting epoch 4136\n",
      "Train Loss: 0.020847103110066167\n",
      "Val Loss: 0.02082771725124783\n",
      "Starting epoch 4137\n",
      "Train Loss: 0.020831977327664692\n",
      "Val Loss: 0.02086398943706795\n",
      "Starting epoch 4138\n",
      "Train Loss: 0.020834716933744925\n",
      "Val Loss: 0.020833668885407625\n",
      "Starting epoch 4139\n",
      "Train Loss: 0.020845417623166686\n",
      "Val Loss: 0.02082487444082896\n",
      "Starting epoch 4140\n",
      "Train Loss: 0.020825031730863783\n",
      "Val Loss: 0.020832529774418584\n",
      "Starting epoch 4141\n",
      "Train Loss: 0.0208424820944115\n",
      "Val Loss: 0.02082006522902736\n",
      "Starting epoch 4142\n",
      "Train Loss: 0.020835481308124685\n",
      "Val Loss: 0.020841264062457614\n",
      "Starting epoch 4143\n",
      "Train Loss: 0.020821820806573937\n",
      "Val Loss: 0.02082295936566812\n",
      "Starting epoch 4144\n",
      "Train Loss: 0.020823906417246216\n",
      "Val Loss: 0.020827442959502892\n",
      "Starting epoch 4145\n",
      "Train Loss: 0.02082914776272244\n",
      "Val Loss: 0.020877734378532128\n",
      "Starting epoch 4146\n",
      "Train Loss: 0.0208734307024214\n",
      "Val Loss: 0.02083799022215384\n",
      "Starting epoch 4147\n",
      "Train Loss: 0.02086771583115613\n",
      "Val Loss: 0.020832029205781442\n",
      "Starting epoch 4148\n",
      "Train Loss: 0.02086474166976081\n",
      "Val Loss: 0.02082342682061372\n",
      "Starting epoch 4149\n",
      "Train Loss: 0.020824344621764287\n",
      "Val Loss: 0.020830454097853765\n",
      "Starting epoch 4150\n",
      "Train Loss: 0.021295774314138625\n",
      "Val Loss: 0.02082352836926778\n",
      "Starting epoch 4151\n",
      "Train Loss: 0.020849401752154034\n",
      "Val Loss: 0.02087674151968073\n",
      "Starting epoch 4152\n",
      "Train Loss: 0.020869411252163076\n",
      "Val Loss: 0.02082281090595104\n",
      "Starting epoch 4153\n",
      "Train Loss: 0.021338832047250535\n",
      "Val Loss: 0.020829411016570196\n",
      "Starting epoch 4154\n",
      "Train Loss: 0.021315532701986807\n",
      "Val Loss: 0.021370537303112173\n",
      "Starting epoch 4155\n",
      "Train Loss: 0.020840828617413838\n",
      "Val Loss: 0.020829543471336365\n",
      "Starting epoch 4156\n",
      "Train Loss: 0.02082668520786144\n",
      "Val Loss: 0.020824388773353013\n",
      "Starting epoch 4157\n",
      "Train Loss: 0.020822403607545076\n",
      "Val Loss: 0.020831907237017597\n",
      "Starting epoch 4158\n",
      "Train Loss: 0.020819851093822055\n",
      "Val Loss: 0.020924294988314312\n",
      "Starting epoch 4159\n",
      "Train Loss: 0.0208270279345689\n",
      "Val Loss: 0.020844922021583275\n",
      "Starting epoch 4160\n",
      "Train Loss: 0.020818938811620075\n",
      "Val Loss: 0.021292311173898203\n",
      "Starting epoch 4161\n",
      "Train Loss: 0.02082197864850362\n",
      "Val Loss: 0.020821270015504625\n",
      "Starting epoch 4162\n",
      "Train Loss: 0.020842652629922936\n",
      "Val Loss: 0.020828318816644174\n",
      "Starting epoch 4163\n",
      "Train Loss: 0.02084173869203638\n",
      "Val Loss: 0.02082528449870922\n",
      "Starting epoch 4164\n",
      "Train Loss: 0.02084653189888707\n",
      "Val Loss: 0.02083803106237341\n",
      "Starting epoch 4165\n",
      "Train Loss: 0.020875126123428345\n",
      "Val Loss: 0.020827772440733732\n",
      "Starting epoch 4166\n",
      "Train Loss: 0.020829485522376165\n",
      "Val Loss: 0.021293067269855075\n",
      "Starting epoch 4167\n",
      "Train Loss: 0.02088658290880698\n",
      "Val Loss: 0.02083479475092005\n",
      "Starting epoch 4168\n",
      "Train Loss: 0.0208491247009348\n",
      "Val Loss: 0.020821600600525184\n",
      "Starting epoch 4169\n",
      "Train Loss: 0.020822650304547063\n",
      "Val Loss: 0.02130257365880189\n",
      "Starting epoch 4170\n",
      "Train Loss: 0.020823606738337764\n",
      "Val Loss: 0.02083052749987002\n",
      "Starting epoch 4171\n",
      "Train Loss: 0.02085195592156163\n",
      "Val Loss: 0.021363594465785556\n",
      "Starting epoch 4172\n",
      "Train Loss: 0.020823708286991826\n",
      "Val Loss: 0.021291722302083618\n",
      "Starting epoch 4173\n",
      "Train Loss: 0.020837446605717694\n",
      "Val Loss: 0.020830786890453763\n",
      "Starting epoch 4174\n",
      "Train Loss: 0.0209262039926317\n",
      "Val Loss: 0.020836484652978403\n",
      "Starting epoch 4175\n",
      "Train Loss: 0.020881273128368235\n",
      "Val Loss: 0.020934236822304903\n",
      "Starting epoch 4176\n",
      "Train Loss: 0.020817555211208486\n",
      "Val Loss: 0.020821924562807435\n",
      "Starting epoch 4177\n",
      "Train Loss: 0.020825058773711876\n",
      "Val Loss: 0.020826848016844854\n",
      "Starting epoch 4178\n",
      "Train Loss: 0.020831581619050767\n",
      "Val Loss: 0.02082002935586152\n",
      "Starting epoch 4179\n",
      "Train Loss: 0.02082202390388206\n",
      "Val Loss: 0.02128905333854534\n",
      "Starting epoch 4180\n",
      "Train Loss: 0.020822852849960327\n",
      "Val Loss: 0.020829661576836196\n",
      "Starting epoch 4181\n",
      "Train Loss: 0.02082209289073944\n",
      "Val Loss: 0.02082312548602069\n",
      "Starting epoch 4182\n",
      "Train Loss: 0.020831384040691233\n",
      "Val Loss: 0.020844392754413462\n",
      "Starting epoch 4183\n",
      "Train Loss: 0.020822408574598807\n",
      "Val Loss: 0.020835406802318716\n",
      "Starting epoch 4184\n",
      "Train Loss: 0.020818107657962374\n",
      "Val Loss: 0.020843080900333547\n",
      "Starting epoch 4185\n",
      "Train Loss: 0.020885380329909147\n",
      "Val Loss: 0.02081927822695838\n",
      "Starting epoch 4186\n",
      "Train Loss: 0.020827450686030917\n",
      "Val Loss: 0.02082331809732649\n",
      "Starting epoch 4187\n",
      "Train Loss: 0.02086979537098496\n",
      "Val Loss: 0.020825958914226957\n",
      "Starting epoch 4188\n",
      "Train Loss: 0.02129564627453133\n",
      "Val Loss: 0.020828523569636874\n",
      "Starting epoch 4189\n",
      "Train Loss: 0.020865143449218186\n",
      "Val Loss: 0.0208186623122957\n",
      "Starting epoch 4190\n",
      "Train Loss: 0.020824733155745047\n",
      "Val Loss: 0.02081760322606122\n",
      "Starting epoch 4191\n",
      "Train Loss: 0.020829287944016634\n",
      "Val Loss: 0.020818905146033677\n",
      "Starting epoch 4192\n",
      "Train Loss: 0.02081881297959222\n",
      "Val Loss: 0.020823239176361648\n",
      "Starting epoch 4193\n",
      "Train Loss: 0.020822197750762658\n",
      "Val Loss: 0.02082352450600377\n",
      "Starting epoch 4194\n",
      "Train Loss: 0.020921369945561444\n",
      "Val Loss: 0.02087048579145361\n",
      "Starting epoch 4195\n",
      "Train Loss: 0.02130840884314643\n",
      "Val Loss: 0.020881627996762592\n",
      "Starting epoch 4196\n",
      "Train Loss: 0.02082392131840741\n",
      "Val Loss: 0.020876892186977244\n",
      "Starting epoch 4197\n",
      "Train Loss: 0.02082503393844322\n",
      "Val Loss: 0.02081893770783036\n",
      "Starting epoch 4198\n",
      "Train Loss: 0.02082493680494803\n",
      "Val Loss: 0.020818257773364032\n",
      "Starting epoch 4199\n",
      "Train Loss: 0.020819179989673472\n",
      "Val Loss: 0.020817431034865202\n",
      "Starting epoch 4200\n",
      "Train Loss: 0.021345919481030217\n",
      "Val Loss: 0.020841865627853957\n",
      "Starting epoch 4201\n",
      "Train Loss: 0.02082089748647478\n",
      "Val Loss: 0.020821368252789532\n",
      "Starting epoch 4202\n",
      "Train Loss: 0.020819514437958046\n",
      "Val Loss: 0.021292668249871995\n",
      "Starting epoch 4203\n",
      "Train Loss: 0.020822642026124178\n",
      "Val Loss: 0.020819334520234004\n",
      "Starting epoch 4204\n",
      "Train Loss: 0.020830733356652437\n",
      "Val Loss: 0.021302504120049654\n",
      "Starting epoch 4205\n",
      "Train Loss: 0.02083413192519435\n",
      "Val Loss: 0.02082632095725448\n",
      "Starting epoch 4206\n",
      "Train Loss: 0.020829891165097553\n",
      "Val Loss: 0.020828888372138695\n",
      "Starting epoch 4207\n",
      "Train Loss: 0.020838032166163128\n",
      "Val Loss: 0.02082013863104361\n",
      "Starting epoch 4208\n",
      "Train Loss: 0.020822801523738436\n",
      "Val Loss: 0.02083012130525377\n",
      "Starting epoch 4209\n",
      "Train Loss: 0.02081581839808711\n",
      "Val Loss: 0.020820538754816407\n",
      "Starting epoch 4210\n",
      "Train Loss: 0.021296697634237784\n",
      "Val Loss: 0.02087312991972323\n",
      "Starting epoch 4211\n",
      "Train Loss: 0.021291501544140005\n",
      "Val Loss: 0.021298525510010897\n",
      "Starting epoch 4212\n",
      "Train Loss: 0.020823503533999126\n",
      "Val Loss: 0.02083331291322355\n",
      "Starting epoch 4213\n",
      "Train Loss: 0.02081646301128246\n",
      "Val Loss: 0.02084459916309074\n",
      "Starting epoch 4214\n",
      "Train Loss: 0.020862830457863985\n",
      "Val Loss: 0.0208920505311754\n",
      "Starting epoch 4215\n",
      "Train Loss: 0.020830568340089586\n",
      "Val Loss: 0.02081996202468872\n",
      "Starting epoch 4216\n",
      "Train Loss: 0.0208255339551855\n",
      "Val Loss: 0.02081539454283538\n",
      "Starting epoch 4217\n",
      "Train Loss: 0.02082585902125747\n",
      "Val Loss: 0.02090440304191024\n",
      "Starting epoch 4218\n",
      "Train Loss: 0.020828089228382817\n",
      "Val Loss: 0.020820233005064505\n",
      "Starting epoch 4219\n",
      "Train Loss: 0.02082318619445518\n",
      "Val Loss: 0.020816459699913307\n",
      "Starting epoch 4220\n",
      "Train Loss: 0.02081822576346221\n",
      "Val Loss: 0.020822574143056518\n",
      "Starting epoch 4221\n",
      "Train Loss: 0.02130419236642343\n",
      "Val Loss: 0.020880054544519494\n",
      "Starting epoch 4222\n",
      "Train Loss: 0.020817847163588914\n",
      "Val Loss: 0.020818248391151428\n",
      "Starting epoch 4223\n",
      "Train Loss: 0.020849839404777245\n",
      "Val Loss: 0.0208363378489459\n",
      "Starting epoch 4224\n",
      "Train Loss: 0.02082702131183059\n",
      "Val Loss: 0.020822535510416382\n",
      "Starting epoch 4225\n",
      "Train Loss: 0.020825430750846863\n",
      "Val Loss: 0.020816096553096065\n",
      "Starting epoch 4226\n",
      "Train Loss: 0.020824562068338746\n",
      "Val Loss: 0.020818587254594872\n",
      "Starting epoch 4227\n",
      "Train Loss: 0.020836453746866296\n",
      "Val Loss: 0.02131004300382402\n",
      "Starting epoch 4228\n",
      "Train Loss: 0.020819421719621728\n",
      "Val Loss: 0.02082882324854533\n",
      "Starting epoch 4229\n",
      "Train Loss: 0.0208175254088861\n",
      "Val Loss: 0.020875166963647912\n",
      "Starting epoch 4230\n",
      "Train Loss: 0.020881501060945017\n",
      "Val Loss: 0.020819051950066177\n",
      "Starting epoch 4231\n",
      "Train Loss: 0.020872295454696373\n",
      "Val Loss: 0.02081652096024266\n",
      "Starting epoch 4232\n",
      "Train Loss: 0.020827708420930086\n",
      "Val Loss: 0.021287263543517503\n",
      "Starting epoch 4233\n",
      "Train Loss: 0.020884801944096882\n",
      "Val Loss: 0.02081725111714116\n",
      "Starting epoch 4234\n",
      "Train Loss: 0.02087330376660382\n",
      "Val Loss: 0.020818208654721577\n",
      "Starting epoch 4235\n",
      "Train Loss: 0.020891118932653358\n",
      "Val Loss: 0.020879472295443218\n",
      "Starting epoch 4236\n",
      "Train Loss: 0.020829248207586783\n",
      "Val Loss: 0.020821457107861836\n",
      "Starting epoch 4237\n",
      "Train Loss: 0.02081588683304963\n",
      "Val Loss: 0.020831834386896203\n",
      "Starting epoch 4238\n",
      "Train Loss: 0.02082505049528899\n",
      "Val Loss: 0.02082348973662765\n",
      "Starting epoch 4239\n",
      "Train Loss: 0.020868327882554796\n",
      "Val Loss: 0.020816826158099704\n",
      "Starting epoch 4240\n",
      "Train Loss: 0.020832579444955895\n",
      "Val Loss: 0.02087081527268445\n",
      "Starting epoch 4241\n",
      "Train Loss: 0.020816174922166048\n",
      "Val Loss: 0.0208142317003674\n",
      "Starting epoch 4242\n",
      "Train Loss: 0.020813915464613173\n",
      "Val Loss: 0.020816027566238685\n",
      "Starting epoch 4243\n",
      "Train Loss: 0.020816364222102694\n",
      "Val Loss: 0.02081438954229708\n",
      "Starting epoch 4244\n",
      "Train Loss: 0.020893393843262283\n",
      "Val Loss: 0.02083347185894295\n",
      "Starting epoch 4245\n",
      "Train Loss: 0.02082861739176291\n",
      "Val Loss: 0.02082490258746677\n",
      "Starting epoch 4246\n",
      "Train Loss: 0.020814582153602882\n",
      "Val Loss: 0.020822502396724844\n",
      "Starting epoch 4247\n",
      "Train Loss: 0.02082830391548298\n",
      "Val Loss: 0.020815274781650968\n",
      "Starting epoch 4248\n",
      "Train Loss: 0.020820651341367652\n",
      "Val Loss: 0.02086819487589377\n",
      "Starting epoch 4249\n",
      "Train Loss: 0.02088354031244914\n",
      "Val Loss: 0.020816193686591253\n",
      "Starting epoch 4250\n",
      "Train Loss: 0.02129377259148492\n",
      "Val Loss: 0.02082311334433379\n",
      "Starting epoch 4251\n",
      "Train Loss: 0.020817103761213797\n",
      "Val Loss: 0.020862857500712078\n",
      "Starting epoch 4252\n",
      "Train Loss: 0.02136127485169305\n",
      "Val Loss: 0.02082760466469659\n",
      "Starting epoch 4253\n",
      "Train Loss: 0.020833012682420236\n",
      "Val Loss: 0.02081491384241316\n",
      "Starting epoch 4254\n",
      "Train Loss: 0.02091439233885871\n",
      "Val Loss: 0.02130610081884596\n",
      "Starting epoch 4255\n",
      "Train Loss: 0.02129388904130017\n",
      "Val Loss: 0.02082209840968803\n",
      "Starting epoch 4256\n",
      "Train Loss: 0.02083253805284147\n",
      "Val Loss: 0.020827863503385474\n",
      "Starting epoch 4257\n",
      "Train Loss: 0.020825191228478042\n",
      "Val Loss: 0.020823781689008076\n",
      "Starting epoch 4258\n",
      "Train Loss: 0.020824730396270752\n",
      "Val Loss: 0.020818780417795533\n",
      "Starting epoch 4259\n",
      "Train Loss: 0.02082347262788702\n",
      "Val Loss: 0.020815561215082806\n",
      "Starting epoch 4260\n",
      "Train Loss: 0.020828130620497244\n",
      "Val Loss: 0.020857882720452768\n",
      "Starting epoch 4261\n",
      "Train Loss: 0.020815731198699387\n",
      "Val Loss: 0.02082519840311121\n",
      "Starting epoch 4262\n",
      "Train Loss: 0.020819551414913602\n",
      "Val Loss: 0.02081486196429641\n",
      "Starting epoch 4263\n",
      "Train Loss: 0.020877613513557998\n",
      "Val Loss: 0.020817986792988248\n",
      "Starting epoch 4264\n",
      "Train Loss: 0.020886759515161866\n",
      "Val Loss: 0.020879489404183847\n",
      "Starting epoch 4265\n",
      "Train Loss: 0.021332526648486103\n",
      "Val Loss: 0.020816358151259245\n",
      "Starting epoch 4266\n",
      "Train Loss: 0.02082470335342266\n",
      "Val Loss: 0.020827891098128423\n",
      "Starting epoch 4267\n",
      "Train Loss: 0.02082724427735364\n",
      "Val Loss: 0.02082385564291919\n",
      "Starting epoch 4268\n",
      "Train Loss: 0.020815863101570693\n",
      "Val Loss: 0.020815089344978333\n",
      "Starting epoch 4269\n",
      "Train Loss: 0.02082481152481503\n",
      "Val Loss: 0.0208199515386864\n",
      "Starting epoch 4270\n",
      "Train Loss: 0.020845286824085093\n",
      "Val Loss: 0.02128842141893175\n",
      "Starting epoch 4271\n",
      "Train Loss: 0.020815284163863572\n",
      "Val Loss: 0.020823104514016047\n",
      "Starting epoch 4272\n",
      "Train Loss: 0.020812373470377038\n",
      "Val Loss: 0.020826814903153315\n",
      "Starting epoch 4273\n",
      "Train Loss: 0.020813303965109366\n",
      "Val Loss: 0.020812192448863277\n",
      "Starting epoch 4274\n",
      "Train Loss: 0.02081468756552096\n",
      "Val Loss: 0.02081417319951234\n",
      "Starting epoch 4275\n",
      "Train Loss: 0.020821584595574275\n",
      "Val Loss: 0.02083540956179301\n",
      "Starting epoch 4276\n",
      "Train Loss: 0.02129454524428756\n",
      "Val Loss: 0.020818334486749437\n",
      "Starting epoch 4277\n",
      "Train Loss: 0.02082102166281806\n",
      "Val Loss: 0.02081989855677993\n",
      "Starting epoch 4278\n",
      "Train Loss: 0.020819803630864178\n",
      "Val Loss: 0.02081951719743234\n",
      "Starting epoch 4279\n",
      "Train Loss: 0.020830998266184772\n",
      "Val Loss: 0.020815109213193256\n",
      "Starting epoch 4280\n",
      "Train Loss: 0.02082874708705478\n",
      "Val Loss: 0.02081258429421319\n",
      "Starting epoch 4281\n",
      "Train Loss: 0.02082210944758521\n",
      "Val Loss: 0.020813270299522964\n",
      "Starting epoch 4282\n",
      "Train Loss: 0.020856787209157592\n",
      "Val Loss: 0.02081300649378035\n",
      "Starting epoch 4283\n",
      "Train Loss: 0.0208168167758871\n",
      "Val Loss: 0.020817114799110976\n",
      "Starting epoch 4284\n",
      "Train Loss: 0.0208132266998291\n",
      "Val Loss: 0.020811741550763447\n",
      "Starting epoch 4285\n",
      "Train Loss: 0.020812371262797603\n",
      "Val Loss: 0.020830996610500193\n",
      "Starting epoch 4286\n",
      "Train Loss: 0.0208716983044589\n",
      "Val Loss: 0.020815132944672195\n",
      "Starting epoch 4287\n",
      "Train Loss: 0.020820718672540452\n",
      "Val Loss: 0.020862592039284884\n",
      "Starting epoch 4288\n",
      "Train Loss: 0.020837284900523997\n",
      "Val Loss: 0.0208158818659959\n",
      "Starting epoch 4289\n",
      "Train Loss: 0.020816196997960407\n",
      "Val Loss: 0.020825029523284348\n",
      "Starting epoch 4290\n",
      "Train Loss: 0.020823356729966623\n",
      "Val Loss: 0.020815294097971032\n",
      "Starting epoch 4291\n",
      "Train Loss: 0.020864909997692815\n",
      "Val Loss: 0.021291009253925748\n",
      "Starting epoch 4292\n",
      "Train Loss: 0.020887484153111775\n",
      "Val Loss: 0.020814603125607525\n",
      "Starting epoch 4293\n",
      "Train Loss: 0.020814358084290115\n",
      "Val Loss: 0.020884130288053443\n",
      "Starting epoch 4294\n",
      "Train Loss: 0.02128302499100014\n",
      "Val Loss: 0.020827365142327768\n",
      "Starting epoch 4295\n",
      "Train Loss: 0.0208278469465397\n",
      "Val Loss: 0.020870626524642662\n",
      "Starting epoch 4296\n",
      "Train Loss: 0.020837133129437763\n",
      "Val Loss: 0.020845467293703998\n",
      "Starting epoch 4297\n",
      "Train Loss: 0.020843423627041006\n",
      "Val Loss: 0.02081442486356806\n",
      "Starting epoch 4298\n",
      "Train Loss: 0.020827583692691946\n",
      "Val Loss: 0.020811539557245042\n",
      "Starting epoch 4299\n",
      "Train Loss: 0.020860818801102816\n",
      "Val Loss: 0.02081273109824569\n",
      "Starting epoch 4300\n",
      "Train Loss: 0.021286402587537414\n",
      "Val Loss: 0.020810444597844726\n",
      "Starting epoch 4301\n",
      "Train Loss: 0.02087550582709136\n",
      "Val Loss: 0.020811862967632436\n",
      "Starting epoch 4302\n",
      "Train Loss: 0.021324948580176743\n",
      "Val Loss: 0.02082650308255796\n",
      "Starting epoch 4303\n",
      "Train Loss: 0.02082215470296365\n",
      "Val Loss: 0.020877803917284363\n",
      "Starting epoch 4304\n",
      "Train Loss: 0.020817590532479464\n",
      "Val Loss: 0.020888162983788386\n",
      "Starting epoch 4305\n",
      "Train Loss: 0.020823117207597802\n",
      "Val Loss: 0.020819792592967\n",
      "Starting epoch 4306\n",
      "Train Loss: 0.020885512784675316\n",
      "Val Loss: 0.02082570007553807\n",
      "Starting epoch 4307\n",
      "Train Loss: 0.02081714184195907\n",
      "Val Loss: 0.021289266921855784\n",
      "Starting epoch 4308\n",
      "Train Loss: 0.020822551515367296\n",
      "Val Loss: 0.020822162981386536\n",
      "Starting epoch 4309\n",
      "Train Loss: 0.02085359228981866\n",
      "Val Loss: 0.020812705159187317\n",
      "Starting epoch 4310\n",
      "Train Loss: 0.02082819739977519\n",
      "Val Loss: 0.02087859754209165\n",
      "Starting epoch 4311\n",
      "Train Loss: 0.02082591641832281\n",
      "Val Loss: 0.020820593392407452\n",
      "Starting epoch 4312\n",
      "Train Loss: 0.020813310035952815\n",
      "Val Loss: 0.020829502079221938\n",
      "Starting epoch 4313\n",
      "Train Loss: 0.02081052131123013\n",
      "Val Loss: 0.020810300001391658\n",
      "Starting epoch 4314\n",
      "Train Loss: 0.020832524807364854\n",
      "Val Loss: 0.020852258911839238\n",
      "Starting epoch 4315\n",
      "Train Loss: 0.020823298229111567\n",
      "Val Loss: 0.02081433159333688\n",
      "Starting epoch 4316\n",
      "Train Loss: 0.021287031747676707\n",
      "Val Loss: 0.020817040845199867\n",
      "Starting epoch 4317\n",
      "Train Loss: 0.02081051524038668\n",
      "Val Loss: 0.02085312262729362\n",
      "Starting epoch 4318\n",
      "Train Loss: 0.020811129499364783\n",
      "Val Loss: 0.020831890128276968\n",
      "Starting epoch 4319\n",
      "Train Loss: 0.020810221080426818\n",
      "Val Loss: 0.021286030058507568\n",
      "Starting epoch 4320\n",
      "Train Loss: 0.020820061917658204\n",
      "Val Loss: 0.021333323032767686\n",
      "Starting epoch 4321\n",
      "Train Loss: 0.02080995230763047\n",
      "Val Loss: 0.020835186044375103\n",
      "Starting epoch 4322\n",
      "Train Loss: 0.020812571600631432\n",
      "Val Loss: 0.020809336944862648\n",
      "Starting epoch 4323\n",
      "Train Loss: 0.020820569109033654\n",
      "Val Loss: 0.020811465603333933\n",
      "Starting epoch 4324\n",
      "Train Loss: 0.020820490188068815\n",
      "Val Loss: 0.020820470319853887\n",
      "Starting epoch 4325\n",
      "Train Loss: 0.02082547269485615\n",
      "Val Loss: 0.021290686395433214\n",
      "Starting epoch 4326\n",
      "Train Loss: 0.020824026730325487\n",
      "Val Loss: 0.021291274163458083\n",
      "Starting epoch 4327\n",
      "Train Loss: 0.020818630854288738\n",
      "Val Loss: 0.020811972242814523\n",
      "Starting epoch 4328\n",
      "Train Loss: 0.020826484318132752\n",
      "Val Loss: 0.02081733500515973\n",
      "Starting epoch 4329\n",
      "Train Loss: 0.020823488080943073\n",
      "Val Loss: 0.020813235530146846\n",
      "Starting epoch 4330\n",
      "Train Loss: 0.02081187566121419\n",
      "Val Loss: 0.0208222523883537\n",
      "Starting epoch 4331\n",
      "Train Loss: 0.020815171577312327\n",
      "Val Loss: 0.020810380578041077\n",
      "Starting epoch 4332\n",
      "Train Loss: 0.020811407654373733\n",
      "Val Loss: 0.02085412100509361\n",
      "Starting epoch 4333\n",
      "Train Loss: 0.02081544255768811\n",
      "Val Loss: 0.020822904728077078\n",
      "Starting epoch 4334\n",
      "Train Loss: 0.02082498813116992\n",
      "Val Loss: 0.020811436904801264\n",
      "Starting epoch 4335\n",
      "Train Loss: 0.0212855096216555\n",
      "Val Loss: 0.020824711079950684\n",
      "Starting epoch 4336\n",
      "Train Loss: 0.020822141457487037\n",
      "Val Loss: 0.020908565984831914\n",
      "Starting epoch 4337\n",
      "Train Loss: 0.020912829924512794\n",
      "Val Loss: 0.02080989546245999\n",
      "Starting epoch 4338\n",
      "Train Loss: 0.02081653641329871\n",
      "Val Loss: 0.02080981378202085\n",
      "Starting epoch 4339\n",
      "Train Loss: 0.020811590331572073\n",
      "Val Loss: 0.02080929058569449\n",
      "Starting epoch 4340\n",
      "Train Loss: 0.02080868129377012\n",
      "Val Loss: 0.02082905062922725\n",
      "Starting epoch 4341\n",
      "Train Loss: 0.0208236426115036\n",
      "Val Loss: 0.020809342463811237\n",
      "Starting epoch 4342\n",
      "Train Loss: 0.020825852398519164\n",
      "Val Loss: 0.0208246691359414\n",
      "Starting epoch 4343\n",
      "Train Loss: 0.02081118082558667\n",
      "Val Loss: 0.020864935936751188\n",
      "Starting epoch 4344\n",
      "Train Loss: 0.02129660767537576\n",
      "Val Loss: 0.02085008610177923\n",
      "Starting epoch 4345\n",
      "Train Loss: 0.02083144364533601\n",
      "Val Loss: 0.021297054158316717\n",
      "Starting epoch 4346\n",
      "Train Loss: 0.0208737850189209\n",
      "Val Loss: 0.02082272536224789\n",
      "Starting epoch 4347\n",
      "Train Loss: 0.020811015257128963\n",
      "Val Loss: 0.020809480989420856\n",
      "Starting epoch 4348\n",
      "Train Loss: 0.020810316558237427\n",
      "Val Loss: 0.020823635988765292\n",
      "Starting epoch 4349\n",
      "Train Loss: 0.02081857235343368\n",
      "Val Loss: 0.020859849121835496\n",
      "Starting epoch 4350\n",
      "Train Loss: 0.020856288296205026\n",
      "Val Loss: 0.02082721723450555\n",
      "Starting epoch 4351\n",
      "Train Loss: 0.020875000843295344\n",
      "Val Loss: 0.020815527549496404\n",
      "Starting epoch 4352\n",
      "Train Loss: 0.020809930783730966\n",
      "Val Loss: 0.0208177516857783\n",
      "Starting epoch 4353\n",
      "Train Loss: 0.021283777775587858\n",
      "Val Loss: 0.020820139734833328\n",
      "Starting epoch 4354\n",
      "Train Loss: 0.020821644752113906\n",
      "Val Loss: 0.020811628964212205\n",
      "Starting epoch 4355\n",
      "Train Loss: 0.020836111572053697\n",
      "Val Loss: 0.020815231733851962\n",
      "Starting epoch 4356\n",
      "Train Loss: 0.0208162698480818\n",
      "Val Loss: 0.020829054492491263\n",
      "Starting epoch 4357\n",
      "Train Loss: 0.020810829268561468\n",
      "Val Loss: 0.02080929610464308\n",
      "Starting epoch 4358\n",
      "Train Loss: 0.02083158548231478\n",
      "Val Loss: 0.020807585782474942\n",
      "Starting epoch 4359\n",
      "Train Loss: 0.021288319870277687\n",
      "Val Loss: 0.021331755099473177\n",
      "Starting epoch 4360\n",
      "Train Loss: 0.020858556584075646\n",
      "Val Loss: 0.020823161359186524\n",
      "Starting epoch 4361\n",
      "Train Loss: 0.020824150906668767\n",
      "Val Loss: 0.020826145454689308\n",
      "Starting epoch 4362\n",
      "Train Loss: 0.020823885445241577\n",
      "Val Loss: 0.020815345976087783\n",
      "Starting epoch 4363\n",
      "Train Loss: 0.02081622348891364\n",
      "Val Loss: 0.02082309623559316\n",
      "Starting epoch 4364\n",
      "Train Loss: 0.02080820224903248\n",
      "Val Loss: 0.020820696596746093\n",
      "Starting epoch 4365\n",
      "Train Loss: 0.02128097414970398\n",
      "Val Loss: 0.02086535040979032\n",
      "Starting epoch 4366\n",
      "Train Loss: 0.020855712117972196\n",
      "Val Loss: 0.02081645859612359\n",
      "Starting epoch 4367\n",
      "Train Loss: 0.020809881113193655\n",
      "Val Loss: 0.02086043413038607\n",
      "Starting epoch 4368\n",
      "Train Loss: 0.020817368118851272\n",
      "Val Loss: 0.020807252437980088\n",
      "Starting epoch 4369\n",
      "Train Loss: 0.02085728336263586\n",
      "Val Loss: 0.02084991611816265\n",
      "Starting epoch 4370\n",
      "Train Loss: 0.020875452293290034\n",
      "Val Loss: 0.02082282249574308\n",
      "Starting epoch 4371\n",
      "Train Loss: 0.021290406032844825\n",
      "Val Loss: 0.020907858455622638\n",
      "Starting epoch 4372\n",
      "Train Loss: 0.020807367232110765\n",
      "Val Loss: 0.02080828172189218\n",
      "Starting epoch 4373\n",
      "Train Loss: 0.020810917019844055\n",
      "Val Loss: 0.020813241049095436\n",
      "Starting epoch 4374\n",
      "Train Loss: 0.020852444348511873\n",
      "Val Loss: 0.020815861997780977\n",
      "Starting epoch 4375\n",
      "Train Loss: 0.0208208042162436\n",
      "Val Loss: 0.02132568480791869\n",
      "Starting epoch 4376\n",
      "Train Loss: 0.021340931455294292\n",
      "Val Loss: 0.020810096904083534\n",
      "Starting epoch 4377\n",
      "Train Loss: 0.02080666411806036\n",
      "Val Loss: 0.02080691357453664\n",
      "Starting epoch 4378\n",
      "Train Loss: 0.020853032116536743\n",
      "Val Loss: 0.02081203019177472\n",
      "Starting epoch 4379\n",
      "Train Loss: 0.02128856877485911\n",
      "Val Loss: 0.02085791031519572\n",
      "Starting epoch 4380\n",
      "Train Loss: 0.020807780049465322\n",
      "Val Loss: 0.020854795420611347\n",
      "Starting epoch 4381\n",
      "Train Loss: 0.0213248696592119\n",
      "Val Loss: 0.02085589865843455\n",
      "Starting epoch 4382\n",
      "Train Loss: 0.02086692386203342\n",
      "Val Loss: 0.020819161225248267\n",
      "Starting epoch 4383\n",
      "Train Loss: 0.020806243574177777\n",
      "Val Loss: 0.0208608513628995\n",
      "Starting epoch 4384\n",
      "Train Loss: 0.020809538386486196\n",
      "Val Loss: 0.02129583888583713\n",
      "Starting epoch 4385\n",
      "Train Loss: 0.020808684605139273\n",
      "Val Loss: 0.020808617273966473\n",
      "Starting epoch 4386\n",
      "Train Loss: 0.020814841544186627\n",
      "Val Loss: 0.020811133914523654\n",
      "Starting epoch 4387\n",
      "Train Loss: 0.021295152880527354\n",
      "Val Loss: 0.020815141223095083\n",
      "Starting epoch 4388\n",
      "Train Loss: 0.020835071250244423\n",
      "Val Loss: 0.021333050396707322\n",
      "Starting epoch 4389\n",
      "Train Loss: 0.020823674069510564\n",
      "Val Loss: 0.02085899809996287\n",
      "Starting epoch 4390\n",
      "Train Loss: 0.020824476524635597\n",
      "Val Loss: 0.020852153499921162\n",
      "Starting epoch 4391\n",
      "Train Loss: 0.020816801874725906\n",
      "Val Loss: 0.020864309536086187\n",
      "Starting epoch 4392\n",
      "Train Loss: 0.02128005138149968\n",
      "Val Loss: 0.020808410313394334\n",
      "Starting epoch 4393\n",
      "Train Loss: 0.020807941754659016\n",
      "Val Loss: 0.020812643346963106\n",
      "Starting epoch 4394\n",
      "Train Loss: 0.020808798847375094\n",
      "Val Loss: 0.02080697759434029\n",
      "Starting epoch 4395\n",
      "Train Loss: 0.02082098689344194\n",
      "Val Loss: 0.020810614029566448\n",
      "Starting epoch 4396\n",
      "Train Loss: 0.021287888840392784\n",
      "Val Loss: 0.020811760315188655\n",
      "Starting epoch 4397\n",
      "Train Loss: 0.020809902085198298\n",
      "Val Loss: 0.020807823649159184\n",
      "Starting epoch 4398\n",
      "Train Loss: 0.02080735840179302\n",
      "Val Loss: 0.020805442774737323\n",
      "Starting epoch 4399\n",
      "Train Loss: 0.02080844618656017\n",
      "Val Loss: 0.020818334486749437\n",
      "Starting epoch 4400\n",
      "Train Loss: 0.020812059994097108\n",
      "Val Loss: 0.02080750079066665\n",
      "Starting epoch 4401\n",
      "Train Loss: 0.02081834938791063\n",
      "Val Loss: 0.020832530878208303\n",
      "Starting epoch 4402\n",
      "Train Loss: 0.02080956874070344\n",
      "Val Loss: 0.02080671544428225\n",
      "Starting epoch 4403\n",
      "Train Loss: 0.02090727620654636\n",
      "Val Loss: 0.02081038333751537\n",
      "Starting epoch 4404\n",
      "Train Loss: 0.020855224242916814\n",
      "Val Loss: 0.02084763513671027\n",
      "Starting epoch 4405\n",
      "Train Loss: 0.020862030210318388\n",
      "Val Loss: 0.020809479885631137\n",
      "Starting epoch 4406\n",
      "Train Loss: 0.021285337430459482\n",
      "Val Loss: 0.020819607708189223\n",
      "Starting epoch 4407\n",
      "Train Loss: 0.021293290235378123\n",
      "Val Loss: 0.020816502195817453\n",
      "Starting epoch 4408\n",
      "Train Loss: 0.02080883361675121\n",
      "Val Loss: 0.020807122190793354\n",
      "Starting epoch 4409\n",
      "Train Loss: 0.020815530860865558\n",
      "Val Loss: 0.0208144701189465\n",
      "Starting epoch 4410\n",
      "Train Loss: 0.020822521713044908\n",
      "Val Loss: 0.020825480973279034\n",
      "Starting epoch 4411\n",
      "Train Loss: 0.02081859994817663\n",
      "Val Loss: 0.02087287770377265\n",
      "Starting epoch 4412\n",
      "Train Loss: 0.020806460468857375\n",
      "Val Loss: 0.020808740898414894\n",
      "Starting epoch 4413\n",
      "Train Loss: 0.020814882384406194\n",
      "Val Loss: 0.020806525040555884\n",
      "Starting epoch 4414\n",
      "Train Loss: 0.02080773976114061\n",
      "Val Loss: 0.020810760833598948\n",
      "Starting epoch 4415\n",
      "Train Loss: 0.020819331760759705\n",
      "Val Loss: 0.020813839303122625\n",
      "Starting epoch 4416\n",
      "Train Loss: 0.021280086702770658\n",
      "Val Loss: 0.020823863921342074\n",
      "Starting epoch 4417\n",
      "Train Loss: 0.020811024639341567\n",
      "Val Loss: 0.021286100149154663\n",
      "Starting epoch 4418\n",
      "Train Loss: 0.0212818615966373\n",
      "Val Loss: 0.020836574059945566\n",
      "Starting epoch 4419\n",
      "Train Loss: 0.020858032835854426\n",
      "Val Loss: 0.02081834993980549\n",
      "Starting epoch 4420\n",
      "Train Loss: 0.021283951070573594\n",
      "Val Loss: 0.020808636038391677\n",
      "Starting epoch 4421\n",
      "Train Loss: 0.020819303614121897\n",
      "Val Loss: 0.020804415698404664\n",
      "Starting epoch 4422\n",
      "Train Loss: 0.02080495876294595\n",
      "Val Loss: 0.020805625451935664\n",
      "Starting epoch 4423\n",
      "Train Loss: 0.02082223583150793\n",
      "Val Loss: 0.020823384324709576\n",
      "Starting epoch 4424\n",
      "Train Loss: 0.021279365376189904\n",
      "Val Loss: 0.020806054826135987\n",
      "Starting epoch 4425\n",
      "Train Loss: 0.020804488548526057\n",
      "Val Loss: 0.021288634450347337\n",
      "Starting epoch 4426\n",
      "Train Loss: 0.020820314685503643\n",
      "Val Loss: 0.02081796913235276\n",
      "Starting epoch 4427\n",
      "Train Loss: 0.020806473162439134\n",
      "Val Loss: 0.020808233155144587\n",
      "Starting epoch 4428\n",
      "Train Loss: 0.02080555260181427\n",
      "Val Loss: 0.02080612270920365\n",
      "Starting epoch 4429\n",
      "Train Loss: 0.02128250676172751\n",
      "Val Loss: 0.020808066482897156\n",
      "Starting epoch 4430\n",
      "Train Loss: 0.020814352013446665\n",
      "Val Loss: 0.020804348919126723\n",
      "Starting epoch 4431\n",
      "Train Loss: 0.02081996147279386\n",
      "Val Loss: 0.020828072671537048\n",
      "Starting epoch 4432\n",
      "Train Loss: 0.020811240982126306\n",
      "Val Loss: 0.021287402621021977\n",
      "Starting epoch 4433\n",
      "Train Loss: 0.020812672045495775\n",
      "Val Loss: 0.020813583223908035\n",
      "Starting epoch 4434\n",
      "Train Loss: 0.02085197854925085\n",
      "Val Loss: 0.020804735245528044\n",
      "Starting epoch 4435\n",
      "Train Loss: 0.020812716197084496\n",
      "Val Loss: 0.020806922956749244\n",
      "Starting epoch 4436\n",
      "Train Loss: 0.020815317277555114\n",
      "Val Loss: 0.020822458797030978\n",
      "Starting epoch 4437\n",
      "Train Loss: 0.020813765349211515\n",
      "Val Loss: 0.02081856241932622\n",
      "Starting epoch 4438\n",
      "Train Loss: 0.021290619064260413\n",
      "Val Loss: 0.020818067921532526\n",
      "Starting epoch 4439\n",
      "Train Loss: 0.020803522180627892\n",
      "Val Loss: 0.021286422455752338\n",
      "Starting epoch 4440\n",
      "Train Loss: 0.020803962592725402\n",
      "Val Loss: 0.020813283544999582\n",
      "Starting epoch 4441\n",
      "Train Loss: 0.02080399570641694\n",
      "Val Loss: 0.020821293195088703\n",
      "Starting epoch 4442\n",
      "Train Loss: 0.02084882281444691\n",
      "Val Loss: 0.020821041531032987\n",
      "Starting epoch 4443\n",
      "Train Loss: 0.020815589913615474\n",
      "Val Loss: 0.020803653531604342\n",
      "Starting epoch 4444\n",
      "Train Loss: 0.020805469817585416\n",
      "Val Loss: 0.02084377408027649\n",
      "Starting epoch 4445\n",
      "Train Loss: 0.020803973078727722\n",
      "Val Loss: 0.02080427606900533\n",
      "Starting epoch 4446\n",
      "Train Loss: 0.020822516745991178\n",
      "Val Loss: 0.020865646777329622\n",
      "Starting epoch 4447\n",
      "Train Loss: 0.02086030388319934\n",
      "Val Loss: 0.02127797128977599\n",
      "Starting epoch 4448\n",
      "Train Loss: 0.020806837413046095\n",
      "Val Loss: 0.02128444832784158\n",
      "Starting epoch 4449\n",
      "Train Loss: 0.020859312128137658\n",
      "Val Loss: 0.020805659117522062\n",
      "Starting epoch 4450\n",
      "Train Loss: 0.02085002428955502\n",
      "Val Loss: 0.02080502664601361\n",
      "Starting epoch 4451\n",
      "Train Loss: 0.02080587877167596\n",
      "Val Loss: 0.020804866044609634\n",
      "Starting epoch 4452\n",
      "Train Loss: 0.02080679988419568\n",
      "Val Loss: 0.020814450250731573\n",
      "Starting epoch 4453\n",
      "Train Loss: 0.020811098041357817\n",
      "Val Loss: 0.02082868637862029\n",
      "Starting epoch 4454\n",
      "Train Loss: 0.020815609781830398\n",
      "Val Loss: 0.02084604292004197\n",
      "Starting epoch 4455\n",
      "Train Loss: 0.020818097171960055\n",
      "Val Loss: 0.020805390896620573\n",
      "Starting epoch 4456\n",
      "Train Loss: 0.020818769379898353\n",
      "Val Loss: 0.020815114732141846\n",
      "Starting epoch 4457\n",
      "Train Loss: 0.020850979619556002\n",
      "Val Loss: 0.02081401866895181\n",
      "Starting epoch 4458\n",
      "Train Loss: 0.02080316455275924\n",
      "Val Loss: 0.02081007151692002\n",
      "Starting epoch 4459\n",
      "Train Loss: 0.020862501528528\n",
      "Val Loss: 0.0208049648337894\n",
      "Starting epoch 4460\n",
      "Train Loss: 0.020809893254880554\n",
      "Val Loss: 0.020804729726579454\n",
      "Starting epoch 4461\n",
      "Train Loss: 0.020844664838578966\n",
      "Val Loss: 0.020807785568413912\n",
      "Starting epoch 4462\n",
      "Train Loss: 0.021335665274549415\n",
      "Val Loss: 0.020854300922817655\n",
      "Starting epoch 4463\n",
      "Train Loss: 0.02081318751529411\n",
      "Val Loss: 0.02127675767298098\n",
      "Starting epoch 4464\n",
      "Train Loss: 0.021327397889561124\n",
      "Val Loss: 0.02081531838134483\n",
      "Starting epoch 4465\n",
      "Train Loss: 0.02080278374530651\n",
      "Val Loss: 0.020815253257751465\n",
      "Starting epoch 4466\n",
      "Train Loss: 0.02081756900857996\n",
      "Val Loss: 0.020804643630981445\n",
      "Starting epoch 4467\n",
      "Train Loss: 0.020817132459746465\n",
      "Val Loss: 0.020811681394223815\n",
      "Starting epoch 4468\n",
      "Train Loss: 0.02081318696339925\n",
      "Val Loss: 0.02080372969309489\n",
      "Starting epoch 4469\n",
      "Train Loss: 0.020895462897088792\n",
      "Val Loss: 0.020816465770756756\n",
      "Starting epoch 4470\n",
      "Train Loss: 0.020812209557603906\n",
      "Val Loss: 0.020804604446446454\n",
      "Starting epoch 4471\n",
      "Train Loss: 0.020811659870324312\n",
      "Val Loss: 0.02080660175394129\n",
      "Starting epoch 4472\n",
      "Train Loss: 0.020854962092858774\n",
      "Val Loss: 0.020806587404674955\n",
      "Starting epoch 4473\n",
      "Train Loss: 0.02081842499750632\n",
      "Val Loss: 0.020802499519454107\n",
      "Starting epoch 4474\n",
      "Train Loss: 0.02083995717543143\n",
      "Val Loss: 0.020809016293949552\n",
      "Starting epoch 4475\n",
      "Train Loss: 0.02082780445063556\n",
      "Val Loss: 0.02081129672350707\n",
      "Starting epoch 4476\n",
      "Train Loss: 0.020824723773532443\n",
      "Val Loss: 0.020809320388016878\n",
      "Starting epoch 4477\n",
      "Train Loss: 0.020811623997158475\n",
      "Val Loss: 0.020861458447244432\n",
      "Starting epoch 4478\n",
      "Train Loss: 0.020870050346409832\n",
      "Val Loss: 0.020804951036417926\n",
      "Starting epoch 4479\n",
      "Train Loss: 0.02128142946296268\n",
      "Val Loss: 0.020803907955134357\n",
      "Starting epoch 4480\n",
      "Train Loss: 0.02081324932751832\n",
      "Val Loss: 0.020811470570387663\n",
      "Starting epoch 4481\n",
      "Train Loss: 0.02080271586223885\n",
      "Val Loss: 0.020814829402499728\n",
      "Starting epoch 4482\n",
      "Train Loss: 0.020827831493483648\n",
      "Val Loss: 0.021276721247920283\n",
      "Starting epoch 4483\n",
      "Train Loss: 0.020802193217807345\n",
      "Val Loss: 0.02128933259734401\n",
      "Starting epoch 4484\n",
      "Train Loss: 0.02080987228287591\n",
      "Val Loss: 0.020845244880075806\n",
      "Starting epoch 4485\n",
      "Train Loss: 0.020817296372519598\n",
      "Val Loss: 0.020801381932364568\n",
      "Starting epoch 4486\n",
      "Train Loss: 0.020849162781680072\n",
      "Val Loss: 0.02082036159656666\n",
      "Starting epoch 4487\n",
      "Train Loss: 0.02128063087110166\n",
      "Val Loss: 0.02080108997998414\n",
      "Starting epoch 4488\n",
      "Train Loss: 0.02082217953823231\n",
      "Val Loss: 0.02080259499726472\n",
      "Starting epoch 4489\n",
      "Train Loss: 0.02080348409988262\n",
      "Val Loss: 0.020803155170546636\n",
      "Starting epoch 4490\n",
      "Train Loss: 0.021281607725002146\n",
      "Val Loss: 0.020810816023084853\n",
      "Starting epoch 4491\n",
      "Train Loss: 0.020803661810027227\n",
      "Val Loss: 0.020804644182876305\n",
      "Starting epoch 4492\n",
      "Train Loss: 0.02080176329171216\n",
      "Val Loss: 0.020854466491275363\n",
      "Starting epoch 4493\n",
      "Train Loss: 0.020811765834137245\n",
      "Val Loss: 0.021275792408872535\n",
      "Starting epoch 4494\n",
      "Train Loss: 0.0208040663489589\n",
      "Val Loss: 0.020841330841735558\n",
      "Starting epoch 4495\n",
      "Train Loss: 0.020814121873290452\n",
      "Val Loss: 0.020813280233630427\n",
      "Starting epoch 4496\n",
      "Train Loss: 0.020862891718193336\n",
      "Val Loss: 0.020809234844313726\n",
      "Starting epoch 4497\n",
      "Train Loss: 0.02129275765683916\n",
      "Val Loss: 0.020801486792387785\n",
      "Starting epoch 4498\n",
      "Train Loss: 0.020847396166236314\n",
      "Val Loss: 0.020858294434017606\n",
      "Starting epoch 4499\n",
      "Train Loss: 0.0208147206792125\n",
      "Val Loss: 0.020815521478652954\n",
      "Starting epoch 4500\n",
      "Train Loss: 0.020811366814154166\n",
      "Val Loss: 0.02130080869904271\n",
      "Starting epoch 4501\n",
      "Train Loss: 0.020809001392788358\n",
      "Val Loss: 0.020842097423694753\n",
      "Starting epoch 4502\n",
      "Train Loss: 0.02089819863990501\n",
      "Val Loss: 0.020805122123824224\n",
      "Starting epoch 4503\n",
      "Train Loss: 0.02082209399452916\n",
      "Val Loss: 0.020804320220594055\n",
      "Starting epoch 4504\n",
      "Train Loss: 0.020804182798774155\n",
      "Val Loss: 0.020813718990043358\n",
      "Starting epoch 4505\n",
      "Train Loss: 0.020800651223571213\n",
      "Val Loss: 0.02080231021951746\n",
      "Starting epoch 4506\n",
      "Train Loss: 0.020843641073615464\n",
      "Val Loss: 0.02127533985508813\n",
      "Starting epoch 4507\n",
      "Train Loss: 0.020811326525829458\n",
      "Val Loss: 0.02080089295351947\n",
      "Starting epoch 4508\n",
      "Train Loss: 0.020801200910850807\n",
      "Val Loss: 0.020802292558881972\n",
      "Starting epoch 4509\n",
      "Train Loss: 0.020845347532519588\n",
      "Val Loss: 0.020810232118323998\n",
      "Starting epoch 4510\n",
      "Train Loss: 0.020848022015006455\n",
      "Val Loss: 0.020801787575085957\n",
      "Starting epoch 4511\n",
      "Train Loss: 0.020866481242356478\n",
      "Val Loss: 0.020815133496567054\n",
      "Starting epoch 4512\n",
      "Train Loss: 0.020801891883214314\n",
      "Val Loss: 0.02081751105961976\n",
      "Starting epoch 4513\n",
      "Train Loss: 0.020803139165595726\n",
      "Val Loss: 0.020823912488089666\n",
      "Starting epoch 4514\n",
      "Train Loss: 0.020858860126248113\n",
      "Val Loss: 0.02080841914371208\n",
      "Starting epoch 4515\n",
      "Train Loss: 0.020808545527634798\n",
      "Val Loss: 0.02085524907818547\n",
      "Starting epoch 4516\n",
      "Train Loss: 0.020807650906068308\n",
      "Val Loss: 0.02081429847964534\n",
      "Starting epoch 4517\n",
      "Train Loss: 0.02085410389635298\n",
      "Val Loss: 0.02080224619971381\n",
      "Starting epoch 4518\n",
      "Train Loss: 0.020803162345179805\n",
      "Val Loss: 0.020816517096978647\n",
      "Starting epoch 4519\n",
      "Train Loss: 0.02081356832274684\n",
      "Val Loss: 0.020799837730549\n",
      "Starting epoch 4520\n",
      "Train Loss: 0.02081148878291801\n",
      "Val Loss: 0.020850695393703603\n",
      "Starting epoch 4521\n",
      "Train Loss: 0.0208035072794667\n",
      "Val Loss: 0.020799573924806383\n",
      "Starting epoch 4522\n",
      "Train Loss: 0.020800033653223957\n",
      "Val Loss: 0.020844059961813467\n",
      "Starting epoch 4523\n",
      "Train Loss: 0.021276151692425763\n",
      "Val Loss: 0.02080973430916115\n",
      "Starting epoch 4524\n",
      "Train Loss: 0.020802445433757925\n",
      "Val Loss: 0.020801243958649813\n",
      "Starting epoch 4525\n",
      "Train Loss: 0.02080781371505172\n",
      "Val Loss: 0.020800325053709524\n",
      "Starting epoch 4526\n",
      "Train Loss: 0.020852766655109548\n",
      "Val Loss: 0.02080808911058638\n",
      "Starting epoch 4527\n",
      "Train Loss: 0.021318649804150616\n",
      "Val Loss: 0.020819667312834\n",
      "Starting epoch 4528\n",
      "Train Loss: 0.020847612509021052\n",
      "Val Loss: 0.020808823682643748\n",
      "Starting epoch 4529\n",
      "Train Loss: 0.020825206681534095\n",
      "Val Loss: 0.020834876431359187\n",
      "Starting epoch 4530\n",
      "Train Loss: 0.02080763821248655\n",
      "Val Loss: 0.02080543339252472\n",
      "Starting epoch 4531\n",
      "Train Loss: 0.020801258307916147\n",
      "Val Loss: 0.020804814166492887\n",
      "Starting epoch 4532\n",
      "Train Loss: 0.020801459197644836\n",
      "Val Loss: 0.02083005452597583\n",
      "Starting epoch 4533\n",
      "Train Loss: 0.020801024856390776\n",
      "Val Loss: 0.02084254887368944\n",
      "Starting epoch 4534\n",
      "Train Loss: 0.020805631522779113\n",
      "Val Loss: 0.020842709475093417\n",
      "Starting epoch 4535\n",
      "Train Loss: 0.021276936486915306\n",
      "Val Loss: 0.02080096745932544\n",
      "Starting epoch 4536\n",
      "Train Loss: 0.02080413533581628\n",
      "Val Loss: 0.020836738524613558\n",
      "Starting epoch 4537\n",
      "Train Loss: 0.020808237570303457\n",
      "Val Loss: 0.02079921684883259\n",
      "Starting epoch 4538\n",
      "Train Loss: 0.020807555428257695\n",
      "Val Loss: 0.020842499203152128\n",
      "Starting epoch 4539\n",
      "Train Loss: 0.020847119666911936\n",
      "Val Loss: 0.02081339833913026\n",
      "Starting epoch 4540\n",
      "Train Loss: 0.02080005352143888\n",
      "Val Loss: 0.020806712684807955\n",
      "Starting epoch 4541\n",
      "Train Loss: 0.020801576751249808\n",
      "Val Loss: 0.020799452507937397\n",
      "Starting epoch 4542\n",
      "Train Loss: 0.020858967193850764\n",
      "Val Loss: 0.021317785536801373\n",
      "Starting epoch 4543\n",
      "Train Loss: 0.021286037233140733\n",
      "Val Loss: 0.02081356445948283\n",
      "Starting epoch 4544\n",
      "Train Loss: 0.020815087137398897\n",
      "Val Loss: 0.02084966003894806\n",
      "Starting epoch 4545\n",
      "Train Loss: 0.020802967526294566\n",
      "Val Loss: 0.021276815621941177\n",
      "Starting epoch 4546\n",
      "Train Loss: 0.020811009738180373\n",
      "Val Loss: 0.02080127265718248\n",
      "Starting epoch 4547\n",
      "Train Loss: 0.020811083140196623\n",
      "Val Loss: 0.020806416317268654\n",
      "Starting epoch 4548\n",
      "Train Loss: 0.020813214006247343\n",
      "Val Loss: 0.020812055578938237\n",
      "Starting epoch 4549\n",
      "Train Loss: 0.020844843100618432\n",
      "Val Loss: 0.02079948396594436\n",
      "Starting epoch 4550\n",
      "Train Loss: 0.02085428491786674\n",
      "Val Loss: 0.021273629532919988\n",
      "Starting epoch 4551\n",
      "Train Loss: 0.02079884211222331\n",
      "Val Loss: 0.021274043454064265\n",
      "Starting epoch 4552\n",
      "Train Loss: 0.020823401433450205\n",
      "Val Loss: 0.02085728832968959\n",
      "Starting epoch 4553\n",
      "Train Loss: 0.020812853618904396\n",
      "Val Loss: 0.021283295419481065\n",
      "Starting epoch 4554\n",
      "Train Loss: 0.02080094759111051\n",
      "Val Loss: 0.020804807543754578\n",
      "Starting epoch 4555\n",
      "Train Loss: 0.02080097077069459\n",
      "Val Loss: 0.020800426050468727\n",
      "Starting epoch 4556\n",
      "Train Loss: 0.020807685675444425\n",
      "Val Loss: 0.020798998850363272\n",
      "Starting epoch 4557\n",
      "Train Loss: 0.02080180468382659\n",
      "Val Loss: 0.020803582337167528\n",
      "Starting epoch 4558\n",
      "Train Loss: 0.020807231465975445\n",
      "Val Loss: 0.02081191705332862\n",
      "Starting epoch 4559\n",
      "Train Loss: 0.020805873252727366\n",
      "Val Loss: 0.020804028268213624\n",
      "Starting epoch 4560\n",
      "Train Loss: 0.02131133664537359\n",
      "Val Loss: 0.02079766160911984\n",
      "Starting epoch 4561\n",
      "Train Loss: 0.020808653699027166\n",
      "Val Loss: 0.020805834620087234\n",
      "Starting epoch 4562\n",
      "Train Loss: 0.02080094924679509\n",
      "Val Loss: 0.02080269213075991\n",
      "Starting epoch 4563\n",
      "Train Loss: 0.02083820711683344\n",
      "Val Loss: 0.020802699305393076\n",
      "Starting epoch 4564\n",
      "Train Loss: 0.02079953529216625\n",
      "Val Loss: 0.020861785169000977\n",
      "Starting epoch 4565\n",
      "Train Loss: 0.020883702017642832\n",
      "Val Loss: 0.020799138479762606\n",
      "Starting epoch 4566\n",
      "Train Loss: 0.020799247203049837\n",
      "Val Loss: 0.020808824786433467\n",
      "Starting epoch 4567\n",
      "Train Loss: 0.02081382660954087\n",
      "Val Loss: 0.020797452992863126\n",
      "Starting epoch 4568\n",
      "Train Loss: 0.020802774914988765\n",
      "Val Loss: 0.020819878136670147\n",
      "Starting epoch 4569\n",
      "Train Loss: 0.02080841859181722\n",
      "Val Loss: 0.020799572269121807\n",
      "Starting epoch 4570\n",
      "Train Loss: 0.02079795190581569\n",
      "Val Loss: 0.020859822078987404\n",
      "Starting epoch 4571\n",
      "Train Loss: 0.020801322879614653\n",
      "Val Loss: 0.020819624265034992\n",
      "Starting epoch 4572\n",
      "Train Loss: 0.020800684889157612\n",
      "Val Loss: 0.020802798094572843\n",
      "Starting epoch 4573\n",
      "Train Loss: 0.02079787850379944\n",
      "Val Loss: 0.02080127762423621\n",
      "Starting epoch 4574\n",
      "Train Loss: 0.020805643112571152\n",
      "Val Loss: 0.020823107273490342\n",
      "Starting epoch 4575\n",
      "Train Loss: 0.021295917806801973\n",
      "Val Loss: 0.020799432639722473\n",
      "Starting epoch 4576\n",
      "Train Loss: 0.020798297391997442\n",
      "Val Loss: 0.020798563405319496\n",
      "Starting epoch 4577\n",
      "Train Loss: 0.020799464097729436\n",
      "Val Loss: 0.021277232302559748\n",
      "Starting epoch 4578\n",
      "Train Loss: 0.020842637728761743\n",
      "Val Loss: 0.020797881815168593\n",
      "Starting epoch 4579\n",
      "Train Loss: 0.02084023036338665\n",
      "Val Loss: 0.020817350458215783\n",
      "Starting epoch 4580\n",
      "Train Loss: 0.020810244811905756\n",
      "Val Loss: 0.020854624885099905\n",
      "Starting epoch 4581\n",
      "Train Loss: 0.020886424514982436\n",
      "Val Loss: 0.020798770365891634\n",
      "Starting epoch 4582\n",
      "Train Loss: 0.020845321593461214\n",
      "Val Loss: 0.020797879607589158\n",
      "Starting epoch 4583\n",
      "Train Loss: 0.02083715244575783\n",
      "Val Loss: 0.020812790702890466\n",
      "Starting epoch 4584\n",
      "Train Loss: 0.020820540410500986\n",
      "Val Loss: 0.02080304644725941\n",
      "Starting epoch 4585\n",
      "Train Loss: 0.02127263943354289\n",
      "Val Loss: 0.020808182932712412\n",
      "Starting epoch 4586\n",
      "Train Loss: 0.02079988408971716\n",
      "Val Loss: 0.02079813458301403\n",
      "Starting epoch 4587\n",
      "Train Loss: 0.020850631925794814\n",
      "Val Loss: 0.0212734407848782\n",
      "Starting epoch 4588\n",
      "Train Loss: 0.020857161945766874\n",
      "Val Loss: 0.020797543503620005\n",
      "Starting epoch 4589\n",
      "Train Loss: 0.020859877820368165\n",
      "Val Loss: 0.02127945754263136\n",
      "Starting epoch 4590\n",
      "Train Loss: 0.02127072325459233\n",
      "Val Loss: 0.021280617073730187\n",
      "Starting epoch 4591\n",
      "Train Loss: 0.02080472200005143\n",
      "Val Loss: 0.020797913273175556\n",
      "Starting epoch 4592\n",
      "Train Loss: 0.020821045394296998\n",
      "Val Loss: 0.02079648220980609\n",
      "Starting epoch 4593\n",
      "Train Loss: 0.020805640353096858\n",
      "Val Loss: 0.020798125752696284\n",
      "Starting epoch 4594\n",
      "Train Loss: 0.020852325139222323\n",
      "Val Loss: 0.02084009956430506\n",
      "Starting epoch 4595\n",
      "Train Loss: 0.02081222390687024\n",
      "Val Loss: 0.0208111184614676\n",
      "Starting epoch 4596\n",
      "Train Loss: 0.021274151073561773\n",
      "Val Loss: 0.02085216619350292\n",
      "Starting epoch 4597\n",
      "Train Loss: 0.020807584678685223\n",
      "Val Loss: 0.020809458361731634\n",
      "Starting epoch 4598\n",
      "Train Loss: 0.020801643530527752\n",
      "Val Loss: 0.02079636741567541\n",
      "Starting epoch 4599\n",
      "Train Loss: 0.020797945283077383\n",
      "Val Loss: 0.02080446536894198\n",
      "Starting epoch 4600\n",
      "Train Loss: 0.020809186829460993\n",
      "Val Loss: 0.020797795167675725\n",
      "Starting epoch 4601\n",
      "Train Loss: 0.02085335276744984\n",
      "Val Loss: 0.020808993114365473\n",
      "Starting epoch 4602\n",
      "Train Loss: 0.020804804784280283\n",
      "Val Loss: 0.020795503700221027\n",
      "Starting epoch 4603\n",
      "Train Loss: 0.020801411734686956\n",
      "Val Loss: 0.020803202633504516\n",
      "Starting epoch 4604\n",
      "Train Loss: 0.020846408826333505\n",
      "Val Loss: 0.020844630069202848\n",
      "Starting epoch 4605\n",
      "Train Loss: 0.020811020776077552\n",
      "Val Loss: 0.020855561450675682\n",
      "Starting epoch 4606\n",
      "Train Loss: 0.02085263475223824\n",
      "Val Loss: 0.02080439693397946\n",
      "Starting epoch 4607\n",
      "Train Loss: 0.02080407021222291\n",
      "Val Loss: 0.020812247086454322\n",
      "Starting epoch 4608\n",
      "Train Loss: 0.02086792058414883\n",
      "Val Loss: 0.02084057088251467\n",
      "Starting epoch 4609\n",
      "Train Loss: 0.020796010339701618\n",
      "Val Loss: 0.020797309500199777\n",
      "Starting epoch 4610\n",
      "Train Loss: 0.0208037335563589\n",
      "Val Loss: 0.02131660889696192\n",
      "Starting epoch 4611\n",
      "Train Loss: 0.020796211229430303\n",
      "Val Loss: 0.020892275704277888\n",
      "Starting epoch 4612\n",
      "Train Loss: 0.02079780454988833\n",
      "Val Loss: 0.02079894807603624\n",
      "Starting epoch 4613\n",
      "Train Loss: 0.02079861693912082\n",
      "Val Loss: 0.020887192752626207\n",
      "Starting epoch 4614\n",
      "Train Loss: 0.02084566045690466\n",
      "Val Loss: 0.02080506251917945\n",
      "Starting epoch 4615\n",
      "Train Loss: 0.020838130403448035\n",
      "Val Loss: 0.020835642461423522\n",
      "Starting epoch 4616\n",
      "Train Loss: 0.020798268693464773\n",
      "Val Loss: 0.020809138262713398\n",
      "Starting epoch 4617\n",
      "Train Loss: 0.021277753843201533\n",
      "Val Loss: 0.020796893923370925\n",
      "Starting epoch 4618\n",
      "Train Loss: 0.020809293345168785\n",
      "Val Loss: 0.0208537506836432\n",
      "Starting epoch 4619\n",
      "Train Loss: 0.020803799231847126\n",
      "Val Loss: 0.020795418708412734\n",
      "Starting epoch 4620\n",
      "Train Loss: 0.020849125804724516\n",
      "Val Loss: 0.020807568673734313\n",
      "Starting epoch 4621\n",
      "Train Loss: 0.020835978013497812\n",
      "Val Loss: 0.020798257103672734\n",
      "Starting epoch 4622\n",
      "Train Loss: 0.020806103944778442\n",
      "Val Loss: 0.02080594720663848\n",
      "Starting epoch 4623\n",
      "Train Loss: 0.020804608309710468\n",
      "Val Loss: 0.020798557334476046\n",
      "Starting epoch 4624\n",
      "Train Loss: 0.02083582569051672\n",
      "Val Loss: 0.020843474401368037\n",
      "Starting epoch 4625\n",
      "Train Loss: 0.020797236650078384\n",
      "Val Loss: 0.020848193102412753\n",
      "Starting epoch 4626\n",
      "Train Loss: 0.020815863101570693\n",
      "Val Loss: 0.020852450419355323\n",
      "Starting epoch 4627\n",
      "Train Loss: 0.020796084845507587\n",
      "Val Loss: 0.02085205250316196\n",
      "Starting epoch 4628\n",
      "Train Loss: 0.021285214357905917\n",
      "Val Loss: 0.020816545243616456\n",
      "Starting epoch 4629\n",
      "Train Loss: 0.020804040961795382\n",
      "Val Loss: 0.021273523569107056\n",
      "Starting epoch 4630\n",
      "Train Loss: 0.020800615902300233\n",
      "Val Loss: 0.020840100116199918\n",
      "Starting epoch 4631\n",
      "Train Loss: 0.02080870833661821\n",
      "Val Loss: 0.02127355502711402\n",
      "Starting epoch 4632\n",
      "Train Loss: 0.020800775399914494\n",
      "Val Loss: 0.020855218172073364\n",
      "Starting epoch 4633\n",
      "Train Loss: 0.020814329385757446\n",
      "Val Loss: 0.02080192334122128\n",
      "Starting epoch 4634\n",
      "Train Loss: 0.020798073322684678\n",
      "Val Loss: 0.02085086041026645\n",
      "Starting epoch 4635\n",
      "Train Loss: 0.020801230161278335\n",
      "Val Loss: 0.020798769813996774\n",
      "Starting epoch 4636\n",
      "Train Loss: 0.021287806608058787\n",
      "Val Loss: 0.020810336978347214\n",
      "Starting epoch 4637\n",
      "Train Loss: 0.020794320437643263\n",
      "Val Loss: 0.020843336427653278\n",
      "Starting epoch 4638\n",
      "Train Loss: 0.02079538228335204\n",
      "Val Loss: 0.020839016746591638\n",
      "Starting epoch 4639\n",
      "Train Loss: 0.020796728354913217\n",
      "Val Loss: 0.021278741734999197\n",
      "Starting epoch 4640\n",
      "Train Loss: 0.020797157729113544\n",
      "Val Loss: 0.02079718808333079\n",
      "Starting epoch 4641\n",
      "Train Loss: 0.020797727284608065\n",
      "Val Loss: 0.020795031278221694\n",
      "Starting epoch 4642\n",
      "Train Loss: 0.02079541539704358\n",
      "Val Loss: 0.020795321574917546\n",
      "Starting epoch 4643\n",
      "Train Loss: 0.020799456923096267\n",
      "Val Loss: 0.020804691093939322\n",
      "Starting epoch 4644\n",
      "Train Loss: 0.02083874300674156\n",
      "Val Loss: 0.02079667592490161\n",
      "Starting epoch 4645\n",
      "Train Loss: 0.020798484484354656\n",
      "Val Loss: 0.02126865475266068\n",
      "Starting epoch 4646\n",
      "Train Loss: 0.02080050441953871\n",
      "Val Loss: 0.020793955635141442\n",
      "Starting epoch 4647\n",
      "Train Loss: 0.02079527411195967\n",
      "Val Loss: 0.020810368988249037\n",
      "Starting epoch 4648\n",
      "Train Loss: 0.021273318264219496\n",
      "Val Loss: 0.02079527300816995\n",
      "Starting epoch 4649\n",
      "Train Loss: 0.020797338750627305\n",
      "Val Loss: 0.02128697876577024\n",
      "Starting epoch 4650\n",
      "Train Loss: 0.0207971030915225\n",
      "Val Loss: 0.02080781978589517\n",
      "Starting epoch 4651\n",
      "Train Loss: 0.02084816661145952\n",
      "Val Loss: 0.020847769799055876\n",
      "Starting epoch 4652\n",
      "Train Loss: 0.020839086837238736\n",
      "Val Loss: 0.020794992645581562\n",
      "Starting epoch 4653\n",
      "Train Loss: 0.02080282900068495\n",
      "Val Loss: 0.020842860142389934\n",
      "Starting epoch 4654\n",
      "Train Loss: 0.020793928040398493\n",
      "Val Loss: 0.020794971121682063\n",
      "Starting epoch 4655\n",
      "Train Loss: 0.020799313982327778\n",
      "Val Loss: 0.020803817996272334\n",
      "Starting epoch 4656\n",
      "Train Loss: 0.020840523419556795\n",
      "Val Loss: 0.02079333640910961\n",
      "Starting epoch 4657\n",
      "Train Loss: 0.02127103728276712\n",
      "Val Loss: 0.020794828180913574\n",
      "Starting epoch 4658\n",
      "Train Loss: 0.021270811557769775\n",
      "Val Loss: 0.020796137275519194\n",
      "Starting epoch 4659\n",
      "Train Loss: 0.020802792023729394\n",
      "Val Loss: 0.020793664786550734\n",
      "Starting epoch 4660\n",
      "Train Loss: 0.020802374239321107\n",
      "Val Loss: 0.021308480037583247\n",
      "Starting epoch 4661\n",
      "Train Loss: 0.021275134550200567\n",
      "Val Loss: 0.021267924043867324\n",
      "Starting epoch 4662\n",
      "Train Loss: 0.020803500656728393\n",
      "Val Loss: 0.020810016879328975\n",
      "Starting epoch 4663\n",
      "Train Loss: 0.02084717430450298\n",
      "Val Loss: 0.020805983631699172\n",
      "Starting epoch 4664\n",
      "Train Loss: 0.020835407354213572\n",
      "Val Loss: 0.020812422037124634\n",
      "Starting epoch 4665\n",
      "Train Loss: 0.020802774363093905\n",
      "Val Loss: 0.021270661442368118\n",
      "Starting epoch 4666\n",
      "Train Loss: 0.020797446370124817\n",
      "Val Loss: 0.021315174522223295\n",
      "Starting epoch 4667\n",
      "Train Loss: 0.020812521930094117\n",
      "Val Loss: 0.020793246450247587\n",
      "Starting epoch 4668\n",
      "Train Loss: 0.021287876698705886\n",
      "Val Loss: 0.020833952559365168\n",
      "Starting epoch 4669\n",
      "Train Loss: 0.0207991655226107\n",
      "Val Loss: 0.020794696829937124\n",
      "Starting epoch 4670\n",
      "Train Loss: 0.021269387669033475\n",
      "Val Loss: 0.02083081558898643\n",
      "Starting epoch 4671\n",
      "Train Loss: 0.020838352817076224\n",
      "Val Loss: 0.020802608794636197\n",
      "Starting epoch 4672\n",
      "Train Loss: 0.02127926493132556\n",
      "Val Loss: 0.020795679754681058\n",
      "Starting epoch 4673\n",
      "Train Loss: 0.020801162830105534\n",
      "Val Loss: 0.02079407153306184\n",
      "Starting epoch 4674\n",
      "Train Loss: 0.020800963044166565\n",
      "Val Loss: 0.020793965569248906\n",
      "Starting epoch 4675\n",
      "Train Loss: 0.020834944866321706\n",
      "Val Loss: 0.02079385022322337\n",
      "Starting epoch 4676\n",
      "Train Loss: 0.020842382201442012\n",
      "Val Loss: 0.020792541680512606\n",
      "Starting epoch 4677\n",
      "Train Loss: 0.020817002764454594\n",
      "Val Loss: 0.02081952437206551\n",
      "Starting epoch 4678\n",
      "Train Loss: 0.020805249059641803\n",
      "Val Loss: 0.021273108544173063\n",
      "Starting epoch 4679\n",
      "Train Loss: 0.02082604169845581\n",
      "Val Loss: 0.020805385377671983\n",
      "Starting epoch 4680\n",
      "Train Loss: 0.020824967159165278\n",
      "Val Loss: 0.02079748003571122\n",
      "Starting epoch 4681\n",
      "Train Loss: 0.020811179721796955\n",
      "Val Loss: 0.020795965084323177\n",
      "Starting epoch 4682\n",
      "Train Loss: 0.02080420873783253\n",
      "Val Loss: 0.020848506026797824\n",
      "Starting epoch 4683\n",
      "Train Loss: 0.02085463923436624\n",
      "Val Loss: 0.02079844805929396\n",
      "Starting epoch 4684\n",
      "Train Loss: 0.020833231232784414\n",
      "Val Loss: 0.020801703687067383\n",
      "Starting epoch 4685\n",
      "Train Loss: 0.02087842866226479\n",
      "Val Loss: 0.020794853016182228\n",
      "Starting epoch 4686\n",
      "Train Loss: 0.02079804793552116\n",
      "Val Loss: 0.020792427990171645\n",
      "Starting epoch 4687\n",
      "Train Loss: 0.021270329753557842\n",
      "Val Loss: 0.020793344135637635\n",
      "Starting epoch 4688\n",
      "Train Loss: 0.020831115819789744\n",
      "Val Loss: 0.020792200609489723\n",
      "Starting epoch 4689\n",
      "Train Loss: 0.020801930515854446\n",
      "Val Loss: 0.020832419947341637\n",
      "Starting epoch 4690\n",
      "Train Loss: 0.02085787057876587\n",
      "Val Loss: 0.02080016831556956\n",
      "Starting epoch 4691\n",
      "Train Loss: 0.020800274279382493\n",
      "Val Loss: 0.020832147311281274\n",
      "Starting epoch 4692\n",
      "Train Loss: 0.020806421284322387\n",
      "Val Loss: 0.02080038521024916\n",
      "Starting epoch 4693\n",
      "Train Loss: 0.020835707585016888\n",
      "Val Loss: 0.020813866897865577\n",
      "Starting epoch 4694\n",
      "Train Loss: 0.020797801790414034\n",
      "Val Loss: 0.02080484010555126\n",
      "Starting epoch 4695\n",
      "Train Loss: 0.020795100816973933\n",
      "Val Loss: 0.02080235602679076\n",
      "Starting epoch 4696\n",
      "Train Loss: 0.021321953998671636\n",
      "Val Loss: 0.02126952564274823\n",
      "Starting epoch 4697\n",
      "Train Loss: 0.02079354281778689\n",
      "Val Loss: 0.021281877601588214\n",
      "Starting epoch 4698\n",
      "Train Loss: 0.020802674470124422\n",
      "Val Loss: 0.02079214486810896\n",
      "Starting epoch 4699\n",
      "Train Loss: 0.02087268509246685\n",
      "Val Loss: 0.021308350894186232\n",
      "Starting epoch 4700\n",
      "Train Loss: 0.020805374891669663\n",
      "Val Loss: 0.020842515208103037\n",
      "Starting epoch 4701\n",
      "Train Loss: 0.02079611188835568\n",
      "Val Loss: 0.020798819484534086\n",
      "Starting epoch 4702\n",
      "Train Loss: 0.020807417454542936\n",
      "Val Loss: 0.020801648497581482\n",
      "Starting epoch 4703\n",
      "Train Loss: 0.020795858016720525\n",
      "Val Loss: 0.02079426524815736\n",
      "Starting epoch 4704\n",
      "Train Loss: 0.02083228694068061\n",
      "Val Loss: 0.02126650732976419\n",
      "Starting epoch 4705\n",
      "Train Loss: 0.020801395729736046\n",
      "Val Loss: 0.020792769613089384\n",
      "Starting epoch 4706\n",
      "Train Loss: 0.02080050386764385\n",
      "Val Loss: 0.021276829419312655\n",
      "Starting epoch 4707\n",
      "Train Loss: 0.020791802693296363\n",
      "Val Loss: 0.020832815655955562\n",
      "Starting epoch 4708\n",
      "Train Loss: 0.02083542611863878\n",
      "Val Loss: 0.020793367315221717\n",
      "Starting epoch 4709\n",
      "Train Loss: 0.020829611354404025\n",
      "Val Loss: 0.020835498968760174\n",
      "Starting epoch 4710\n",
      "Train Loss: 0.020794008065153052\n",
      "Val Loss: 0.020840962175969726\n",
      "Starting epoch 4711\n",
      "Train Loss: 0.020825831978409377\n",
      "Val Loss: 0.020796125133832295\n",
      "Starting epoch 4712\n",
      "Train Loss: 0.02082607646783193\n",
      "Val Loss: 0.021275580481246666\n",
      "Starting epoch 4713\n",
      "Train Loss: 0.020852392470395123\n",
      "Val Loss: 0.020816593258469192\n",
      "Starting epoch 4714\n",
      "Train Loss: 0.02080934687897011\n",
      "Val Loss: 0.02080042494667901\n",
      "Starting epoch 4715\n",
      "Train Loss: 0.020843126707606845\n",
      "Val Loss: 0.020796007580227323\n",
      "Starting epoch 4716\n",
      "Train Loss: 0.021311950904351694\n",
      "Val Loss: 0.02079212334420946\n",
      "Starting epoch 4717\n",
      "Train Loss: 0.020794994853161\n",
      "Val Loss: 0.02127186291747623\n",
      "Starting epoch 4718\n",
      "Train Loss: 0.02079506163243894\n",
      "Val Loss: 0.020792923039860196\n",
      "Starting epoch 4719\n",
      "Train Loss: 0.02080162697368198\n",
      "Val Loss: 0.020806368302415917\n",
      "Starting epoch 4720\n",
      "Train Loss: 0.020804575196018926\n",
      "Val Loss: 0.020792381079108628\n",
      "Starting epoch 4721\n",
      "Train Loss: 0.020793680239606788\n",
      "Val Loss: 0.020811305553824815\n",
      "Starting epoch 4722\n",
      "Train Loss: 0.020797167663221008\n",
      "Val Loss: 0.020794101887279086\n",
      "Starting epoch 4723\n",
      "Train Loss: 0.020803561917057744\n",
      "Val Loss: 0.020795248172901296\n",
      "Starting epoch 4724\n",
      "Train Loss: 0.0208312902185652\n",
      "Val Loss: 0.020808676878611248\n",
      "Starting epoch 4725\n",
      "Train Loss: 0.020804598375603004\n",
      "Val Loss: 0.020828154903871042\n",
      "Starting epoch 4726\n",
      "Train Loss: 0.020791609530095703\n",
      "Val Loss: 0.02079877146968135\n",
      "Starting epoch 4727\n",
      "Train Loss: 0.02079027560022142\n",
      "Val Loss: 0.020795782959019696\n",
      "Starting epoch 4728\n",
      "Train Loss: 0.020790574175340158\n",
      "Val Loss: 0.020824919696207398\n",
      "Starting epoch 4729\n",
      "Train Loss: 0.020791419126369334\n",
      "Val Loss: 0.0208253750094661\n",
      "Starting epoch 4730\n",
      "Train Loss: 0.020835936621383385\n",
      "Val Loss: 0.020796648882053518\n",
      "Starting epoch 4731\n",
      "Train Loss: 0.02083401326779966\n",
      "Val Loss: 0.020836072939413565\n",
      "Starting epoch 4732\n",
      "Train Loss: 0.021277342681531555\n",
      "Val Loss: 0.021275653883262916\n",
      "Starting epoch 4733\n",
      "Train Loss: 0.020789858367707994\n",
      "Val Loss: 0.020803989083678635\n",
      "Starting epoch 4734\n",
      "Train Loss: 0.020807155856379756\n",
      "Val Loss: 0.02080155301977087\n",
      "Starting epoch 4735\n",
      "Train Loss: 0.020798688133557636\n",
      "Val Loss: 0.020791608978200843\n",
      "Starting epoch 4736\n",
      "Train Loss: 0.02079093290699853\n",
      "Val Loss: 0.0208349597674829\n",
      "Starting epoch 4737\n",
      "Train Loss: 0.020833975187054387\n",
      "Val Loss: 0.020830869122787758\n",
      "Starting epoch 4738\n",
      "Train Loss: 0.02082908981376224\n",
      "Val Loss: 0.020833841628498502\n",
      "Starting epoch 4739\n",
      "Train Loss: 0.0208368632528517\n",
      "Val Loss: 0.02082402397085119\n",
      "Starting epoch 4740\n",
      "Train Loss: 0.021269483146844088\n",
      "Val Loss: 0.020791522882602834\n",
      "Starting epoch 4741\n",
      "Train Loss: 0.020792071466092712\n",
      "Val Loss: 0.020794016343575937\n",
      "Starting epoch 4742\n",
      "Train Loss: 0.020797181460592482\n",
      "Val Loss: 0.020826802761466416\n",
      "Starting epoch 4743\n",
      "Train Loss: 0.020792751952453895\n",
      "Val Loss: 0.02079094836005458\n",
      "Starting epoch 4744\n",
      "Train Loss: 0.02079132475234844\n",
      "Val Loss: 0.02130417029062907\n",
      "Starting epoch 4745\n",
      "Train Loss: 0.02127889902503402\n",
      "Val Loss: 0.020790833014029043\n",
      "Starting epoch 4746\n",
      "Train Loss: 0.020791305987923232\n",
      "Val Loss: 0.02080816803155122\n",
      "Starting epoch 4747\n",
      "Train Loss: 0.020795766402173926\n",
      "Val Loss: 0.020791360625514278\n",
      "Starting epoch 4748\n",
      "Train Loss: 0.020791618912308303\n",
      "Val Loss: 0.020789452724986605\n",
      "Starting epoch 4749\n",
      "Train Loss: 0.02126662212389487\n",
      "Val Loss: 0.02079350639272619\n",
      "Starting epoch 4750\n",
      "Train Loss: 0.020827875645072373\n",
      "Val Loss: 0.020789805385801528\n",
      "Starting epoch 4751\n",
      "Train Loss: 0.020789965987205505\n",
      "Val Loss: 0.02126835286617279\n",
      "Starting epoch 4752\n",
      "Train Loss: 0.020801663950637535\n",
      "Val Loss: 0.02079145555143003\n",
      "Starting epoch 4753\n",
      "Train Loss: 0.020797420982961303\n",
      "Val Loss: 0.02079468192877593\n",
      "Starting epoch 4754\n",
      "Train Loss: 0.020792308228987234\n",
      "Val Loss: 0.02079455664864293\n",
      "Starting epoch 4755\n",
      "Train Loss: 0.020826089713308547\n",
      "Val Loss: 0.020789395327921265\n",
      "Starting epoch 4756\n",
      "Train Loss: 0.02079192355827049\n",
      "Val Loss: 0.020796537399291992\n",
      "Starting epoch 4757\n",
      "Train Loss: 0.0207981296159603\n",
      "Val Loss: 0.02080702892056218\n",
      "Starting epoch 4758\n",
      "Train Loss: 0.020800525943438213\n",
      "Val Loss: 0.02081409869370637\n",
      "Starting epoch 4759\n",
      "Train Loss: 0.021320685744285583\n",
      "Val Loss: 0.020789534957320603\n",
      "Starting epoch 4760\n",
      "Train Loss: 0.02079499430126614\n",
      "Val Loss: 0.02081241375870175\n",
      "Starting epoch 4761\n",
      "Train Loss: 0.020794143279393513\n",
      "Val Loss: 0.021265984685332688\n",
      "Starting epoch 4762\n",
      "Train Loss: 0.02080821935777311\n",
      "Val Loss: 0.02078988817003038\n",
      "Starting epoch 4763\n",
      "Train Loss: 0.02079249200997529\n",
      "Val Loss: 0.021266258977077627\n",
      "Starting epoch 4764\n",
      "Train Loss: 0.020788847848221107\n",
      "Val Loss: 0.0208004426073145\n",
      "Starting epoch 4765\n",
      "Train Loss: 0.020843787877647964\n",
      "Val Loss: 0.020830658850846468\n",
      "Starting epoch 4766\n",
      "Train Loss: 0.020790021176691407\n",
      "Val Loss: 0.020790759612012794\n",
      "Starting epoch 4767\n",
      "Train Loss: 0.02079868151081933\n",
      "Val Loss: 0.02079402517389368\n",
      "Starting epoch 4768\n",
      "Train Loss: 0.0208236426115036\n",
      "Val Loss: 0.020793452307030006\n",
      "Starting epoch 4769\n",
      "Train Loss: 0.02084699383488408\n",
      "Val Loss: 0.020793153180016413\n",
      "Starting epoch 4770\n",
      "Train Loss: 0.020804962626209966\n",
      "Val Loss: 0.020814023636005544\n",
      "Starting epoch 4771\n",
      "Train Loss: 0.020804162930559228\n",
      "Val Loss: 0.020827606320381165\n",
      "Starting epoch 4772\n",
      "Train Loss: 0.020795525776015386\n",
      "Val Loss: 0.020796871847576566\n",
      "Starting epoch 4773\n",
      "Train Loss: 0.02080108004587668\n",
      "Val Loss: 0.020791603459252253\n",
      "Starting epoch 4774\n",
      "Train Loss: 0.020811418140376056\n",
      "Val Loss: 0.020789692247355426\n",
      "Starting epoch 4775\n",
      "Train Loss: 0.02079173536212356\n",
      "Val Loss: 0.02078966796398163\n",
      "Starting epoch 4776\n",
      "Train Loss: 0.020838922924465604\n",
      "Val Loss: 0.020790996926802176\n",
      "Starting epoch 4777\n",
      "Train Loss: 0.020797386213585182\n",
      "Val Loss: 0.020790170188303345\n",
      "Starting epoch 4778\n",
      "Train Loss: 0.0208425952328576\n",
      "Val Loss: 0.020867553574067575\n",
      "Starting epoch 4779\n",
      "Train Loss: 0.020791734258333843\n",
      "Val Loss: 0.020826866781270062\n",
      "Starting epoch 4780\n",
      "Train Loss: 0.020806889291162842\n",
      "Val Loss: 0.020793093575371638\n",
      "Starting epoch 4781\n",
      "Train Loss: 0.020792340790783917\n",
      "Val Loss: 0.0212722889803074\n",
      "Starting epoch 4782\n",
      "Train Loss: 0.02080103975755197\n",
      "Val Loss: 0.020796854186941077\n",
      "Starting epoch 4783\n",
      "Train Loss: 0.021267952190505132\n",
      "Val Loss: 0.020831185358541983\n",
      "Starting epoch 4784\n",
      "Train Loss: 0.020802632526115136\n",
      "Val Loss: 0.021264522715851112\n",
      "Starting epoch 4785\n",
      "Train Loss: 0.020825963329385827\n",
      "Val Loss: 0.020799658364719815\n",
      "Starting epoch 4786\n",
      "Train Loss: 0.020794319885748404\n",
      "Val Loss: 0.02126581801308526\n",
      "Starting epoch 4787\n",
      "Train Loss: 0.02079755398962233\n",
      "Val Loss: 0.020801140754311172\n",
      "Starting epoch 4788\n",
      "Train Loss: 0.02079208305588475\n",
      "Val Loss: 0.020792690140229685\n",
      "Starting epoch 4789\n",
      "Train Loss: 0.020788124865955777\n",
      "Val Loss: 0.020788426752443665\n",
      "Starting epoch 4790\n",
      "Train Loss: 0.020808512413943256\n",
      "Val Loss: 0.020834635253305787\n",
      "Starting epoch 4791\n",
      "Train Loss: 0.020835349957148235\n",
      "Val Loss: 0.020800694271370216\n",
      "Starting epoch 4792\n",
      "Train Loss: 0.020787378152211506\n",
      "Val Loss: 0.020792274563400832\n",
      "Starting epoch 4793\n",
      "Train Loss: 0.02080598473548889\n",
      "Val Loss: 0.02079444902914542\n",
      "Starting epoch 4794\n",
      "Train Loss: 0.020793339720478764\n",
      "Val Loss: 0.02079339325428009\n",
      "Starting epoch 4795\n",
      "Train Loss: 0.0208724163196705\n",
      "Val Loss: 0.020795705141844572\n",
      "Starting epoch 4796\n",
      "Train Loss: 0.02079004270059091\n",
      "Val Loss: 0.020790847363295378\n",
      "Starting epoch 4797\n",
      "Train Loss: 0.02078950570689307\n",
      "Val Loss: 0.020798438125186496\n",
      "Starting epoch 4798\n",
      "Train Loss: 0.02078798689224102\n",
      "Val Loss: 0.020787875409479493\n",
      "Starting epoch 4799\n",
      "Train Loss: 0.02078873195030071\n",
      "Val Loss: 0.020822268945199472\n",
      "Starting epoch 4800\n",
      "Train Loss: 0.020824207751839248\n",
      "Val Loss: 0.02079402572578854\n",
      "Starting epoch 4801\n",
      "Train Loss: 0.020800569543132075\n",
      "Val Loss: 0.020797486658449525\n",
      "Starting epoch 4802\n",
      "Train Loss: 0.020788193300918297\n",
      "Val Loss: 0.020804369891131366\n",
      "Starting epoch 4803\n",
      "Train Loss: 0.020801286454553956\n",
      "Val Loss: 0.02078863040164665\n",
      "Starting epoch 4804\n",
      "Train Loss: 0.020792523467982257\n",
      "Val Loss: 0.02079138822025723\n",
      "Starting epoch 4805\n",
      "Train Loss: 0.020788269462408842\n",
      "Val Loss: 0.02080743235570413\n",
      "Starting epoch 4806\n",
      "Train Loss: 0.020788283811675176\n",
      "Val Loss: 0.02079333696100447\n",
      "Starting epoch 4807\n",
      "Train Loss: 0.020788515055621112\n",
      "Val Loss: 0.02079384415237992\n",
      "Starting epoch 4808\n",
      "Train Loss: 0.020834193185523705\n",
      "Val Loss: 0.020798849838751333\n",
      "Starting epoch 4809\n",
      "Train Loss: 0.020792533953984577\n",
      "Val Loss: 0.020799830555915833\n",
      "Starting epoch 4810\n",
      "Train Loss: 0.02080063025156657\n",
      "Val Loss: 0.020837077939951862\n",
      "Starting epoch 4811\n",
      "Train Loss: 0.021283808129805105\n",
      "Val Loss: 0.020830861948154592\n",
      "Starting epoch 4812\n",
      "Train Loss: 0.020831237236658733\n",
      "Val Loss: 0.020791591317565354\n",
      "Starting epoch 4813\n",
      "Train Loss: 0.021263038118680317\n",
      "Val Loss: 0.020787096685833402\n",
      "Starting epoch 4814\n",
      "Train Loss: 0.021272310504206905\n",
      "Val Loss: 0.020793639399387217\n",
      "Starting epoch 4815\n",
      "Train Loss: 0.020803845591015287\n",
      "Val Loss: 0.020798933726769907\n",
      "Starting epoch 4816\n",
      "Train Loss: 0.020789149734709\n",
      "Val Loss: 0.020796934211695636\n",
      "Starting epoch 4817\n",
      "Train Loss: 0.02080032781318382\n",
      "Val Loss: 0.020789150838498718\n",
      "Starting epoch 4818\n",
      "Train Loss: 0.02078955868879954\n",
      "Val Loss: 0.020823233657413058\n",
      "Starting epoch 4819\n",
      "Train Loss: 0.02126661550115656\n",
      "Val Loss: 0.020796008132122182\n",
      "Starting epoch 4820\n",
      "Train Loss: 0.020838945552154823\n",
      "Val Loss: 0.020788369907273188\n",
      "Starting epoch 4821\n",
      "Train Loss: 0.020799264863685326\n",
      "Val Loss: 0.020791107857668842\n",
      "Starting epoch 4822\n",
      "Train Loss: 0.020827974986146996\n",
      "Val Loss: 0.0208233462439643\n",
      "Starting epoch 4823\n",
      "Train Loss: 0.020828575999648484\n",
      "Val Loss: 0.020786735194700735\n",
      "Starting epoch 4824\n",
      "Train Loss: 0.02079764339658949\n",
      "Val Loss: 0.02078914421576041\n",
      "Starting epoch 4825\n",
      "Train Loss: 0.020793458929768315\n",
      "Val Loss: 0.020829657161677326\n",
      "Starting epoch 4826\n",
      "Train Loss: 0.020831254897294222\n",
      "Val Loss: 0.02086367540889316\n",
      "Starting epoch 4827\n",
      "Train Loss: 0.02083025872707367\n",
      "Val Loss: 0.020787425063274526\n",
      "Starting epoch 4828\n",
      "Train Loss: 0.020790217651261225\n",
      "Val Loss: 0.02080188250100171\n",
      "Starting epoch 4829\n",
      "Train Loss: 0.020861952945038124\n",
      "Val Loss: 0.021262072302677012\n",
      "Starting epoch 4830\n",
      "Train Loss: 0.021272503115512705\n",
      "Val Loss: 0.020801075078822947\n",
      "Starting epoch 4831\n",
      "Train Loss: 0.020836903541176406\n",
      "Val Loss: 0.02082343233956231\n",
      "Starting epoch 4832\n",
      "Train Loss: 0.02079014480113983\n",
      "Val Loss: 0.020789619949128892\n",
      "Starting epoch 4833\n",
      "Train Loss: 0.020788771686730562\n",
      "Val Loss: 0.020794426401456196\n",
      "Starting epoch 4834\n",
      "Train Loss: 0.020796537951186852\n",
      "Val Loss: 0.020794368452496\n",
      "Starting epoch 4835\n",
      "Train Loss: 0.02078782077188845\n",
      "Val Loss: 0.020834353235032823\n",
      "Starting epoch 4836\n",
      "Train Loss: 0.020791489768911292\n",
      "Val Loss: 0.02082008730482172\n",
      "Starting epoch 4837\n",
      "Train Loss: 0.020804495723159226\n",
      "Val Loss: 0.020786209790794936\n",
      "Starting epoch 4838\n",
      "Train Loss: 0.021266788244247437\n",
      "Val Loss: 0.020787391397688124\n",
      "Starting epoch 4839\n",
      "Train Loss: 0.021265296472443476\n",
      "Val Loss: 0.020785728538477863\n",
      "Starting epoch 4840\n",
      "Train Loss: 0.020793299984048913\n",
      "Val Loss: 0.020795088123392175\n",
      "Starting epoch 4841\n",
      "Train Loss: 0.0207869498818009\n",
      "Val Loss: 0.02078562643792894\n",
      "Starting epoch 4842\n",
      "Train Loss: 0.020824536129280372\n",
      "Val Loss: 0.020822311992998475\n",
      "Starting epoch 4843\n",
      "Train Loss: 0.020793777373101976\n",
      "Val Loss: 0.020790967676374648\n",
      "Starting epoch 4844\n",
      "Train Loss: 0.020796247654491\n",
      "Val Loss: 0.020785834502290795\n",
      "Starting epoch 4845\n",
      "Train Loss: 0.02131298018826379\n",
      "Val Loss: 0.020791246383278457\n",
      "Starting epoch 4846\n",
      "Train Loss: 0.02079161560093915\n",
      "Val Loss: 0.020800979601012334\n",
      "Starting epoch 4847\n",
      "Train Loss: 0.020791317025820415\n",
      "Val Loss: 0.02079094836005458\n",
      "Starting epoch 4848\n",
      "Train Loss: 0.020785511091903405\n",
      "Val Loss: 0.02078821813618695\n",
      "Starting epoch 4849\n",
      "Train Loss: 0.020790608944716276\n",
      "Val Loss: 0.02082665154227504\n",
      "Starting epoch 4850\n",
      "Train Loss: 0.020788047048780654\n",
      "Val Loss: 0.02078583229471136\n",
      "Starting epoch 4851\n",
      "Train Loss: 0.02078810058258198\n",
      "Val Loss: 0.02078991742045791\n",
      "Starting epoch 4852\n",
      "Train Loss: 0.02079854408899943\n",
      "Val Loss: 0.020824404226409063\n",
      "Starting epoch 4853\n",
      "Train Loss: 0.020790253524427062\n",
      "Val Loss: 0.02080236816847766\n",
      "Starting epoch 4854\n",
      "Train Loss: 0.020790441168679133\n",
      "Val Loss: 0.020786455384007207\n",
      "Starting epoch 4855\n",
      "Train Loss: 0.020786466421904386\n",
      "Val Loss: 0.020785804699968408\n",
      "Starting epoch 4856\n",
      "Train Loss: 0.020789670723455923\n",
      "Val Loss: 0.021263570145324425\n",
      "Starting epoch 4857\n",
      "Train Loss: 0.02078775895966424\n",
      "Val Loss: 0.02082759859385314\n",
      "Starting epoch 4858\n",
      "Train Loss: 0.020801337780775846\n",
      "Val Loss: 0.020799087153540716\n",
      "Starting epoch 4859\n",
      "Train Loss: 0.020797899475804082\n",
      "Val Loss: 0.02126729874699204\n",
      "Starting epoch 4860\n",
      "Train Loss: 0.02078537698145266\n",
      "Val Loss: 0.020785273225219163\n",
      "Starting epoch 4861\n",
      "Train Loss: 0.020786010004855967\n",
      "Val Loss: 0.020796958495069434\n",
      "Starting epoch 4862\n",
      "Train Loss: 0.0207860271135966\n",
      "Val Loss: 0.02082397374841902\n",
      "Starting epoch 4863\n",
      "Train Loss: 0.020786138596358122\n",
      "Val Loss: 0.020785398505352163\n",
      "Starting epoch 4864\n",
      "Train Loss: 0.02079568968878852\n",
      "Val Loss: 0.02078668166089941\n",
      "Starting epoch 4865\n",
      "Train Loss: 0.02079417363361076\n",
      "Val Loss: 0.02078643606768714\n",
      "Starting epoch 4866\n",
      "Train Loss: 0.02126286758316888\n",
      "Val Loss: 0.021263001141724764\n",
      "Starting epoch 4867\n",
      "Train Loss: 0.02078602104275315\n",
      "Val Loss: 0.020797052869090327\n",
      "Starting epoch 4868\n",
      "Train Loss: 0.020826900446856464\n",
      "Val Loss: 0.020786059675393282\n",
      "Starting epoch 4869\n",
      "Train Loss: 0.020795122892768296\n",
      "Val Loss: 0.021298848920398288\n",
      "Starting epoch 4870\n",
      "Train Loss: 0.020828376213709515\n",
      "Val Loss: 0.020785910111886484\n",
      "Starting epoch 4871\n",
      "Train Loss: 0.021272861847171077\n",
      "Val Loss: 0.020790990855958726\n",
      "Starting epoch 4872\n",
      "Train Loss: 0.021264505055215623\n",
      "Val Loss: 0.02078526384300656\n",
      "Starting epoch 4873\n",
      "Train Loss: 0.020794345824806777\n",
      "Val Loss: 0.020829055044386122\n",
      "Starting epoch 4874\n",
      "Train Loss: 0.020823508501052856\n",
      "Val Loss: 0.020828323783697904\n",
      "Starting epoch 4875\n",
      "Train Loss: 0.020794649918874104\n",
      "Val Loss: 0.02083257834116618\n",
      "Starting epoch 4876\n",
      "Train Loss: 0.020785668381938228\n",
      "Val Loss: 0.021312520459846215\n",
      "Starting epoch 4877\n",
      "Train Loss: 0.020791082470505325\n",
      "Val Loss: 0.020787210376174363\n",
      "Starting epoch 4878\n",
      "Train Loss: 0.020799492796262104\n",
      "Val Loss: 0.02079877312536593\n",
      "Starting epoch 4879\n",
      "Train Loss: 0.020830552887033532\n",
      "Val Loss: 0.020859171394948608\n",
      "Starting epoch 4880\n",
      "Train Loss: 0.02078707405814418\n",
      "Val Loss: 0.020785357665132592\n",
      "Starting epoch 4881\n",
      "Train Loss: 0.020786699321534898\n",
      "Val Loss: 0.020788153012593586\n",
      "Starting epoch 4882\n",
      "Train Loss: 0.020789291571687768\n",
      "Val Loss: 0.020805311975655733\n",
      "Starting epoch 4883\n",
      "Train Loss: 0.020842516311892757\n",
      "Val Loss: 0.02079166692716104\n",
      "Starting epoch 4884\n",
      "Train Loss: 0.020788187781969707\n",
      "Val Loss: 0.02079758048057556\n",
      "Starting epoch 4885\n",
      "Train Loss: 0.021265850022987084\n",
      "Val Loss: 0.020791590213775635\n",
      "Starting epoch 4886\n",
      "Train Loss: 0.020789515089105676\n",
      "Val Loss: 0.02078809340794881\n",
      "Starting epoch 4887\n",
      "Train Loss: 0.020823440066090337\n",
      "Val Loss: 0.02078587810198466\n",
      "Starting epoch 4888\n",
      "Train Loss: 0.020784821223329614\n",
      "Val Loss: 0.020785305787015845\n",
      "Starting epoch 4889\n",
      "Train Loss: 0.02083139176721926\n",
      "Val Loss: 0.020794184119613084\n",
      "Starting epoch 4890\n",
      "Train Loss: 0.020791288327287744\n",
      "Val Loss: 0.021334599013681763\n",
      "Starting epoch 4891\n",
      "Train Loss: 0.020790714356634352\n",
      "Val Loss: 0.020837134785122342\n",
      "Starting epoch 4892\n",
      "Train Loss: 0.02079680617208834\n",
      "Val Loss: 0.020787025491396587\n",
      "Starting epoch 4893\n",
      "Train Loss: 0.021261718538072374\n",
      "Val Loss: 0.020789857263918275\n",
      "Starting epoch 4894\n",
      "Train Loss: 0.020789243004940176\n",
      "Val Loss: 0.02078789472579956\n",
      "Starting epoch 4895\n",
      "Train Loss: 0.020832227336035833\n",
      "Val Loss: 0.02081998685995738\n",
      "Starting epoch 4896\n",
      "Train Loss: 0.021269042182851722\n",
      "Val Loss: 0.021300275016714026\n",
      "Starting epoch 4897\n",
      "Train Loss: 0.0207898892738201\n",
      "Val Loss: 0.02126100880128366\n",
      "Starting epoch 4898\n",
      "Train Loss: 0.020831655021067017\n",
      "Val Loss: 0.020785140218558134\n",
      "Starting epoch 4899\n",
      "Train Loss: 0.02079728411303626\n",
      "Val Loss: 0.020790327478338172\n",
      "Starting epoch 4900\n",
      "Train Loss: 0.020784160605183354\n",
      "Val Loss: 0.020795555026442918\n",
      "Starting epoch 4901\n",
      "Train Loss: 0.020824945635265775\n",
      "Val Loss: 0.020797856979899935\n",
      "Starting epoch 4902\n",
      "Train Loss: 0.020825383839783846\n",
      "Val Loss: 0.02126429588706405\n",
      "Starting epoch 4903\n",
      "Train Loss: 0.021261158364790457\n",
      "Val Loss: 0.020792804382465505\n",
      "Starting epoch 4904\n",
      "Train Loss: 0.021268441169350234\n",
      "Val Loss: 0.02078413411423012\n",
      "Starting epoch 4905\n",
      "Train Loss: 0.02126044973179146\n",
      "Val Loss: 0.020833617559185735\n",
      "Starting epoch 4906\n",
      "Train Loss: 0.02127049642580527\n",
      "Val Loss: 0.020799513216371888\n",
      "Starting epoch 4907\n",
      "Train Loss: 0.02082024293917197\n",
      "Val Loss: 0.020819519956906635\n",
      "Starting epoch 4908\n",
      "Train Loss: 0.020825206681534095\n",
      "Val Loss: 0.021261586635201064\n",
      "Starting epoch 4909\n",
      "Train Loss: 0.02078439736807788\n",
      "Val Loss: 0.021262562937206693\n",
      "Starting epoch 4910\n",
      "Train Loss: 0.020784045811052674\n",
      "Val Loss: 0.020820392502678767\n",
      "Starting epoch 4911\n",
      "Train Loss: 0.020784548035374394\n",
      "Val Loss: 0.020783339937527973\n",
      "Starting epoch 4912\n",
      "Train Loss: 0.021278242270151775\n",
      "Val Loss: 0.020784175506344548\n",
      "Starting epoch 4913\n",
      "Train Loss: 0.020834763292913085\n",
      "Val Loss: 0.02079319953918457\n",
      "Starting epoch 4914\n",
      "Train Loss: 0.020783924946078548\n",
      "Val Loss: 0.02078514904887588\n",
      "Starting epoch 4915\n",
      "Train Loss: 0.020803721414672002\n",
      "Val Loss: 0.021262566248575848\n",
      "Starting epoch 4916\n",
      "Train Loss: 0.02079030650633353\n",
      "Val Loss: 0.02078555855486128\n",
      "Starting epoch 4917\n",
      "Train Loss: 0.020805144751513446\n",
      "Val Loss: 0.020783618644431786\n",
      "Starting epoch 4918\n",
      "Train Loss: 0.020785976891164428\n",
      "Val Loss: 0.02081719923902441\n",
      "Starting epoch 4919\n",
      "Train Loss: 0.020825733189229614\n",
      "Val Loss: 0.021263412303394742\n",
      "Starting epoch 4920\n",
      "Train Loss: 0.02079762076890027\n",
      "Val Loss: 0.02079005484227781\n",
      "Starting epoch 4921\n",
      "Train Loss: 0.020784092170220834\n",
      "Val Loss: 0.020788884825176664\n",
      "Starting epoch 4922\n",
      "Train Loss: 0.020795738807430974\n",
      "Val Loss: 0.020800427154258446\n",
      "Starting epoch 4923\n",
      "Train Loss: 0.020820831259091694\n",
      "Val Loss: 0.020822946672086364\n",
      "Starting epoch 4924\n",
      "Train Loss: 0.020786251734804223\n",
      "Val Loss: 0.02083012185714863\n",
      "Starting epoch 4925\n",
      "Train Loss: 0.020789559792589257\n",
      "Val Loss: 0.020796739944705257\n",
      "Starting epoch 4926\n",
      "Train Loss: 0.02127066640942185\n",
      "Val Loss: 0.020783795802681533\n",
      "Starting epoch 4927\n",
      "Train Loss: 0.021267696111290542\n",
      "Val Loss: 0.020817490087615118\n",
      "Starting epoch 4928\n",
      "Train Loss: 0.020792463863337482\n",
      "Val Loss: 0.020788769479151124\n",
      "Starting epoch 4929\n",
      "Train Loss: 0.02078441944387224\n",
      "Val Loss: 0.02079342195281276\n",
      "Starting epoch 4930\n",
      "Train Loss: 0.020825662546687655\n",
      "Val Loss: 0.020784907870822482\n",
      "Starting epoch 4931\n",
      "Train Loss: 0.02078272678233959\n",
      "Val Loss: 0.020788113828058594\n",
      "Starting epoch 4932\n",
      "Train Loss: 0.020791008516594215\n",
      "Val Loss: 0.020790870542879456\n",
      "Starting epoch 4933\n",
      "Train Loss: 0.021262201446074026\n",
      "Val Loss: 0.021301204959551494\n",
      "Starting epoch 4934\n",
      "Train Loss: 0.02082095543543498\n",
      "Val Loss: 0.020790528919961717\n",
      "Starting epoch 4935\n",
      "Train Loss: 0.020783148430011892\n",
      "Val Loss: 0.020787804215042678\n",
      "Starting epoch 4936\n",
      "Train Loss: 0.020786695458270884\n",
      "Val Loss: 0.020788526093518292\n",
      "Starting epoch 4937\n",
      "Train Loss: 0.02081809827574977\n",
      "Val Loss: 0.020782240562968783\n",
      "Starting epoch 4938\n",
      "Train Loss: 0.020790519537749113\n",
      "Val Loss: 0.02079406104705952\n",
      "Starting epoch 4939\n",
      "Train Loss: 0.020783339385633117\n",
      "Val Loss: 0.020784242285622492\n",
      "Starting epoch 4940\n",
      "Train Loss: 0.021308696380367986\n",
      "Val Loss: 0.020785260531637404\n",
      "Starting epoch 4941\n",
      "Train Loss: 0.020789243004940176\n",
      "Val Loss: 0.020782696980017203\n",
      "Starting epoch 4942\n",
      "Train Loss: 0.02079061832692888\n",
      "Val Loss: 0.020788074643523606\n",
      "Starting epoch 4943\n",
      "Train Loss: 0.020787910178855614\n",
      "Val Loss: 0.02078796205697236\n",
      "Starting epoch 4944\n",
      "Train Loss: 0.020799506041738722\n",
      "Val Loss: 0.020782479533442744\n",
      "Starting epoch 4945\n",
      "Train Loss: 0.020785811322706717\n",
      "Val Loss: 0.020783791939417522\n",
      "Starting epoch 4946\n",
      "Train Loss: 0.020788009519930237\n",
      "Val Loss: 0.020790770649909973\n",
      "Starting epoch 4947\n",
      "Train Loss: 0.02079455554485321\n",
      "Val Loss: 0.020832367517330027\n",
      "Starting epoch 4948\n",
      "Train Loss: 0.020784022631468595\n",
      "Val Loss: 0.02081920040978326\n",
      "Starting epoch 4949\n",
      "Train Loss: 0.020783748339723657\n",
      "Val Loss: 0.020816035292766714\n",
      "Starting epoch 4950\n",
      "Train Loss: 0.02080498249442489\n",
      "Val Loss: 0.020784218002248694\n",
      "Starting epoch 4951\n",
      "Train Loss: 0.020820255080858868\n",
      "Val Loss: 0.02078253417103379\n",
      "Starting epoch 4952\n",
      "Train Loss: 0.020782889591323003\n",
      "Val Loss: 0.020791558203873812\n",
      "Starting epoch 4953\n",
      "Train Loss: 0.02078330682383643\n",
      "Val Loss: 0.020787857196949148\n",
      "Starting epoch 4954\n",
      "Train Loss: 0.02078286530794921\n",
      "Val Loss: 0.020789482527308993\n",
      "Starting epoch 4955\n",
      "Train Loss: 0.020786200960477192\n",
      "Val Loss: 0.021260957475061768\n",
      "Starting epoch 4956\n",
      "Train Loss: 0.020782124665048387\n",
      "Val Loss: 0.020789441687089426\n",
      "Starting epoch 4957\n",
      "Train Loss: 0.020787973094869544\n",
      "Val Loss: 0.021259204105094628\n",
      "Starting epoch 4958\n",
      "Train Loss: 0.02079396888061806\n",
      "Val Loss: 0.020823036079053527\n",
      "Starting epoch 4959\n",
      "Train Loss: 0.020796445232850534\n",
      "Val Loss: 0.020783315654154175\n",
      "Starting epoch 4960\n",
      "Train Loss: 0.02078537035871435\n",
      "Val Loss: 0.020785897418304725\n",
      "Starting epoch 4961\n",
      "Train Loss: 0.02078182664182451\n",
      "Val Loss: 0.020781950266272935\n",
      "Starting epoch 4962\n",
      "Train Loss: 0.020793526812835975\n",
      "Val Loss: 0.020797657193960966\n",
      "Starting epoch 4963\n",
      "Train Loss: 0.021261531997610023\n",
      "Val Loss: 0.02078235149383545\n",
      "Starting epoch 4964\n",
      "Train Loss: 0.020788086785210505\n",
      "Val Loss: 0.020781473981009588\n",
      "Starting epoch 4965\n",
      "Train Loss: 0.020791869472574304\n",
      "Val Loss: 0.02082022472664162\n",
      "Starting epoch 4966\n",
      "Train Loss: 0.020829629566934373\n",
      "Val Loss: 0.020817947056558397\n",
      "Starting epoch 4967\n",
      "Train Loss: 0.020787709289126925\n",
      "Val Loss: 0.02078300107408453\n",
      "Starting epoch 4968\n",
      "Train Loss: 0.02078751888540056\n",
      "Val Loss: 0.020785550276438396\n",
      "Starting epoch 4969\n",
      "Train Loss: 0.02078318761454688\n",
      "Val Loss: 0.020785224658471567\n",
      "Starting epoch 4970\n",
      "Train Loss: 0.020790495806270175\n",
      "Val Loss: 0.021278212467829388\n",
      "Starting epoch 4971\n",
      "Train Loss: 0.020794819902490685\n",
      "Val Loss: 0.021258378470385517\n",
      "Starting epoch 4972\n",
      "Train Loss: 0.020781784697815223\n",
      "Val Loss: 0.02079765443448667\n",
      "Starting epoch 4973\n",
      "Train Loss: 0.020781184788103455\n",
      "Val Loss: 0.020782331625620525\n",
      "Starting epoch 4974\n",
      "Train Loss: 0.020783493916193645\n",
      "Val Loss: 0.020790210476628056\n",
      "Starting epoch 4975\n",
      "Train Loss: 0.02078766127427419\n",
      "Val Loss: 0.02078142762184143\n",
      "Starting epoch 4976\n",
      "Train Loss: 0.020786040359073214\n",
      "Val Loss: 0.020781667696105108\n",
      "Starting epoch 4977\n",
      "Train Loss: 0.020783162779278226\n",
      "Val Loss: 0.02078680197397868\n",
      "Starting epoch 4978\n",
      "Train Loss: 0.020800887434570876\n",
      "Val Loss: 0.021296422790597985\n",
      "Starting epoch 4979\n",
      "Train Loss: 0.020832614766226873\n",
      "Val Loss: 0.020822979233883047\n",
      "Starting epoch 4980\n",
      "Train Loss: 0.020782524788821186\n",
      "Val Loss: 0.020814992211483144\n",
      "Starting epoch 4981\n",
      "Train Loss: 0.020813714574884484\n",
      "Val Loss: 0.02081292702092065\n",
      "Starting epoch 4982\n",
      "Train Loss: 0.020790784447281448\n",
      "Val Loss: 0.02081617271458661\n",
      "Starting epoch 4983\n",
      "Train Loss: 0.02078779869609409\n",
      "Val Loss: 0.02081194464807157\n",
      "Starting epoch 4984\n",
      "Train Loss: 0.0207826633144308\n",
      "Val Loss: 0.020782844335944566\n",
      "Starting epoch 4985\n",
      "Train Loss: 0.020782973479341577\n",
      "Val Loss: 0.020788060846152128\n",
      "Starting epoch 4986\n",
      "Train Loss: 0.020827263041778846\n",
      "Val Loss: 0.020781902803315058\n",
      "Starting epoch 4987\n",
      "Train Loss: 0.020784699806460628\n",
      "Val Loss: 0.020781535793233802\n",
      "Starting epoch 4988\n",
      "Train Loss: 0.020786417303261934\n",
      "Val Loss: 0.020786215861638386\n",
      "Starting epoch 4989\n",
      "Train Loss: 0.020854208756376197\n",
      "Val Loss: 0.020781077720500803\n",
      "Starting epoch 4990\n",
      "Train Loss: 0.020786246215855633\n",
      "Val Loss: 0.020780969549108436\n",
      "Starting epoch 4991\n",
      "Train Loss: 0.020787539857405203\n",
      "Val Loss: 0.020786385845254968\n",
      "Starting epoch 4992\n",
      "Train Loss: 0.020794541195586876\n",
      "Val Loss: 0.021258486089883028\n",
      "Starting epoch 4993\n",
      "Train Loss: 0.0207829260163837\n",
      "Val Loss: 0.02082489099767473\n",
      "Starting epoch 4994\n",
      "Train Loss: 0.021265576283137005\n",
      "Val Loss: 0.02080380916595459\n",
      "Starting epoch 4995\n",
      "Train Loss: 0.020782751065713388\n",
      "Val Loss: 0.020780433659200317\n",
      "Starting epoch 4996\n",
      "Train Loss: 0.020797512045613042\n",
      "Val Loss: 0.021258389508282696\n",
      "Starting epoch 4997\n",
      "Train Loss: 0.020835041999816895\n",
      "Val Loss: 0.02085191563323692\n",
      "Starting epoch 4998\n",
      "Train Loss: 0.020781494401119375\n",
      "Val Loss: 0.020790010138794227\n",
      "Starting epoch 4999\n",
      "Train Loss: 0.02079302955556799\n",
      "Val Loss: 0.020780411583405954\n",
      "Starting epoch 5000\n",
      "Train Loss: 0.020814923776520625\n",
      "Val Loss: 0.02081842941266519\n",
      "Training process has finished.\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "train_loss_all_epoch = []\n",
    "val_loss_all_epoch = []\n",
    "\n",
    "mlp.train(True)\n",
    "for epoch in range(epochs):\n",
    "    print(f'Starting epoch {epoch+1}')\n",
    "\n",
    "    train_loss_per_epoch = train_one_epoch(mlp,loss_function,optimizer,data_train)\n",
    "\n",
    "    train_loss_all_epoch.append(train_loss_per_epoch)\n",
    "\n",
    "    val_loss_per_epoch = validation_one_epoch(mlp,loss_function,data_train)\n",
    "    \n",
    "    val_loss_all_epoch.append(val_loss_per_epoch)\n",
    "    \n",
    "    print(f'Train Loss: {train_loss_per_epoch}')\n",
    "    print(f'Val Loss: {val_loss_per_epoch}')\n",
    "\n",
    "print('Training process has finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss_all_epoch)\n",
    "plt.plot(val_loss_all_epoch)\n",
    "plt.legend(['Treino', 'Validação'])\n",
    "plt.xlabel('Épocas')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.80      0.89        10\n",
      "           2       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.94      0.93      0.93        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "mlp.train(False)\n",
    "\n",
    "for data in data_test:\n",
    "    x_test,y_test = data\n",
    "    x_test = x_test.to(torch.float32)\n",
    "    y_pred = mlp(x_test)\n",
    "    y_pred = torch.Tensor.argmax(y_pred, dim=1)\n",
    "    y_pred = torch.Tensor.numpy(y_pred)\n",
    "    y_test = torch.Tensor.numpy(y_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred,zero_division=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6b89750708a65724d1ad44a6840d11699d802f355f062b571e40236a66d24876"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
